#!/usr/bin/env python3
"""ã€V8.3.21ã€‘å›æµ‹ä¼˜åŒ–æ¨¡å— - è½»é‡çº§ã€æˆæœ¬ä¼˜åŒ–ã€èµ„æºæ§åˆ¶

ç‰¹æ€§ï¼š
1. å¤šç»´åº¦Grid Searchï¼ˆ11ä¸ªå‚æ•°ç»´åº¦ï¼‰
2. V8.3.21ä¸Šä¸‹æ–‡è¿‡æ»¤ï¼ˆKçº¿/å¸‚åœºç»“æ„/S/Rå†å²ï¼‰
3. æœ¬åœ°ç»Ÿè®¡åˆ†æï¼ˆå‚æ•°æ•æ„Ÿåº¦ã€å¼‚å¸¸æ£€æµ‹ï¼‰
4. æˆæœ¬ä¼˜åŒ–çš„AIå†³ç­–ï¼ˆå‹ç¼©æ•°æ®ã€ç²¾ç®€Promptï¼‰
5. èµ„æºæ§åˆ¶ï¼ˆé™åˆ¶å†…å­˜ã€CPU niceå€¼ã€è¿›ç¨‹éš”ç¦»ï¼‰

é€‚ç”¨ç¯å¢ƒï¼š2æ ¸2GæœåŠ¡å™¨
"""

import gc
import os
import random

import numpy as np

# å°è¯•å¯¼å…¥psutilï¼ˆå¯é€‰ï¼‰
try:
    import psutil

    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False


# ============================================================
# ã€æ­¥éª¤2ã€‘è½»é‡çº§Grid Searchï¼ˆèµ„æºæ§åˆ¶ï¼‰
# ============================================================


def optimize_params_v8321_lightweight(
    opportunities: list[dict],
    current_params: dict,
    signal_type: str = "scalping",
    max_combinations: int = 200,
    ai_suggested_params: dict | None = None,
) -> dict:
    """ã€V8.3.21ã€‘è½»é‡çº§å‚æ•°ä¼˜åŒ–

    è®¾è®¡ï¼š
    - 2æ ¸CPUï¼šä½¿ç”¨éšæœºé‡‡æ ·ä»£æ›¿éå†ï¼ˆ200ç»„ vs 2592ç»„ï¼‰
    - 2Gå†…å­˜ï¼šåŠæ—¶é‡Šæ”¾å†…å­˜ï¼Œæ¯10ç»„GCä¸€æ¬¡
    - è¿›ç¨‹éš”ç¦»ï¼šè®¾ç½®niceå€¼ï¼Œé¿å…å½±å“å®æ—¶AI

    Args:
        opportunities: æœºä¼šåˆ—è¡¨ï¼ˆå·²åŒ…å«V8.3.21å­—æ®µï¼‰
        current_params: å½“å‰å‚æ•°
        signal_type: 'scalping' or 'swing'
        max_combinations: æœ€å¤§æµ‹è¯•ç»„æ•°ï¼ˆé»˜è®¤200ï¼‰
        ai_suggested_params: ã€V8.3.25.10æ–°å¢ã€‘AIæ´å¯Ÿå»ºè®®çš„å‚æ•°ï¼ˆå°†åŠ å…¥æµ‹è¯•å€™é€‰é›†ï¼‰

    Returns:
        {
            'optimized_params': {...},
            'top_10_configs': [...],
            'statistics': {...},
            'cost_saved': 0.xx
        }

    """
    # è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§ï¼ˆniceå€¼=10ï¼Œé¿å…å½±å“å®æ—¶AIï¼‰
    try:
        os.nice(10)
        print("   â„¹ï¸  å·²è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§ï¼ˆnice=10ï¼‰ï¼Œé¿å…å½±å“å®æ—¶AI")
    except (OSError, AttributeError):
        pass

    print(f"\n{'=' * 60}")
    print(f"ã€V8.3.21å›æµ‹ä¼˜åŒ–ã€‘è½»é‡çº§å‚æ•°æœç´¢ï¼ˆ{signal_type}ï¼‰")
    print(f"  æœºä¼šæ•°: {len(opportunities)}")
    print(f"  æµ‹è¯•ç»„æ•°: {max_combinations}")
    if HAS_PSUTIL:
        print(
            f"  å†…å­˜é™åˆ¶: æ£€æµ‹åˆ°{psutil.virtual_memory().total / (1024**3):.1f}Gï¼Œå°†ä¸»åŠ¨æ§åˆ¶"
        )
    else:
        print("  èµ„æºç›‘æ§: ä¸å¯ç”¨ï¼ˆpsutilæœªå®‰è£…ï¼‰")
    print(f"{'=' * 60}\n")

    # ===== é˜¶æ®µ1ï¼šå®šä¹‰æœç´¢ç©ºé—´ =====
    print("ğŸ“Š é˜¶æ®µ1: å®šä¹‰æœç´¢ç©ºé—´...")

    # ã€V8.4.4ã€‘ä¼ å…¥current_paramsä½œä¸ºbaselineï¼Œå…è®¸åŠ¨æ€è°ƒæ•´æœç´¢ä¸­å¿ƒ
    param_grid = define_param_grid_v8321(signal_type, baseline_params=current_params)
    total_combinations = calculate_total_combinations(param_grid)

    print("   âœ… æœç´¢ç©ºé—´å®šä¹‰å®Œæˆ")
    print(f"      ç†è®ºç»„åˆæ•°: {total_combinations}ç»„")
    print(f"      å®é™…æµ‹è¯•æ•°: {max_combinations}ç»„ï¼ˆéšæœºé‡‡æ ·ï¼‰")

    # ===== é˜¶æ®µ2ï¼šéšæœºé‡‡æ ·Grid Search =====
    print("\nğŸ” é˜¶æ®µ2: éšæœºé‡‡æ ·Grid Search...")

    sampled_params = random_sample_param_grid(param_grid, max_combinations)

    # ã€V8.3.25.10ã€‘å°†AIå»ºè®®çš„å‚æ•°åŠ å…¥æµ‹è¯•å€™é€‰é›†
    if ai_suggested_params:
        print("   ğŸ¤– å‘ç°AIå»ºè®®å‚æ•°ï¼ŒåŠ å…¥æµ‹è¯•å€™é€‰é›†...")
        ai_config = {}
        # ğŸ”§ V8.3.25.12: åªä¿ç•™æœç´¢ç©ºé—´ä¸­å­˜åœ¨çš„å‚æ•°
        valid_param_names = set(param_grid.keys())
        for key, value in ai_suggested_params.items():
            if key in valid_param_names:
                ai_config[key] = value
            else:
                print(f"      âš ï¸  è·³è¿‡ä¸åœ¨æœç´¢ç©ºé—´ä¸­çš„å‚æ•°: {key}={value}")

        if ai_config:
            # ç¡®ä¿AIå»ºè®®çš„å‚æ•°åœ¨å€™é€‰é›†çš„å‰åˆ—ï¼ˆä¼˜å…ˆæµ‹è¯•ï¼‰
            sampled_params.insert(0, ai_config)
            print(f"      âœ… AIå»ºè®®å‚æ•°å·²åŠ å…¥ï¼ˆä¼˜å…ˆæµ‹è¯•ï¼‰: {ai_config}")
        else:
            print("      â„¹ï¸  AIå»ºè®®çš„å‚æ•°éƒ½ä¸åœ¨æœç´¢ç©ºé—´ä¸­ï¼Œè·³è¿‡")

    all_results = []

    for i, params in enumerate(sampled_params):
        # å†…å­˜æ£€æŸ¥ï¼ˆæ¯10ç»„æ£€æŸ¥ä¸€æ¬¡ï¼‰
        if i % 10 == 0 and HAS_PSUTIL:
            mem_usage = psutil.Process().memory_info().rss / (1024**2)
            if mem_usage > 300:  # è¶…è¿‡300MBåˆ™GC
                gc.collect()
                print(f"      [{i}/{max_combinations}] å†…å­˜: {mem_usage:.0f}MB â†’ GC")

        # æ¨¡æ‹Ÿè¿™ä¸ªå‚æ•°é…ç½®
        result = simulate_params_with_v8321_filter(opportunities, params)
        score = calculate_v8321_optimization_score(result)

        all_results.append({
            "params": params,
            "score": score,
            "metrics": extract_key_metrics(result),
        })

        # è¿›åº¦æ˜¾ç¤º
        if (i + 1) % 20 == 0:
            print(f"      è¿›åº¦: {i + 1}/{max_combinations}...")

    # æ’åºå¹¶å–Top 10
    top_10 = sorted(all_results, key=lambda x: x["score"], reverse=True)[:10]

    print("   âœ… Grid Searchå®Œæˆ")
    print(f"      æœ€é«˜åˆ†: {top_10[0]['score']:.3f}")
    print(f"      æµ‹è¯•ç»„æ•°: {len(all_results)}")

    # ä¸»åŠ¨GC
    gc.collect()

    # ===== é˜¶æ®µ3ï¼šæœ¬åœ°ç»Ÿè®¡åˆ†æ =====
    print("\nğŸ“ˆ é˜¶æ®µ3: æœ¬åœ°ç»Ÿè®¡åˆ†æï¼ˆå…è´¹ï¼‰...")

    # æœ¬åœ°è®¡ç®—ï¼šå‚æ•°æ•æ„Ÿåº¦
    param_sensitivity = calculate_param_sensitivity_local(all_results)

    # æœ¬åœ°è®¡ç®—ï¼šä¸Šä¸‹æ–‡ç‰¹å¾ç›¸å…³æ€§
    context_analysis = analyze_context_features_local(
        opportunities, top_10[0]["params"]
    )

    # æœ¬åœ°æ£€æµ‹ï¼šå¼‚å¸¸æƒ…å†µ
    anomalies = detect_anomalies_local(all_results, param_sensitivity)

    print("   âœ… ç»Ÿè®¡åˆ†æå®Œæˆ")
    print(f"      å…³é”®å‚æ•°: {list(param_sensitivity.keys())[:3]}")
    print(f"      å¼‚å¸¸æ£€æµ‹: {len(anomalies)}ä¸ª")

    # ===== é˜¶æ®µ4ï¼šæ•°æ®å‹ç¼© =====
    print("\nğŸ—œï¸  é˜¶æ®µ4: æ•°æ®å‹ç¼©ï¼ˆèŠ‚çœAIæˆæœ¬ï¼‰...")

    compressed_data = compress_optimization_results(
        top_10=top_10,
        param_sensitivity=param_sensitivity,
        context_analysis=context_analysis,
        anomalies=anomalies,
    )

    estimated_tokens = estimate_token_count(compressed_data)
    original_tokens = len(all_results) * 100  # å‡è®¾åŸå§‹æ¯ç»„100 tokens
    cost_saved = (original_tokens - estimated_tokens) * 0.00002  # GPT-4ä»·æ ¼

    print("   âœ… æ•°æ®å‹ç¼©å®Œæˆ")
    print(f"      åŸå§‹: ~{original_tokens} tokens")
    print(f"      å‹ç¼©å: ~{estimated_tokens} tokens")
    print(f"      ğŸ’° é¢„è®¡èŠ‚çœ: ${cost_saved:.4f}")

    # ===== é˜¶æ®µ5ï¼šAIè¿­ä»£å†³ç­–ï¼ˆå¯é€‰ï¼‰=====
    ai_decision = None
    ai_adjusted_params = None

    if max_combinations >= 100:  # åªæœ‰å¤§è§„æ¨¡æœç´¢æ‰å€¼å¾—AIä»‹å…¥
        print("\nğŸ¤– é˜¶æ®µ5: AIè¿­ä»£å†³ç­–...")
        try:
            ai_decision = call_ai_for_iterative_optimization(
                top_10_configs=top_10,
                param_sensitivity=param_sensitivity,
                context_analysis=context_analysis,
                anomalies=anomalies,
                compressed_data=compressed_data,
                signal_type=signal_type,
            )

            if ai_decision and ai_decision.get("needs_adjustment"):
                print("   ğŸ”§ AIå»ºè®®è°ƒæ•´å‚æ•°...")
                ai_adjusted_params = apply_ai_adjustments(
                    base_params=top_10[0]["params"],
                    adjustments=ai_decision["param_adjustments"],
                )

                # éªŒè¯AIè°ƒæ•´åçš„å‚æ•°
                ai_result = simulate_params_with_v8321_filter(
                    opportunities, ai_adjusted_params
                )
                ai_score = calculate_v8321_optimization_score(ai_result)

                print("   ğŸ“Š AIè°ƒæ•´æ•ˆæœ:")
                print(f"      Gridæœ€ä¼˜: {top_10[0]['score']:.3f}")
                print(
                    f"      AIè°ƒæ•´å: {ai_score:.3f} ({ai_score - top_10[0]['score']:+.3f})"
                )

                # å¦‚æœAIè°ƒæ•´åæ›´å¥½ï¼Œä½¿ç”¨AIå‚æ•°
                if ai_score > top_10[0]["score"]:
                    print("   âœ… AIè°ƒæ•´æœ‰æ•ˆï¼Œé‡‡çº³AIå»ºè®®")
                    final_params = ai_adjusted_params
                    cost_saved += 0.01  # AIè°ƒç”¨æˆæœ¬çº¦$0.01
                else:
                    print("   âš ï¸  AIè°ƒæ•´æ•ˆæœä¸ä½³ï¼Œä¿æŒGridç»“æœ")
                    final_params = top_10[0]["params"]
                    top_10[0]["score"]
            else:
                print("   âœ… AIè®¤ä¸ºå½“å‰å‚æ•°å·²æ˜¯æœ€ä¼˜")
                final_params = top_10[0]["params"]
                top_10[0]["score"]

        except Exception as e:
            print(f"   âš ï¸  AIå†³ç­–å¤±è´¥: {e}")
            final_params = top_10[0]["params"]
            top_10[0]["score"]
    else:
        final_params = top_10[0]["params"]
        top_10[0]["score"]

    return {
        "optimized_params": final_params,
        "top_10_configs": top_10,
        "statistics": {
            "param_sensitivity": param_sensitivity,
            "score_distribution": calculate_score_distribution(all_results),
        },
        "context_analysis": context_analysis,
        "anomalies": anomalies,
        "compressed_data": compressed_data,
        "cost_saved": cost_saved,
        "ai_decision": ai_decision,  # AIå†³ç­–ï¼ˆè‹±æ–‡ï¼‰
        "ai_adjusted_params": ai_adjusted_params,  # AIè°ƒæ•´åçš„å‚æ•°
    }


def define_param_grid_v8321(
    signal_type: str, baseline_params: dict | None = None
) -> dict:
    """ã€V8.4.4ã€‘å®šä¹‰V8.3.21å‚æ•°æœç´¢ç©ºé—´ï¼ˆåŠ¨æ€èŒƒå›´çº¦æŸï¼‰

    æ ¸å¿ƒæ€è·¯ï¼š
    1. å›ºå®šåŸºå‡†å‚æ•°ï¼ˆé˜¶æ®µ2ç”¨äºè®¡ç®—actual_profitï¼Œç¡®ä¿å®¢è§‚æ€§ï¼‰
    2. ä¼˜åŒ–å™¨å¯ä»¥åœ¨åŸºå‡†Â±50%èŒƒå›´å†…æœç´¢ï¼ˆè‡ªé€‚åº”å¸‚åœºæ³¢åŠ¨ï¼‰
    3. è®¾ç½®ç»å¯¹è¾¹ç•Œé˜²æ­¢æç«¯å€¼ï¼ˆå¦‚atr_tp=6.0ï¼‰

    ç¤ºä¾‹ï¼ˆæ³¢æ®µï¼‰ï¼š
    - åŸºå‡†ï¼šatr_tp=3.0
    - æœç´¢èŒƒå›´ï¼š[1.5, 3.0, 4.5]ï¼ˆÂ±50%ï¼‰
    - ç»å¯¹è¾¹ç•Œï¼š[2.0, 5.0]ï¼ˆä¸å…è®¸<2.0æˆ–>5.0ï¼‰
    - å®é™…æœç´¢ï¼š[2.0, 3.0, 4.5]

    Args:
        signal_type: 'scalping' æˆ– 'swing'
        baseline_params: ä¸Šä¸€æ¬¡ä¼˜åŒ–çš„å‚æ•°ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´æœç´¢ä¸­å¿ƒï¼‰

    Returns:
        å‚æ•°æœç´¢ç©ºé—´å­—å…¸

    """
    # ã€V8.5.2.4.39ã€‘æ‰©å¤§å‚æ•°æœç´¢ç©ºé—´ï¼ˆç”¨æˆ·åé¦ˆï¼šæ‰©å¤§èŒƒå›´ï¼Œæ›´å¥½åœ°æ‰¾åˆ°æœ€ä¼˜å‚æ•°ï¼‰
    if signal_type == "scalping":
        # è¶…çŸ­çº¿å›ºå®šåŸºå‡†
        baseline = {
            "atr_tp_multiplier": 2.0,
            "atr_stop_multiplier": 1.5,
            "max_holding_hours": 8,
            "min_risk_reward": 1.0,  # ã€V8.4.7ã€‘ä»1.5é™åˆ°1.0ï¼ˆåŒ¹é…å®é™…R:Råˆ†å¸ƒï¼‰
        }
        # ã€V8.5.2.4.39ã€‘ç»å¯¹è¾¹ç•Œæ‰©å¤§ï¼ˆç¡¬çº¦æŸï¼Œä½†å…è®¸æ›´å¹¿èŒƒå›´æ¢ç´¢ï¼‰
        bounds = {
            "atr_tp_multiplier": (0.8, 4.0),  # æ‰©å¤§ï¼š1.0-3.0 â†’ 0.8-4.0
            "atr_stop_multiplier": (0.8, 2.5),  # æ‰©å¤§ï¼š1.0-2.0 â†’ 0.8-2.5
            "max_holding_hours": (2, 24),  # æ‰©å¤§ï¼š4-16 â†’ 2-24
            "min_risk_reward": (0.5, 3.5),  # æ‰©å¤§ï¼š0.5-2.5 â†’ 0.5-3.5
        }
    else:  # swing
        # æ³¢æ®µå›ºå®šåŸºå‡†
        baseline = {
            "atr_tp_multiplier": 3.0,
            "atr_stop_multiplier": 1.5,
            "max_holding_hours": 60,
            "min_risk_reward": 1.2,  # ã€V8.4.7ã€‘ä»1.5é™åˆ°1.2ï¼ˆæ›´æ¥è¿‘å®é™…ï¼‰
        }
        # ã€V8.5.2.4.39ã€‘ç»å¯¹è¾¹ç•Œæ‰©å¤§
        bounds = {
            "atr_tp_multiplier": (1.5, 7.0),  # æ‰©å¤§ï¼š2.0-5.0 â†’ 1.5-7.0
            "atr_stop_multiplier": (0.8, 3.0),  # æ‰©å¤§ï¼š1.0-2.5 â†’ 0.8-3.0
            "max_holding_hours": (24, 120),  # æ‰©å¤§ï¼š36-96 â†’ 24-120
            "min_risk_reward": (0.5, 4.0),  # æ‰©å¤§ï¼š0.5-3.0 â†’ 0.5-4.0
        }

    # ã€V8.4.4ã€‘å¦‚æœæä¾›äº†baseline_paramsï¼Œç”¨å®ƒä½œä¸ºæœç´¢ä¸­å¿ƒï¼ˆä½†ä»å—è¾¹ç•Œé™åˆ¶ï¼‰
    if baseline_params:
        for key in [
            "atr_tp_multiplier",
            "atr_stop_multiplier",
            "max_holding_hours",
            "min_risk_reward",
        ]:
            if key in baseline_params:
                value = baseline_params[key]
                min_bound, max_bound = bounds[key]
                # é™åˆ¶åœ¨è¾¹ç•Œå†…
                baseline[key] = max(min_bound, min(max_bound, value))

    # ã€V8.4.4ã€‘ç”Ÿæˆæœç´¢ç©ºé—´ï¼ˆåŸºå‡†Â±50%ï¼Œå—ç»å¯¹è¾¹ç•Œé™åˆ¶ï¼‰
    def generate_search_range(param_name, center_value):
        """ç”Ÿæˆæœç´¢èŒƒå›´ï¼šcenter Â± 50%ï¼Œä½†ä¸è¶…è¿‡ç»å¯¹è¾¹ç•Œ"""
        min_bound, max_bound = bounds[param_name]

        # è®¡ç®—Â±50%èŒƒå›´
        lower = max(min_bound, center_value * 0.5)
        upper = min(max_bound, center_value * 1.5)

        # ç”Ÿæˆ3ä¸ªé‡‡æ ·ç‚¹ï¼šä¸‹é™ã€ä¸­å¿ƒã€ä¸Šé™
        if param_name == "max_holding_hours":
            # æ•´æ•°å‚æ•°
            return [int(lower), int(center_value), int(upper)]
        # æµ®ç‚¹å‚æ•°ï¼Œä¿ç•™1ä½å°æ•°
        return [round(lower, 1), round(center_value, 1), round(upper, 1)]

    if signal_type == "scalping":
        grid = {
            # ã€V8.4.4ã€‘åŸºç¡€å‚æ•°ï¼ˆåŠ¨æ€èŒƒå›´ï¼Œå›´ç»•åŸºå‡†Â±50%ï¼‰
            "max_holding_hours": generate_search_range(
                "max_holding_hours", baseline["max_holding_hours"]
            ),
            "atr_tp_multiplier": generate_search_range(
                "atr_tp_multiplier", baseline["atr_tp_multiplier"]
            ),
            "atr_stop_multiplier": generate_search_range(
                "atr_stop_multiplier", baseline["atr_stop_multiplier"]
            ),
            "min_risk_reward": generate_search_range(
                "min_risk_reward", baseline["min_risk_reward"]
            ),
            # å…¥åœºè¿‡æ»¤å‚æ•°ï¼ˆä¿æŒåŸæœ‰èŒƒå›´ï¼‰
            "min_signal_score": [40, 50, 60],
            "min_consensus_score": [0, 10, 20, 30],
            "min_consensus": [0, 1, 2],
            "min_kline_bullish_ratio": [0.6, 0.7],
            "min_price_chg_pct": [0.5, 1.0, 1.5],
            "allowed_mkt_struct": ["all", "trend_only"],
            "min_trend_age_hours": [0.5, 1.0],
            "max_sr_test_count": [5, 999],
        }
    else:  # swing
        grid = {
            # ã€V8.4.4ã€‘åŸºç¡€å‚æ•°ï¼ˆåŠ¨æ€èŒƒå›´ï¼Œå›´ç»•åŸºå‡†Â±50%ï¼‰
            "max_holding_hours": generate_search_range(
                "max_holding_hours", baseline["max_holding_hours"]
            ),
            "atr_tp_multiplier": generate_search_range(
                "atr_tp_multiplier", baseline["atr_tp_multiplier"]
            ),
            "atr_stop_multiplier": generate_search_range(
                "atr_stop_multiplier", baseline["atr_stop_multiplier"]
            ),
            "min_risk_reward": generate_search_range(
                "min_risk_reward", baseline["min_risk_reward"]
            ),
            # å…¥åœºè¿‡æ»¤å‚æ•°ï¼ˆä¿æŒåŸæœ‰èŒƒå›´ï¼‰
            "min_signal_score": [40, 50, 60],
            "min_consensus_score": [0, 10, 20, 30],
            "min_consensus": [0, 1, 2],
            "min_kline_bullish_ratio": [0.6, 0.7],
            "min_price_chg_pct": [0.5, 1.0, 1.5],
            "allowed_mkt_struct": ["all", "trend_only"],
            "min_trend_age_hours": [1.0, 2.0],
            "max_sr_test_count": [5, 999],
        }

    return grid


def random_sample_param_grid(grid: dict, sample_size: int) -> list[dict]:
    """ã€V8.4.5ã€‘æ™ºèƒ½é‡‡æ ·å‚æ•°ç»„åˆ

    ç­–ç•¥ï¼š
    1. è¾¹ç•Œé‡‡æ ·ï¼ˆ30%ï¼‰ï¼šæµ‹è¯•æ¯ä¸ªå‚æ•°çš„æå€¼ï¼Œç¡®ä¿è¦†ç›–è¾¹ç•Œ
    2. ä¸­å¿ƒç‚¹é‡‡æ ·ï¼ˆ1ä¸ªï¼‰ï¼šæµ‹è¯•é»˜è®¤é…ç½®
    3. éšæœºå¡«å……ï¼ˆå‰©ä½™ï¼‰ï¼šè¦†ç›–å…¶ä»–åŒºåŸŸ

    ä¼˜åŠ¿ï¼š
    - ç¡®ä¿æµ‹è¯•æ‰€æœ‰å…³é”®åŒºåŸŸï¼ˆè¾¹ç•Œã€ä¸­å¿ƒï¼‰
    - ä¸å¢åŠ è®¡ç®—é‡ï¼ˆä»ç„¶200ç»„ï¼‰
    - æé«˜æ‰¾åˆ°æœ€ä¼˜è§£çš„æ¦‚ç‡

    ç¤ºä¾‹ï¼ˆ200ç»„ï¼‰ï¼š
    - è¾¹ç•Œé‡‡æ ·ï¼š60ç»„ï¼ˆæ¯ä¸ªå‚æ•°çš„min/maxé…ç½®ï¼‰
    - ä¸­å¿ƒç‚¹ï¼š1ç»„
    - éšæœºï¼š139ç»„
    """
    samples = []
    param_names = list(grid.keys())
    param_values = [grid[name] for name in param_names]

    # ===== 1. è¾¹ç•Œé‡‡æ ·ï¼ˆ30%ï¼‰ =====
    boundary_samples = []
    for i, param_name in enumerate(param_names):
        values = param_values[i]
        if len(values) < 2:
            continue  # åªæœ‰1ä¸ªå€¼ï¼Œè·³è¿‡

        # æœ€å°å€¼é…ç½®ï¼šè¯¥å‚æ•°å–æœ€å°å€¼ï¼Œå…¶ä»–å‚æ•°å–ä¸­é—´å€¼
        min_config = {}
        for j, name in enumerate(param_names):
            if j == i:
                min_config[name] = param_values[j][0]  # æœ€å°å€¼
            else:
                mid_idx = len(param_values[j]) // 2
                min_config[name] = param_values[j][mid_idx]  # ä¸­é—´å€¼
        boundary_samples.append(min_config)

        # æœ€å¤§å€¼é…ç½®ï¼šè¯¥å‚æ•°å–æœ€å¤§å€¼ï¼Œå…¶ä»–å‚æ•°å–ä¸­é—´å€¼
        max_config = {}
        for j, name in enumerate(param_names):
            if j == i:
                max_config[name] = param_values[j][-1]  # æœ€å¤§å€¼
            else:
                mid_idx = len(param_values[j]) // 2
                max_config[name] = param_values[j][mid_idx]  # ä¸­é—´å€¼
        boundary_samples.append(max_config)

    # å»é‡ï¼ˆå¯èƒ½æœ‰é‡å¤çš„è¾¹ç•Œé…ç½®ï¼‰
    boundary_samples_unique = []
    seen = set()
    for config in boundary_samples:
        config_tuple = tuple(sorted(config.items()))
        if config_tuple not in seen:
            seen.add(config_tuple)
            boundary_samples_unique.append(config)

    samples.extend(boundary_samples_unique)

    # ===== 2. ä¸­å¿ƒç‚¹é‡‡æ ·ï¼ˆ1ä¸ªï¼‰ =====
    center_config = {}
    for i, name in enumerate(param_names):
        mid_idx = len(param_values[i]) // 2
        center_config[name] = param_values[i][mid_idx]

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    center_tuple = tuple(sorted(center_config.items()))
    if center_tuple not in seen:
        samples.append(center_config)
        seen.add(center_tuple)

    # ===== 3. éšæœºå¡«å……ï¼ˆå‰©ä½™ï¼‰ =====
    remaining = sample_size - len(samples)
    if remaining > 0:
        # ç”Ÿæˆæ‰€æœ‰ç»„åˆçš„ç´¢å¼•
        from itertools import product

        all_indices = list(product(*[range(len(vals)) for vals in param_values]))

        # è¿‡æ»¤æ‰å·²é‡‡æ ·çš„é…ç½®
        available_indices = []
        for indices in all_indices:
            config = {
                param_names[i]: param_values[i][indices[i]]
                for i in range(len(param_names))
            }
            config_tuple = tuple(sorted(config.items()))
            if config_tuple not in seen:
                available_indices.append(indices)

        # éšæœºé‡‡æ ·
        if len(available_indices) > remaining:
            sampled_indices = random.sample(available_indices, remaining)
        else:
            sampled_indices = available_indices

        # æ„å»ºå‚æ•°å­—å…¸
        for indices in sampled_indices:
            config = {
                param_names[i]: param_values[i][indices[i]]
                for i in range(len(param_names))
            }
            samples.append(config)

    print("   ğŸ“Š æ™ºèƒ½é‡‡æ ·ç»Ÿè®¡:")
    print(f"      è¾¹ç•Œé‡‡æ ·: {len(boundary_samples_unique)}ç»„")
    print("      ä¸­å¿ƒç‚¹: 1ç»„")
    print(f"      éšæœºå¡«å……: {len(samples) - len(boundary_samples_unique) - 1}ç»„")
    print(f"      æ€»è®¡: {len(samples)}ç»„")

    return samples


def calculate_total_combinations(grid: dict) -> int:
    """è®¡ç®—æ€»ç»„åˆæ•°"""
    total = 1
    for values in grid.values():
        total *= len(values)
    return total


# ============================================================
# ã€æ­¥éª¤3ã€‘V8.3.21ä¸Šä¸‹æ–‡è¿‡æ»¤å‡½æ•°
# ============================================================


def test_params_on_opportunities(opportunities: list[dict], params: dict) -> dict:
    """ã€V8.4.5ã€‘æµ‹è¯•å‚æ•°åœ¨æœºä¼šé›†ä¸Šçš„è¡¨ç°ï¼ˆåˆ«åå‡½æ•°ï¼‰

    è¿™æ˜¯simulate_params_with_v8321_filterçš„åˆ«åï¼Œ
    ç”¨äºå‰å‘éªŒè¯æ—¶æµ‹è¯•å‚æ•°æ•ˆæœã€‚

    Args:
        opportunities: æœºä¼šåˆ—è¡¨
        params: å‚æ•°å­—å…¸

    Returns:
        ç»Ÿè®¡ç»“æœå­—å…¸ï¼ˆåŒ…æ‹¬avg_profit, capture_rateç­‰ï¼‰

    """
    return simulate_params_with_v8321_filter(opportunities, params)


def simulate_params_with_v8321_filter(opportunities: list[dict], params: dict) -> dict:
    """ã€V8.3.21â†’V8.3.21.1ã€‘ä½¿ç”¨ä¸Šä¸‹æ–‡è¿‡æ»¤å‚æ•°æ¨¡æ‹Ÿäº¤æ˜“ï¼ˆä¿®å¤è¿‡åº¦è¿‡æ»¤ï¼‰

    è¿‡æ»¤å±‚æ¬¡ï¼š
    1. åŸºç¡€è¿‡æ»¤ï¼ˆsignal_score/consensus/risk_rewardï¼‰- å¿…é¡»
    2. Kçº¿ä¸Šä¸‹æ–‡è¿‡æ»¤ï¼ˆé˜³çº¿æ¯”ä¾‹ã€ä»·æ ¼å˜åŒ–ï¼‰- å¯é€‰
    3. å¸‚åœºç»“æ„è¿‡æ»¤ï¼ˆswingç±»å‹ã€è¶‹åŠ¿å¹´é¾„ï¼‰- å¯é€‰
    4. S/Rå†å²è¿‡æ»¤ï¼ˆæµ‹è¯•æ¬¡æ•°ã€å‡çªç ´ï¼‰- å¯é€‰

    ã€V8.3.21.1ä¿®å¤ã€‘ï¼šLayer 2-4é»˜è®¤ä¸å¯ç”¨ï¼Œé¿å…è¿‡åº¦è¿‡æ»¤å†å²æ•°æ®
    """
    captured = []
    missed_reasons: dict[str, int] = {}

    # ã€V8.3.21.1ä¿®å¤ã€‘é«˜çº§è¿‡æ»¤å™¨é»˜è®¤ä¸å¯ç”¨
    enable_advanced_filters = params.get("enable_advanced_filters", False)

    for opp in opportunities:
        # ç¬¬1å±‚ï¼šåŸºç¡€è¿‡æ»¤ï¼ˆå¿…é¡»ï¼‰
        if not passes_basic_filter(opp, params):
            reason = "basic_params"
            missed_reasons[reason] = missed_reasons.get(reason, 0) + 1
            continue

        # ã€V8.3.21.1ä¿®å¤ã€‘ç¬¬2-4å±‚ï¼šé«˜çº§è¿‡æ»¤ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸å¯ç”¨ï¼‰
        if enable_advanced_filters:
            # ç¬¬2å±‚ï¼šKçº¿ä¸Šä¸‹æ–‡è¿‡æ»¤
            if not passes_kline_context_filter(opp, params):
                reason = "kline_context"
                missed_reasons[reason] = missed_reasons.get(reason, 0) + 1
                continue

            # ç¬¬3å±‚ï¼šå¸‚åœºç»“æ„è¿‡æ»¤
            if not passes_market_structure_filter(opp, params):
                reason = "market_structure"
                missed_reasons[reason] = missed_reasons.get(reason, 0) + 1
                continue

            # ç¬¬4å±‚ï¼šS/Rå†å²è¿‡æ»¤
            if not passes_sr_history_filter(opp, params):
                reason = "sr_history"
                missed_reasons[reason] = missed_reasons.get(reason, 0) + 1
                continue

        # é€šè¿‡æ‰€æœ‰è¿‡æ»¤ï¼Œè®°å½•
        captured.append(opp)

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if len(captured) == 0:
        return {
            "total_opportunities": len(opportunities),
            "captured_count": 0,
            "capture_rate": 0,
            "avg_profit": 0,
            "win_rate": 0,
            "time_exit_rate": 0,
            "missed_reasons": missed_reasons,
        }

    # ã€V8.3.21.1ä¿®å¤ã€‘è®¡ç®—åˆ©æ¶¦ï¼ˆå…¼å®¹ä¸åŒå­—æ®µåï¼‰
    # ä¼˜å…ˆä½¿ç”¨actual_profit_pctï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨objective_profit
    profits = []
    for c in captured:
        if "actual_profit_pct" in c:
            profits.append(c["actual_profit_pct"])
        elif "objective_profit" in c:
            profits.append(c["objective_profit"])
        else:
            profits.append(0)  # é»˜è®¤å€¼

    avg_profit = np.mean(profits) if len(profits) > 0 else 0

    # ã€V8.3.21é£æ§ã€‘åˆ†ç¦»ç›ˆåˆ©å’ŒäºæŸ
    wins = [p for p in profits if p > 0]
    losses = [p for p in profits if p <= 0]

    win_rate = len(wins) / len(profits) if len(profits) > 0 else 0
    avg_win = np.mean(wins) if len(wins) > 0 else 0
    avg_loss = np.mean(losses) if len(losses) > 0 else 0

    # ç›ˆäºæ¯”ï¼ˆèµšçš„æ—¶å€™èµšå¤šå°‘ / äºçš„æ—¶å€™äºå¤šå°‘ï¼‰
    profit_loss_ratio = abs(avg_win / avg_loss) if avg_loss != 0 else 999

    # æœŸæœ›æ”¶ç›Šï¼ˆè€ƒè™‘èƒœç‡å’Œç›ˆäºæ¯”ï¼‰
    expectancy = (win_rate * avg_win) + ((1 - win_rate) * avg_loss)

    # æœ€å¤§å›æ’¤ï¼ˆè¿ç»­äºæŸçš„æœ€å¤§å€¼ï¼‰
    max_drawdown = 0
    cumulative = 0
    peak = 0
    for p in profits:
        cumulative += p
        peak = max(peak, cumulative)
        drawdown = peak - cumulative
        max_drawdown = max(max_drawdown, drawdown)

    return {
        "total_opportunities": len(opportunities),
        "captured_count": len(captured),
        "capture_rate": len(captured) / len(opportunities),
        "avg_profit": avg_profit,
        "win_rate": win_rate,
        "time_exit_rate": 0.5,  # ç®€åŒ–ï¼šå‡è®¾50% time_exit
        "missed_reasons": missed_reasons,
        "captured_details": captured,  # è¯¦ç»†æ•°æ®ï¼ˆç”¨äºè¿›ä¸€æ­¥åˆ†æï¼‰
        # ã€V8.3.21é£æ§ã€‘æ–°å¢é£æ§æŒ‡æ ‡
        "avg_win": avg_win,  # ç›ˆåˆ©æ—¶å¹³å‡èµšå¤šå°‘
        "avg_loss": avg_loss,  # äºæŸæ—¶å¹³å‡äºå¤šå°‘
        "profit_loss_ratio": profit_loss_ratio,  # ç›ˆäºæ¯”
        "expectancy": expectancy,  # æœŸæœ›æ”¶ç›Š
        "max_drawdown": max_drawdown,  # æœ€å¤§å›æ’¤
        "win_count": len(wins),  # ç›ˆåˆ©ç¬”æ•°
        "loss_count": len(losses),  # äºæŸç¬”æ•°
    }


def get_profit_pct(opp: dict) -> float:
    """ã€V8.3.21.1è¾…åŠ©ã€‘è·å–åˆ©æ¶¦ç™¾åˆ†æ¯”ï¼ˆå…¼å®¹ä¸åŒå­—æ®µåï¼‰

    ä¼˜å…ˆçº§ï¼šactual_profit_pct > objective_profit > 0
    """
    if "actual_profit_pct" in opp:
        return opp["actual_profit_pct"]
    if "objective_profit" in opp:
        return opp["objective_profit"]
    return 0.0


def passes_basic_filter(opp: dict, params: dict) -> bool:
    """ã€V8.4ã€‘åŸºç¡€å‚æ•°è¿‡æ»¤ - ä½¿ç”¨æ–°çš„consensus_score

    ä¼˜å…ˆçº§ï¼š
    1. ä¼˜å…ˆä½¿ç”¨consensus_scoreï¼ˆ0-100ï¼‰è€Œéæ—§çš„consensusï¼ˆ0-5ï¼‰
    2. ä¼˜å…ˆä½¿ç”¨actual_risk_rewardè€Œérisk_reward
    """
    # ä¼˜å…ˆä½¿ç”¨actual_risk_rewardï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ°risk_reward
    rr_value = opp.get("actual_risk_reward", opp.get("risk_reward", 0))

    # ã€V8.4ã€‘ä¼˜å…ˆä½¿ç”¨æ–°çš„consensus_scoreï¼ˆ0-100åˆ†ï¼‰
    if "consensus_score" in opp and "min_consensus_score" in params:
        # æ–°ç‰ˆè¿‡æ»¤ï¼šä½¿ç”¨consensus_score
        return (
            opp["signal_score"] >= params.get("min_signal_score", 50)
            and opp["consensus_score"] >= params.get("min_consensus_score", 30)
            and rr_value >= params.get("min_risk_reward", 1.5)
        )
    # ã€å…¼å®¹æ€§ã€‘å›é€€åˆ°æ—§ç‰ˆè¿‡æ»¤ï¼šä½¿ç”¨consensusï¼ˆ0-5ï¼‰
    consensus_value = opp.get("consensus", opp.get("indicator_consensus", 0))
    return (
        opp["signal_score"] >= params.get("min_signal_score", 50)
        and consensus_value >= params.get("min_consensus", 2)
        and rr_value >= params.get("min_risk_reward", 1.5)
    )


def passes_kline_context_filter(opp: dict, params: dict) -> bool:
    """Kçº¿ä¸Šä¸‹æ–‡è¿‡æ»¤"""
    # æ£€æŸ¥é˜³çº¿/é˜´çº¿æ¯”ä¾‹
    bullish_ratio = opp.get("kline_ctx_bullish_ratio", 0)
    min_ratio = params.get("min_kline_bullish_ratio", 0.6)

    if opp["direction"] == "long":
        if bullish_ratio < min_ratio:
            return False
    elif (1 - bullish_ratio) < min_ratio:
        return False

    # æ£€æŸ¥ä»·æ ¼å˜åŒ–å¹…åº¦
    price_chg = abs(opp.get("kline_ctx_price_chg_pct", 0))
    if price_chg < params.get("min_price_chg_pct", 0.5):
        return False

    return True


def passes_market_structure_filter(opp: dict, params: dict) -> bool:
    """å¸‚åœºç»“æ„è¿‡æ»¤"""
    # æ£€æŸ¥æ˜¯å¦åªåšè¶‹åŠ¿å¸‚åœº
    if params.get("allowed_mkt_struct") == "trend_only":
        swing_type = opp.get("mkt_struct_swing", "")
        if swing_type not in ["HH-HL", "LL-LH"]:
            return False

    # æ£€æŸ¥è¶‹åŠ¿å¹´é¾„
    trend_age = opp.get("mkt_struct_age_hours", 0)
    min_age = params.get("min_trend_age_hours", 0.5)
    if trend_age < min_age:
        return False

    return True


def passes_sr_history_filter(opp: dict, params: dict) -> bool:
    """S/Rå†å²è¿‡æ»¤"""
    # æ ¹æ®æ–¹å‘é€‰æ‹©å¯¹åº”çš„S/R
    if opp["direction"] == "long":
        test_cnt = opp.get("support_hist_test_cnt", 0)
        false_bd = opp.get("support_hist_false_bd", 0)
    else:
        test_cnt = opp.get("resist_hist_test_cnt", 0)
        false_bd = opp.get("resist_hist_false_bo", 0)

    # æ£€æŸ¥æµ‹è¯•æ¬¡æ•°
    max_test = params.get("max_sr_test_count", 999)
    if test_cnt > max_test:
        return False

    # æ£€æŸ¥å‡çªç ´ï¼ˆå›ºå®šâ‰¤2æ¬¡ï¼‰
    if false_bd > 2:
        return False

    return True


# ============================================================
# ã€æ­¥éª¤4ã€‘æœ¬åœ°ç»Ÿè®¡åˆ†æå‡½æ•°
# ============================================================


def calculate_param_sensitivity_local(all_results: list[dict]) -> dict:
    """ã€æœ¬åœ°è®¡ç®—ã€‘å‚æ•°æ•æ„Ÿåº¦åˆ†æ

    è®¡ç®—æ¯ä¸ªå‚æ•°å˜åŒ–æ—¶ï¼Œscoreçš„å¹³å‡å˜åŒ–é‡
    """
    sensitivity = {}

    # æŒ‰å‚æ•°åˆ†ç»„
    param_names = list(all_results[0]["params"].keys())

    for param_name in param_names:
        # è·å–è¯¥å‚æ•°çš„æ‰€æœ‰å–å€¼
        param_values = sorted(set([r["params"][param_name] for r in all_results]))

        if len(param_values) < 2:
            continue

        # è®¡ç®—ç›¸é‚»å–å€¼ä¹‹é—´çš„scoreå˜åŒ–
        score_changes = []
        for i in range(len(param_values) - 1):
            v1, v2 = param_values[i], param_values[i + 1]

            # æ‰¾åˆ°è¯¥å‚æ•°=v1å’Œv2çš„ç»“æœ
            results_v1 = [r for r in all_results if r["params"][param_name] == v1]
            results_v2 = [r for r in all_results if r["params"][param_name] == v2]

            if results_v1 and results_v2:
                avg_score_v1 = np.mean([r["score"] for r in results_v1])
                avg_score_v2 = np.mean([r["score"] for r in results_v2])

                # è®¡ç®—å•ä½å˜åŒ–çš„å½±å“
                param_change = abs(v2 - v1) if isinstance(v1, (int, float)) else 1
                score_change = (avg_score_v2 - avg_score_v1) / param_change
                score_changes.append(score_change)

        if score_changes:
            avg_impact = np.mean(score_changes)
            sensitivity[param_name] = {
                "avg_impact": round(avg_impact, 3),
                "std_impact": round(np.std(score_changes), 3),
                "importance": "high"
                if abs(avg_impact) > 0.1
                else "medium"
                if abs(avg_impact) > 0.05
                else "low",
            }

    return sensitivity


def analyze_context_features_local(
    opportunities: list[dict], best_params: dict
) -> dict:
    """ã€æœ¬åœ°è®¡ç®—ã€‘ä¸Šä¸‹æ–‡ç‰¹å¾åˆ†æ

    åˆ†æV8.3.21å­—æ®µä¸æˆåŠŸçš„å…³ç³»
    """
    # ä½¿ç”¨æœ€ä¼˜å‚æ•°æ¨¡æ‹Ÿï¼ŒåŒºåˆ†capturedå’Œmissed
    result = simulate_params_with_v8321_filter(opportunities, best_params)
    captured = result.get("captured_details", [])

    if len(captured) == 0:
        return {"error": "æ— æ•è·æœºä¼š"}

    analysis = {}

    # åˆ†æ1ï¼šKçº¿ä¸Šä¸‹æ–‡
    analysis["kline_context"] = analyze_kline_context_impact(captured)

    # åˆ†æ2ï¼šå¸‚åœºç»“æ„
    analysis["market_structure"] = analyze_market_structure_impact(captured)

    # åˆ†æ3ï¼šS/Rå†å²
    analysis["sr_history"] = analyze_sr_history_impact(captured)

    # ç”Ÿæˆå…³é”®æ´å¯Ÿ
    analysis["key_insights"] = generate_insights_from_analysis(analysis)

    return analysis


def analyze_kline_context_impact(captured: list[dict]) -> dict:
    """åˆ†æKçº¿ä¸Šä¸‹æ–‡ä¸æˆåŠŸç‡çš„å…³ç³»"""
    # æŒ‰é˜³çº¿æ¯”ä¾‹åˆ†ç»„
    groups: dict[str, list[dict]] = {"0.6-0.7": [], "0.7-0.8": [], "0.8-1.0": []}

    for opp in captured:
        ratio = opp.get("kline_ctx_bullish_ratio", 0)
        if 0.6 <= ratio < 0.7:
            groups["0.6-0.7"].append(opp)
        elif 0.7 <= ratio < 0.8:
            groups["0.7-0.8"].append(opp)
        elif 0.8 <= ratio <= 1.0:
            groups["0.8-1.0"].append(opp)

    # è®¡ç®—å„ç»„ç»Ÿè®¡
    result = {}
    for range_name, group in groups.items():
        if len(group) > 0:
            profits = [
                get_profit_pct(o) for o in group
            ]  # ã€V8.3.21.1ä¿®å¤ã€‘ä½¿ç”¨è¾…åŠ©å‡½æ•°
            result[range_name] = {
                "count": len(group),
                "avg_profit": round(np.mean(profits), 1),
                "win_rate": round(len([p for p in profits if p > 0]) / len(profits), 2),
            }

    # ç”Ÿæˆç»“è®º
    if result:
        best_range = max(result.keys(), key=lambda k: result[k]["avg_profit"])
        result["conclusion"] = (
            f"é˜³çº¿æ¯”ä¾‹{best_range}æ—¶æ•ˆæœæœ€å¥½ï¼ˆå¹³å‡åˆ©æ¶¦{result[best_range]['avg_profit']:.1f}%ï¼‰"
        )

    return result


def analyze_market_structure_impact(captured: list[dict]) -> dict:
    """åˆ†æå¸‚åœºç»“æ„ä¸æˆåŠŸç‡çš„å…³ç³»"""
    # æŒ‰swingç±»å‹åˆ†ç»„
    groups: dict[str, list[dict]] = {}
    for opp in captured:
        swing_type = opp.get("mkt_struct_swing", "unknown")
        if swing_type not in groups:
            groups[swing_type] = []
        groups[swing_type].append(opp)

    # è®¡ç®—å„ç»„ç»Ÿè®¡
    result = {}
    for swing_type, group in groups.items():
        if len(group) > 0:
            profits = [
                get_profit_pct(o) for o in group
            ]  # ã€V8.3.21.1ä¿®å¤ã€‘ä½¿ç”¨è¾…åŠ©å‡½æ•°
            result[swing_type] = {
                "count": len(group),
                "avg_profit": round(np.mean(profits), 1),
            }

    # ç”Ÿæˆç»“è®º
    if result:
        best_type = max(result.keys(), key=lambda k: result[k]["avg_profit"])
        result["conclusion"] = (
            f"{best_type}ç»“æ„æ•ˆæœæœ€å¥½ï¼ˆå¹³å‡åˆ©æ¶¦{result[best_type]['avg_profit']:.1f}%ï¼‰"
        )

    return result


def analyze_sr_history_impact(captured: list[dict]) -> dict:
    """åˆ†æS/Rå†å²ä¸æˆåŠŸç‡çš„å…³ç³»"""
    # æŒ‰æµ‹è¯•æ¬¡æ•°åˆ†ç»„
    groups: dict[str, list[dict]] = {"1-2æ¬¡": [], "3-5æ¬¡": [], "5æ¬¡+": []}

    for opp in captured:
        test_cnt = (
            opp.get("resist_hist_test_cnt", 0)
            if opp["direction"] == "short"
            else opp.get("support_hist_test_cnt", 0)
        )

        if 1 <= test_cnt <= 2:
            groups["1-2æ¬¡"].append(opp)
        elif 3 <= test_cnt <= 5:
            groups["3-5æ¬¡"].append(opp)
        elif test_cnt > 5:
            groups["5æ¬¡+"].append(opp)

    # è®¡ç®—å„ç»„ç»Ÿè®¡
    result = {}
    for range_name, group in groups.items():
        if len(group) > 0:
            profits = [
                get_profit_pct(o) for o in group
            ]  # ã€V8.3.21.1ä¿®å¤ã€‘ä½¿ç”¨è¾…åŠ©å‡½æ•°
            result[range_name] = {
                "count": len(group),
                "avg_profit": round(np.mean(profits), 1),
            }

    # ç”Ÿæˆç»“è®º
    if result:
        best_range = max(result.keys(), key=lambda k: result[k]["avg_profit"])
        result["conclusion"] = (
            f"S/Ræµ‹è¯•{best_range}æ—¶æ•ˆæœæœ€å¥½ï¼ˆå¹³å‡åˆ©æ¶¦{result[best_range]['avg_profit']:.1f}%ï¼‰"
        )

    return result


def generate_insights_from_analysis(analysis: dict) -> list[str]:
    """ä»åˆ†æä¸­ç”Ÿæˆå…³é”®æ´å¯Ÿ"""
    insights = []

    # Kçº¿ä¸Šä¸‹æ–‡æ´å¯Ÿ
    if "kline_context" in analysis and "conclusion" in analysis["kline_context"]:
        insights.append(f"ğŸ’¡ {analysis['kline_context']['conclusion']}")

    # å¸‚åœºç»“æ„æ´å¯Ÿ
    if "market_structure" in analysis and "conclusion" in analysis["market_structure"]:
        insights.append(f"ğŸ’¡ {analysis['market_structure']['conclusion']}")

    # S/Rå†å²æ´å¯Ÿ
    if "sr_history" in analysis and "conclusion" in analysis["sr_history"]:
        insights.append(f"ğŸ’¡ {analysis['sr_history']['conclusion']}")

    return insights


def detect_anomalies_local(
    all_results: list[dict], param_sensitivity: dict
) -> list[dict]:
    """ã€æœ¬åœ°æ£€æµ‹ã€‘å¼‚å¸¸æƒ…å†µ

    åŸºäºè§„åˆ™æ£€æµ‹å¼‚å¸¸ï¼Œä¸éœ€è¦AI
    """
    anomalies = []

    # å¼‚å¸¸1ï¼šæŸä¸ªå‚æ•°å¯¼è‡´æ•è·ç‡éª¤é™
    for param_name in param_sensitivity:
        # æ‰¾åˆ°è¯¥å‚æ•°çš„æç«¯å€¼
        param_results: dict[float, list[float]] = {}
        for r in all_results:
            pval = r["params"][param_name]
            if pval not in param_results:
                param_results[pval] = []
            param_results[pval].append(r["metrics"].get("capture_rate", 0))

        # è®¡ç®—æ¯ä¸ªå€¼çš„å¹³å‡æ•è·ç‡
        param_avg_capture = {k: np.mean(v) for k, v in param_results.items()}

        # æ£€æµ‹éª¤é™
        values = sorted(param_avg_capture.keys())
        for i in range(len(values) - 1):
            v1, v2 = values[i], values[i + 1]
            drop = param_avg_capture[v2] - param_avg_capture[v1]

            if drop < -0.2:  # ä¸‹é™è¶…è¿‡20%
                anomalies.append({
                    "type": "capture_rate_drop",
                    "param": param_name,
                    "from_value": v1,
                    "to_value": v2,
                    "drop": round(drop, 2),
                    "severity": "high" if drop < -0.3 else "medium",
                    "description": f"{param_name}ä»{v1}â†’{v2}æ—¶ï¼Œæ•è·ç‡ä¸‹é™{abs(drop) * 100:.0f}%",
                })

    # å¼‚å¸¸2ï¼šæ•´ä½“æ•è·ç‡è¿‡ä½
    avg_capture_rate = np.mean([
        r["metrics"].get("capture_rate", 0) for r in all_results
    ])
    if avg_capture_rate < 0.3:
        anomalies.append({
            "type": "low_capture_rate",
            "value": round(avg_capture_rate, 2),
            "severity": "high",
            "description": f"æ•´ä½“æ•è·ç‡è¿‡ä½ï¼ˆ{avg_capture_rate * 100:.0f}%ï¼‰ï¼Œå‚æ•°å¯èƒ½è¿‡ä¸¥",
        })

    return anomalies


# ============================================================
# ã€æ­¥éª¤5ã€‘è¯„åˆ†å‡½æ•°å’Œè¾…åŠ©å‡½æ•°
# ============================================================


def calculate_v8321_optimization_score(result: dict) -> float:
    """ã€V8.5.2å‡çº§ã€‘å¤šç›®æ ‡ä¼˜åŒ–è¯„åˆ†å‡½æ•° - å¹³è¡¡èƒœç‡ã€ç›ˆäºæ¯”ã€åˆ©æ¶¦ã€é£é™©

    æ ¸å¿ƒç›®æ ‡ï¼šæ‰¾åˆ°"èƒœç‡-ç›ˆäºæ¯”-æ€»åˆ©æ¶¦"çš„æœ€ä¼˜æƒè¡¡ç‚¹

    å…³é”®æ”¹è¿›ï¼š
    1. æœŸæœ›æ”¶ç›Šä¸ºæ ¸å¿ƒï¼ˆå·²åŒ…å«èƒœç‡Ã—ç›ˆåˆ©+è´¥ç‡Ã—äºæŸï¼‰
    2. ç›ˆäºæ¯”ç‹¬ç«‹è¯„ä¼°ï¼ˆé¿å…æç«¯é…ç½®ï¼‰
    3. è½¯çº¦æŸæƒ©ç½šï¼ˆè€Œéç¡¬æ€§é˜ˆå€¼ï¼‰
    4. å›æ’¤æ§åˆ¶

    è¯„åˆ†é€»è¾‘ï¼š
    - æœŸæœ›æ”¶ç›Š > 0ï¼šåŸºç¡€åˆ†
    - ç›ˆäºæ¯” â‰¥ 1.5ï¼šåŠ åˆ†ï¼Œ< 1.5ï¼šæ‰£åˆ†
    - èƒœç‡ â‰¥ 30%ï¼šæ­£å¸¸ï¼Œ< 30%ï¼šæ‰£åˆ†
    - æœ€å¤§å›æ’¤ < 20%ï¼šæ­£å¸¸ï¼Œ> 20%ï¼šæ‰£åˆ†
    - æ•è·ç‡ï¼šé€‚å½“åŠ åˆ†

    ç¤ºä¾‹å¯¹æ¯”ï¼š
    - é«˜èƒœç‡ä½ç›ˆäºæ¯”ï¼ˆQwenå‹ï¼‰: èƒœç‡75% + ç›ˆäºæ¯”0.8 â†’ æ‰£åˆ†
    - ä½èƒœç‡é«˜ç›ˆäºæ¯”ï¼ˆDeepSeekå‹ï¼‰: èƒœç‡30% + ç›ˆäºæ¯”0.68 â†’ æ‰£åˆ†
    - å¹³è¡¡é…ç½®: èƒœç‡50% + ç›ˆäºæ¯”2.0 â†’ é«˜åˆ†
    """
    if result["captured_count"] == 0:
        return 0.0

    # æå–æ ¸å¿ƒæŒ‡æ ‡
    result.get("avg_profit", 0)
    win_rate = result.get("win_rate", 0)
    avg_win = result.get("avg_win", 0)
    avg_loss = result.get("avg_loss", 0)
    max_drawdown = result.get("max_drawdown", 0)
    capture_rate = result.get("capture_rate", 0)

    # è®¡ç®—ç›ˆäºæ¯”
    profit_loss_ratio = abs(avg_win / avg_loss) if avg_loss != 0 else 999

    # è®¡ç®—æœŸæœ›æ”¶ç›Š
    expectancy = (win_rate * avg_win) + ((1 - win_rate) * avg_loss)

    # ========================================
    # ã€æ ¸å¿ƒè¯„åˆ†ã€‘æœŸæœ›æ”¶ç›Š
    # ========================================
    if expectancy <= 0:
        # è´ŸæœŸæœ›ï¼Œç»™äºˆæä½åˆ†
        return max(0.01, 0.01 + (expectancy + 5) / 5 * 0.04)

    # æœŸæœ›æ”¶ç›ŠåŸºç¡€åˆ†ï¼ˆ0-100ï¼‰
    expectancy_score = min(100, expectancy * 20)  # 1%æœŸæœ›=20åˆ†ï¼Œ5%æœŸæœ›=100åˆ†

    # ========================================
    # ã€æƒè¡¡è°ƒèŠ‚ã€‘ç›ˆäºæ¯”
    # ========================================
    pl_ratio_penalty = 0  # åˆå§‹åŒ–
    pl_ratio_bonus = 0  # åˆå§‹åŒ–

    if profit_loss_ratio < 1.5:
        # ç›ˆäºæ¯”å¤ªä½ï¼Œæ‰£åˆ†
        pl_ratio_penalty = (1.5 - profit_loss_ratio) * 20  # æ¯ä½0.1æ‰£2åˆ†
    elif profit_loss_ratio >= 2.0:
        # ç›ˆäºæ¯”ä¼˜ç§€ï¼ŒåŠ åˆ†
        pl_ratio_bonus = min(
            20, (profit_loss_ratio - 2.0) * 10
        )  # æ¯é«˜0.1åŠ 1åˆ†ï¼Œæœ€å¤š+20
    # else: ç›ˆäºæ¯”æ­£å¸¸ï¼ˆ1.5-2.0ï¼‰ï¼Œä¿æŒåˆå§‹å€¼0

    # ========================================
    # ã€æƒè¡¡è°ƒèŠ‚ã€‘èƒœç‡
    # ========================================
    if win_rate < 0.30:
        # èƒœç‡å¤ªä½ï¼Œæ‰£åˆ†
        win_rate_penalty = (0.30 - win_rate) * 50  # æ¯ä½1%æ‰£0.5åˆ†
    elif win_rate >= 0.60 and profit_loss_ratio < 1.5:
        # é«˜èƒœç‡ä½†ä½ç›ˆäºæ¯”ï¼ˆè¿‡æ—©æ­¢ç›ˆï¼‰ï¼Œæ‰£åˆ†
        win_rate_penalty = 10  # å›ºå®šæ‰£10åˆ†
    else:
        win_rate_penalty = 0

    # ========================================
    # ã€é£é™©æ§åˆ¶ã€‘æœ€å¤§å›æ’¤
    # ========================================
    if max_drawdown > 0.20:
        # å›æ’¤è¶…è¿‡20%ï¼Œæ‰£åˆ†
        drawdown_penalty = (max_drawdown - 0.20) * 100  # æ¯è¶…1%æ‰£1åˆ†
    else:
        drawdown_penalty = 0

    # ========================================
    # ã€æ•è·ç‡ã€‘åŠ åˆ†
    # ========================================
    capture_bonus = capture_rate * 15  # 100%æ•è·ç‡+15åˆ†

    # ========================================
    # ã€ç»¼åˆå¾—åˆ†ã€‘
    # ========================================
    total_score = (
        expectancy_score  # æœŸæœ›æ”¶ç›Šï¼ˆæ ¸å¿ƒï¼‰
        + pl_ratio_bonus
        - pl_ratio_penalty  # ç›ˆäºæ¯”è°ƒèŠ‚
        + -win_rate_penalty  # èƒœç‡æƒ©ç½š
        + -drawdown_penalty  # å›æ’¤æƒ©ç½š
        + capture_bonus  # æ•è·ç‡åŠ åˆ†
    )

    return max(0, total_score / 100)  # å½’ä¸€åŒ–åˆ°0-1


def extract_key_metrics(result: dict) -> dict:
    """æå–å…³é”®æŒ‡æ ‡ï¼ˆV8.5.2æ‰©å±•ï¼šåŒ…å«ç›ˆäºæ¯”ã€æœŸæœ›æ”¶ç›Šç­‰ï¼‰"""
    return {
        "capture_rate": result.get("capture_rate", 0),
        "avg_profit": result.get("avg_profit", 0),
        "win_rate": result.get("win_rate", 0),
        "time_exit_rate": result.get("time_exit_rate", 0),
        # V8.5.2æ–°å¢ï¼šå¤šç›®æ ‡æƒè¡¡æŒ‡æ ‡
        "avg_win": result.get("avg_win", 0),
        "avg_loss": result.get("avg_loss", 0),
        "profit_loss_ratio": result.get("profit_loss_ratio", 0),
        "expectancy": result.get("expectancy", 0),
        "max_drawdown": result.get("max_drawdown", 0),
    }


def calculate_score_distribution(all_results: list[dict]) -> dict:
    """è®¡ç®—åˆ†æ•°åˆ†å¸ƒ"""
    scores = [r["score"] for r in all_results]
    return {
        "mean": round(np.mean(scores), 3),
        "std": round(np.std(scores), 3),
        "min": round(np.min(scores), 3),
        "max": round(np.max(scores), 3),
        "q25": round(np.percentile(scores, 25), 3),
        "q50": round(np.percentile(scores, 50), 3),
        "q75": round(np.percentile(scores, 75), 3),
    }


def compress_optimization_results(
    top_10: list[dict],
    param_sensitivity: dict,
    context_analysis: dict,
    anomalies: list[dict],
) -> dict:
    """å‹ç¼©ä¼˜åŒ–ç»“æœï¼ˆç”¨äºAIå†³ç­–ï¼‰

    å°†è¯¦ç»†æ•°æ®å‹ç¼©æˆæ‘˜è¦
    """
    return {
        "top_3_configs": [
            {
                "rank": i + 1,
                "score": r["score"],
                "params_summary": format_params_compact(r["params"]),
                "metrics": r["metrics"],
            }
            for i, r in enumerate(top_10[:3])
        ],
        "param_sensitivity_summary": {
            k: v
            for k, v in sorted(
                param_sensitivity.items(),
                key=lambda x: abs(x[1]["avg_impact"]),
                reverse=True,
            )[:5]  # åªä¿ç•™Top 5
        },
        "context_insights": context_analysis.get("key_insights", []),
        "anomalies_summary": [
            {
                "type": a["type"],
                "severity": a["severity"],
                "description": a["description"],
            }
            for a in anomalies[:3]  # åªä¿ç•™Top 3
        ],
    }


def format_params_compact(params: dict) -> str:
    """ç´§å‡‘æ ¼å¼åŒ–å‚æ•°"""
    return ", ".join([f"{k}={v}" for k, v in list(params.items())[:3]]) + "..."


def estimate_token_count(data: dict) -> int:
    """ä¼°ç®—tokenæ•°é‡"""
    import json

    json_str = json.dumps(data)
    # ç²—ç•¥ä¼°ç®—ï¼šæ¯4ä¸ªå­—ç¬¦â‰ˆ1 token
    return len(json_str) // 4


# ============================================================
# ä¸»å‡½æ•°ç¤ºä¾‹
# ============================================================

# ============================================================
# ã€AIè¿­ä»£å†³ç­–å±‚ã€‘è‹±æ–‡é€šä¿¡ï¼Œç”¨äºå¤šè½®ä¼˜åŒ–
# ============================================================


def call_ai_for_iterative_optimization(
    top_10_configs: list[dict],
    param_sensitivity: dict,
    context_analysis: dict,
    anomalies: list[dict],
    compressed_data: dict,
    signal_type: str,
) -> dict:
    """ã€V8.3.21 AIè¿­ä»£ã€‘Call AI for iterative parameter optimization

    Communication: English (efficient for AI)
    Output: English (internal use only, translated to Chinese for users)

    Args:
        top_10_configs: Top 10 parameter configurations from Grid Search
        param_sensitivity: Parameter sensitivity analysis
        context_analysis: Market context analysis
        anomalies: Detected anomalies
        compressed_data: Compressed optimization data
        signal_type: 'scalping' or 'swing'

    Returns:
        AI decision dict (English)

    """
    # æ„å»ºè‹±æ–‡Prompt
    prompt = build_ai_optimization_prompt_en(
        top_10_configs=top_10_configs,
        param_sensitivity=param_sensitivity,
        context_analysis=context_analysis,
        anomalies=anomalies,
        signal_type=signal_type,
    )

    # è°ƒç”¨AIï¼ˆè‹±æ–‡é€šä¿¡ï¼‰
    ai_response = call_deepseek_for_optimization(prompt)

    # è§£æAIå“åº”ï¼ˆè‹±æ–‡ï¼‰
    ai_decision = parse_ai_optimization_response(ai_response)

    # è½¬æ¢å…³é”®æ´å¯Ÿä¸ºä¸­æ–‡ï¼ˆç»™ç”¨æˆ·çœ‹ï¼‰
    if ai_decision:
        ai_decision["key_insights_zh"] = translate_insights_to_chinese(
            ai_decision.get("key_insights_en", [])
        )

    return ai_decision


def build_ai_optimization_prompt_en(
    top_10_configs: list[dict],
    param_sensitivity: dict,
    context_analysis: dict,
    anomalies: list[dict],
    signal_type: str,
) -> str:
    """ã€V8.5.2å‡çº§ã€‘Build AI prompt with win rate - P/L ratio trade-off analysis

    å±•ç¤ºTop 10é…ç½®çš„æƒè¡¡å…³ç³»ï¼Œè®©AIé€‰æ‹©æœ€ä¼˜å¹³è¡¡ç‚¹
    """
    # ã€V8.5.2ã€‘Format Top 10 configs with trade-off table
    top_10_table = "\n| Rank | Score | Win Rate | P/L Ratio | Avg Win | Avg Loss | Expectancy | Capture | Max DD |\n"
    top_10_table += "|------|-------|----------|-----------|---------|----------|------------|---------|--------|\n"

    for i, config in enumerate(top_10_configs[:10], 1):
        m = config["metrics"]
        win_rate = m.get("win_rate", 0) * 100
        pl_ratio = m.get("profit_loss_ratio", 0)
        avg_win = m.get("avg_win", 0)
        avg_loss = m.get("avg_loss", 0)
        expectancy = m.get("expectancy", 0)
        capture = m.get("capture_rate", 0) * 100
        max_dd = m.get("max_drawdown", 0) * 100

        top_10_table += f"| {i:2d}   | {config['score']:.3f} | {win_rate:5.1f}% | {pl_ratio:5.2f}:1 | {avg_win:+5.2f}% | {avg_loss:5.2f}% | {expectancy:+5.2f}% | {capture:5.1f}% | {max_dd:4.1f}% |\n"

    # Format Top 3 configs (detail view)
    top_3_str = ""
    for i, config in enumerate(top_10_configs[:3], 1):
        top_3_str += f"\nRank {i}:\n"
        top_3_str += f"  Score: {config['score']:.3f}\n"
        m = config["metrics"]
        top_3_str += f"  Win Rate: {m.get('win_rate', 0) * 100:.1f}%\n"
        top_3_str += f"  P/L Ratio: {m.get('profit_loss_ratio', 0):.2f}:1\n"
        top_3_str += f"  Expectancy: {m.get('expectancy', 0):+.2f}%\n"
        top_3_str += f"  Capture Rate: {m.get('capture_rate', 0) * 100:.0f}%\n"
        top_3_str += f"  Avg Profit: {m.get('avg_profit', 0):.1f}%\n"
        # Show key params (including TP/SL)
        params = config["params"]
        top_3_str += f"  Key Params: signalâ‰¥{params.get('min_signal_score', 60)}, "
        top_3_str += f"consensusâ‰¥{params.get('min_consensus', 3)}, "
        top_3_str += f"RRâ‰¥{params.get('min_risk_reward', 2.0):.1f}, "
        top_3_str += f"TP={params.get('atr_tp_multiplier', 4.0):.1f}Ã—ATR, "
        top_3_str += f"SL={params.get('atr_stop_multiplier', 1.5):.1f}Ã—ATR\n"

    # Format parameter sensitivity (Top 3)
    sensitivity_str = ""
    sorted_params = sorted(
        param_sensitivity.items(), key=lambda x: abs(x[1]["avg_impact"]), reverse=True
    )[:3]
    for param_name, sensitivity in sorted_params:
        sensitivity_str += f"\n  â€¢ {param_name}: {sensitivity['importance']} importance"
        sensitivity_str += f" (impact={sensitivity['avg_impact']:+.3f})"

    # Format context insights
    insights_str = "\n".join([
        f"  â€¢ {insight}" for insight in context_analysis.get("key_insights", [])[:3]
    ])

    # Format anomalies
    anomalies_str = ""
    for anomaly in anomalies[:2]:
        anomalies_str += f"\n  â€¢ {anomaly.get('type', 'unknown')}: {anomaly.get('description', 'N/A')}"

    # ã€V8.5.2ã€‘Construct enhanced prompt with trade-off analysis
    prompt = f"""You are an expert in trading parameter optimization. 

Your task: Analyze the trade-off between win rate, profit/loss ratio, and total profit to find the optimal balance.

Signal Type: {signal_type.upper()}

=== Trade-Off Analysis (Top 10 Configurations) ===
{top_10_table}

**Key Patterns to Identify:**
- High win rate + Low P/L ratio â†’ Early exits (leaving money on table)
- Low win rate + High P/L ratio â†’ Getting stopped out too often
- Balanced configs â†’ Optimal expectancy

=== Detailed View (Top 3) ===
{top_3_str}

=== Parameter Sensitivity ===
{sensitivity_str}

=== Market Context ===
{insights_str}

=== Anomalies ===
{anomalies_str if anomalies_str else "  None"}

=== Your Task ===

1. **Identify the optimal trade-off:**
   - Which rank has the best balance between win rate and P/L ratio?
   - Is expectancy maximized? (Expectancy = Win Rate Ã— Avg Win + Loss Rate Ã— Avg Loss)
   - Are there red flags? (e.g., Win Rate > 60% but P/L < 1.5 = early exits)

2. **Adjust TP/SL if needed:**
   - If P/L ratio < 1.5 â†’ Consider increasing TP multiplier
   - If win rate < 30% â†’ Consider decreasing SL multiplier or increasing TP
   - If max drawdown > 20% â†’ Consider tighter risk controls

3. **Select the best configuration:**
   - Rank 1 may not be optimal if it has extreme trade-offs
   - Consider Rank 2-10 if they have better balance

Please respond in JSON format:

{{
    "needs_adjustment": true/false,
    "selected_rank": 1,  // 1-10
    "param_adjustments": {{
        // Only specify params that need adjustment
        // Available: "atr_tp_multiplier", "atr_stop_multiplier", "min_signal_score", etc.
        // Example: "atr_tp_multiplier": 4.5
    }},
    "reasoning_en": "Why this configuration achieves the best trade-off between win rate, P/L ratio, and expectancy",
    "trade_off_analysis": "Explain the trade-off pattern observed (e.g., 'Rank 1 has high win rate but low P/L ratio due to early exits')",
    "key_insights_en": [
        "Insight about win rate pattern",
        "Insight about P/L ratio optimization"
    ],
    "expected_improvement": {{
        "win_rate": "â†‘/â†“/â†’",
        "pl_ratio": "â†‘/â†“/â†’",
        "expectancy": "+X%"
    }}
}}

Respond with ONLY the JSON, no additional text."""

    return prompt


def call_deepseek_for_optimization(prompt: str) -> str | None:
    """Call DeepSeek API for optimization decision

    Uses existing call_deepseek function from main file
    """
    try:
        # å°è¯•å¯¼å…¥ä¸»æ–‡ä»¶çš„call_deepseekå‡½æ•°
        import os
        import sys

        sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

        # åŠ¨æ€å¯¼å…¥ï¼ˆé¿å…å¾ªç¯ä¾èµ–ï¼‰
        import importlib.util

        spec = importlib.util.spec_from_file_location("main", "qwen_å¤šå¸ç§æ™ºèƒ½ç‰ˆ.py")
        if spec and spec.loader:
            main_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(main_module)

            if hasattr(main_module, "call_deepseek"):
                response = main_module.call_deepseek(
                    prompt=prompt, max_tokens=500, temperature=0.3
                )
                return response

        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œè¿”å›Noneï¼ˆè·³è¿‡AIå†³ç­–ï¼‰
        return None

    except Exception as e:
        print(f"âš ï¸  AI APIè°ƒç”¨å¤±è´¥: {e}")
        return None


def parse_ai_optimization_response(ai_response: str | None) -> dict | None:
    """Parse AI response (JSON format)

    Returns English decision dict
    """
    if not ai_response:
        return None

    try:
        import json
        import re

        # æå–JSONï¼ˆAIå¯èƒ½ä¼šè¿”å›é¢å¤–çš„æ–‡å­—ï¼‰
        json_match = re.search(r"\{.*\}", ai_response, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            decision = json.loads(json_str)
            return decision
        return None

    except Exception as e:
        print(f"âš ï¸  AIå“åº”è§£æå¤±è´¥: {e}")
        return None


def apply_ai_adjustments(base_params: dict, adjustments: dict) -> dict:
    """Apply AI-suggested parameter adjustments

    Args:
        base_params: Base parameter configuration
        adjustments: AI-suggested adjustments (can be partial)

    Returns:
        Adjusted parameters

    """
    adjusted = base_params.copy()

    # åº”ç”¨AIå»ºè®®çš„è°ƒæ•´
    for param_name, new_value in adjustments.items():
        if param_name in adjusted:
            adjusted[param_name] = new_value

    return adjusted


def translate_insights_to_chinese(insights_en: list[str]) -> list[str]:
    """Translate English insights to Chinese for user display

    Simple keyword-based translation for common patterns
    """
    insights_zh = []

    for insight in insights_en:
        # ç®€å•çš„å…³é”®è¯ç¿»è¯‘ï¼ˆå¯ä»¥æ‰©å±•ï¼‰
        insight_zh = insight

        # å¸¸è§æ¨¡å¼ç¿»è¯‘
        replacements = {
            "bullish ratio": "é˜³çº¿æ¯”ä¾‹",
            "best performance": "æ•ˆæœæœ€å¥½",
            "average profit": "å¹³å‡åˆ©æ¶¦",
            "HH-HL structure": "HH-HLç»“æ„",
            "LL-LH structure": "LL-LHç»“æ„",
            "support/resistance": "æ”¯æ’‘/é˜»åŠ›",
            "test": "æµ‹è¯•",
            "times": "æ¬¡",
            "when": "æ—¶",
            "Rank 1 is optimal": "Top 1é…ç½®æœ€ä¼˜",
            "No adjustment needed": "æ— éœ€è°ƒæ•´",
            "Micro-adjust": "å¾®è°ƒ",
            "Market volatility": "å¸‚åœºæ³¢åŠ¨",
            "Risk": "é£é™©",
        }

        for en, zh in replacements.items():
            insight_zh = insight_zh.replace(en, zh)

        insights_zh.append(f"ğŸ’¡ {insight_zh}")

    return insights_zh


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

if __name__ == "__main__":
    print("V8.3.21å›æµ‹ä¼˜åŒ–æ¨¡å—ï¼ˆå«AIè¿­ä»£ï¼‰")
    print("ä½¿ç”¨æ–¹æ³•ï¼šä»ä¸»ç¨‹åºå¯¼å…¥ optimize_params_v8321_lightweight")
