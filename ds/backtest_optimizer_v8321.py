#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã€V8.3.21ã€‘å›æµ‹ä¼˜åŒ–æ¨¡å— - è½»é‡çº§ã€æˆæœ¬ä¼˜åŒ–ã€èµ„æºæ§åˆ¶

ç‰¹æ€§ï¼š
1. å¤šç»´åº¦Grid Searchï¼ˆ11ä¸ªå‚æ•°ç»´åº¦ï¼‰
2. V8.3.21ä¸Šä¸‹æ–‡è¿‡æ»¤ï¼ˆKçº¿/å¸‚åœºç»“æ„/S/Rå†å²ï¼‰
3. æœ¬åœ°ç»Ÿè®¡åˆ†æï¼ˆå‚æ•°æ•æ„Ÿåº¦ã€å¼‚å¸¸æ£€æµ‹ï¼‰
4. æˆæœ¬ä¼˜åŒ–çš„AIå†³ç­–ï¼ˆå‹ç¼©æ•°æ®ã€ç²¾ç®€Promptï¼‰
5. èµ„æºæ§åˆ¶ï¼ˆé™åˆ¶å†…å­˜ã€CPU niceå€¼ã€è¿›ç¨‹éš”ç¦»ï¼‰

é€‚ç”¨ç¯å¢ƒï¼š2æ ¸2GæœåŠ¡å™¨
"""

import os
import gc
import psutil
import random
import numpy as np
from typing import Dict, List, Tuple, Any
from datetime import datetime


# ============================================================
# ã€æ­¥éª¤2ã€‘è½»é‡çº§Grid Searchï¼ˆèµ„æºæ§åˆ¶ï¼‰
# ============================================================

def optimize_params_v8321_lightweight(opportunities: List[Dict], 
                                      current_params: Dict, 
                                      signal_type: str = 'scalping',
                                      max_combinations: int = 200) -> Dict:
    """
    ã€V8.3.21ã€‘è½»é‡çº§å‚æ•°ä¼˜åŒ–
    
    è®¾è®¡ï¼š
    - 2æ ¸CPUï¼šä½¿ç”¨éšæœºé‡‡æ ·ä»£æ›¿éå†ï¼ˆ200ç»„ vs 2592ç»„ï¼‰
    - 2Gå†…å­˜ï¼šåŠæ—¶é‡Šæ”¾å†…å­˜ï¼Œæ¯10ç»„GCä¸€æ¬¡
    - è¿›ç¨‹éš”ç¦»ï¼šè®¾ç½®niceå€¼ï¼Œé¿å…å½±å“å®æ—¶AI
    
    Args:
        opportunities: æœºä¼šåˆ—è¡¨ï¼ˆå·²åŒ…å«V8.3.21å­—æ®µï¼‰
        current_params: å½“å‰å‚æ•°
        signal_type: 'scalping' or 'swing'
        max_combinations: æœ€å¤§æµ‹è¯•ç»„æ•°ï¼ˆé»˜è®¤200ï¼‰
    
    Returns:
        {
            'optimized_params': {...},
            'top_10_configs': [...],
            'statistics': {...},
            'cost_saved': 0.xx
        }
    """
    # è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§ï¼ˆniceå€¼=10ï¼Œé¿å…å½±å“å®æ—¶AIï¼‰
    try:
        os.nice(10)
        print(f"   â„¹ï¸  å·²è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§ï¼ˆnice=10ï¼‰ï¼Œé¿å…å½±å“å®æ—¶AI")
    except:
        pass
    
    print(f"\n{'='*60}")
    print(f"ã€V8.3.21å›æµ‹ä¼˜åŒ–ã€‘è½»é‡çº§å‚æ•°æœç´¢ï¼ˆ{signal_type}ï¼‰")
    print(f"  æœºä¼šæ•°: {len(opportunities)}")
    print(f"  æµ‹è¯•ç»„æ•°: {max_combinations}")
    print(f"  å†…å­˜é™åˆ¶: æ£€æµ‹åˆ°{psutil.virtual_memory().total / (1024**3):.1f}Gï¼Œå°†ä¸»åŠ¨æ§åˆ¶")
    print(f"{'='*60}\n")
    
    # ===== é˜¶æ®µ1ï¼šå®šä¹‰æœç´¢ç©ºé—´ =====
    print("ğŸ“Š é˜¶æ®µ1: å®šä¹‰æœç´¢ç©ºé—´...")
    
    param_grid = define_param_grid_v8321(signal_type)
    total_combinations = calculate_total_combinations(param_grid)
    
    print(f"   âœ… æœç´¢ç©ºé—´å®šä¹‰å®Œæˆ")
    print(f"      ç†è®ºç»„åˆæ•°: {total_combinations}ç»„")
    print(f"      å®é™…æµ‹è¯•æ•°: {max_combinations}ç»„ï¼ˆéšæœºé‡‡æ ·ï¼‰")
    
    # ===== é˜¶æ®µ2ï¼šéšæœºé‡‡æ ·Grid Search =====
    print(f"\nğŸ” é˜¶æ®µ2: éšæœºé‡‡æ ·Grid Search...")
    
    sampled_params = random_sample_param_grid(param_grid, max_combinations)
    all_results = []
    
    for i, params in enumerate(sampled_params):
        # å†…å­˜æ£€æŸ¥ï¼ˆæ¯10ç»„æ£€æŸ¥ä¸€æ¬¡ï¼‰
        if i % 10 == 0:
            mem_usage = psutil.Process().memory_info().rss / (1024**2)
            if mem_usage > 300:  # è¶…è¿‡300MBåˆ™GC
                gc.collect()
                print(f"      [{i}/{max_combinations}] å†…å­˜: {mem_usage:.0f}MB â†’ GC")
        
        # æ¨¡æ‹Ÿè¿™ä¸ªå‚æ•°é…ç½®
        result = simulate_params_with_v8321_filter(opportunities, params)
        score = calculate_v8321_optimization_score(result)
        
        all_results.append({
            'params': params,
            'score': score,
            'metrics': extract_key_metrics(result)
        })
        
        # è¿›åº¦æ˜¾ç¤º
        if (i + 1) % 20 == 0:
            print(f"      è¿›åº¦: {i+1}/{max_combinations}...")
    
    # æ’åºå¹¶å–Top 10
    top_10 = sorted(all_results, key=lambda x: x['score'], reverse=True)[:10]
    
    print(f"   âœ… Grid Searchå®Œæˆ")
    print(f"      æœ€é«˜åˆ†: {top_10[0]['score']:.3f}")
    print(f"      æµ‹è¯•ç»„æ•°: {len(all_results)}")
    
    # ä¸»åŠ¨GC
    gc.collect()
    
    # ===== é˜¶æ®µ3ï¼šæœ¬åœ°ç»Ÿè®¡åˆ†æ =====
    print(f"\nğŸ“ˆ é˜¶æ®µ3: æœ¬åœ°ç»Ÿè®¡åˆ†æï¼ˆå…è´¹ï¼‰...")
    
    # æœ¬åœ°è®¡ç®—ï¼šå‚æ•°æ•æ„Ÿåº¦
    param_sensitivity = calculate_param_sensitivity_local(all_results)
    
    # æœ¬åœ°è®¡ç®—ï¼šä¸Šä¸‹æ–‡ç‰¹å¾ç›¸å…³æ€§
    context_analysis = analyze_context_features_local(opportunities, top_10[0]['params'])
    
    # æœ¬åœ°æ£€æµ‹ï¼šå¼‚å¸¸æƒ…å†µ
    anomalies = detect_anomalies_local(all_results, param_sensitivity)
    
    print(f"   âœ… ç»Ÿè®¡åˆ†æå®Œæˆ")
    print(f"      å…³é”®å‚æ•°: {list(param_sensitivity.keys())[:3]}")
    print(f"      å¼‚å¸¸æ£€æµ‹: {len(anomalies)}ä¸ª")
    
    # ===== é˜¶æ®µ4ï¼šæ•°æ®å‹ç¼© =====
    print(f"\nğŸ—œï¸  é˜¶æ®µ4: æ•°æ®å‹ç¼©ï¼ˆèŠ‚çœAIæˆæœ¬ï¼‰...")
    
    compressed_data = compress_optimization_results(
        top_10=top_10,
        param_sensitivity=param_sensitivity,
        context_analysis=context_analysis,
        anomalies=anomalies
    )
    
    estimated_tokens = estimate_token_count(compressed_data)
    original_tokens = len(all_results) * 100  # å‡è®¾åŸå§‹æ¯ç»„100 tokens
    cost_saved = (original_tokens - estimated_tokens) * 0.00002  # GPT-4ä»·æ ¼
    
    print(f"   âœ… æ•°æ®å‹ç¼©å®Œæˆ")
    print(f"      åŸå§‹: ~{original_tokens} tokens")
    print(f"      å‹ç¼©å: ~{estimated_tokens} tokens")
    print(f"      ğŸ’° é¢„è®¡èŠ‚çœ: ${cost_saved:.4f}")
    
    return {
        'optimized_params': top_10[0]['params'],
        'top_10_configs': top_10,
        'statistics': {
            'param_sensitivity': param_sensitivity,
            'score_distribution': calculate_score_distribution(all_results)
        },
        'context_analysis': context_analysis,
        'anomalies': anomalies,
        'compressed_data': compressed_data,
        'cost_saved': cost_saved
    }


def define_param_grid_v8321(signal_type: str) -> Dict:
    """
    å®šä¹‰V8.3.21å‚æ•°æœç´¢ç©ºé—´
    
    åŒ…å«ï¼š
    - åŸºç¡€å‚æ•°ï¼ˆ4ä¸ªï¼‰
    - V8.3.21ä¸Šä¸‹æ–‡è¿‡æ»¤å‚æ•°ï¼ˆ7ä¸ªï¼‰
    """
    if signal_type == 'scalping':
        grid = {
            # åŸºç¡€å‚æ•°
            'max_holding_hours': [1, 2, 4],
            'atr_tp_multiplier': [2.0, 3.0, 4.0],
            'atr_stop_multiplier': [1.5, 2.0],
            'min_risk_reward': [1.5, 2.0, 2.5],
            
            # V8.3.21æ–°å¢ï¼šå…¥åœºè¿‡æ»¤å‚æ•°
            'min_signal_score': [50, 60, 70],
            'min_consensus': [2, 3, 4],
            'min_kline_bullish_ratio': [0.6, 0.7],
            'min_price_chg_pct': [0.5, 1.0, 1.5],
            'allowed_mkt_struct': ['all', 'trend_only'],
            'min_trend_age_hours': [0.5, 1.0],
            'max_sr_test_count': [5, 999]
        }
    else:  # swing
        grid = {
            # åŸºç¡€å‚æ•°
            'max_holding_hours': [48, 60, 72],
            'atr_tp_multiplier': [2.0, 3.0, 4.0],
            'atr_stop_multiplier': [1.5, 2.0],
            'min_risk_reward': [1.5, 2.0, 2.5],
            
            # V8.3.21æ–°å¢ï¼šå…¥åœºè¿‡æ»¤å‚æ•°
            'min_signal_score': [50, 60, 70],
            'min_consensus': [2, 3, 4],
            'min_kline_bullish_ratio': [0.6, 0.7],
            'min_price_chg_pct': [0.5, 1.0, 1.5],
            'allowed_mkt_struct': ['all', 'trend_only'],
            'min_trend_age_hours': [1.0, 2.0],
            'max_sr_test_count': [5, 999]
        }
    
    return grid


def random_sample_param_grid(grid: Dict, sample_size: int) -> List[Dict]:
    """
    éšæœºé‡‡æ ·å‚æ•°ç»„åˆ
    
    é¿å…éå†æ‰€æœ‰ç»„åˆï¼ˆ2592ç»„â†’200ç»„ï¼‰
    """
    samples = []
    
    # è·å–æ‰€æœ‰å‚æ•°åå’Œå–å€¼
    param_names = list(grid.keys())
    param_values = [grid[name] for name in param_names]
    
    # ç”Ÿæˆæ‰€æœ‰ç»„åˆçš„ç´¢å¼•
    from itertools import product
    all_indices = list(product(*[range(len(vals)) for vals in param_values]))
    
    # éšæœºé‡‡æ ·
    sampled_indices = random.sample(all_indices, min(sample_size, len(all_indices)))
    
    # æ„å»ºå‚æ•°å­—å…¸
    for indices in sampled_indices:
        params = {
            param_names[i]: param_values[i][indices[i]]
            for i in range(len(param_names))
        }
        samples.append(params)
    
    return samples


def calculate_total_combinations(grid: Dict) -> int:
    """è®¡ç®—æ€»ç»„åˆæ•°"""
    total = 1
    for values in grid.values():
        total *= len(values)
    return total


# ============================================================
# ã€æ­¥éª¤3ã€‘V8.3.21ä¸Šä¸‹æ–‡è¿‡æ»¤å‡½æ•°
# ============================================================

def simulate_params_with_v8321_filter(opportunities: List[Dict], params: Dict) -> Dict:
    """
    ã€V8.3.21ã€‘ä½¿ç”¨ä¸Šä¸‹æ–‡è¿‡æ»¤å‚æ•°æ¨¡æ‹Ÿäº¤æ˜“
    
    è¿‡æ»¤å±‚æ¬¡ï¼š
    1. åŸºç¡€è¿‡æ»¤ï¼ˆsignal_score/consensus/risk_rewardï¼‰
    2. Kçº¿ä¸Šä¸‹æ–‡è¿‡æ»¤ï¼ˆé˜³çº¿æ¯”ä¾‹ã€ä»·æ ¼å˜åŒ–ï¼‰
    3. å¸‚åœºç»“æ„è¿‡æ»¤ï¼ˆswingç±»å‹ã€è¶‹åŠ¿å¹´é¾„ï¼‰
    4. S/Rå†å²è¿‡æ»¤ï¼ˆæµ‹è¯•æ¬¡æ•°ã€å‡çªç ´ï¼‰
    """
    captured = []
    missed_reasons = {}
    
    for opp in opportunities:
        # ç¬¬1å±‚ï¼šåŸºç¡€è¿‡æ»¤
        if not passes_basic_filter(opp, params):
            reason = 'basic_params'
            missed_reasons[reason] = missed_reasons.get(reason, 0) + 1
            continue
        
        # ç¬¬2å±‚ï¼šKçº¿ä¸Šä¸‹æ–‡è¿‡æ»¤
        if not passes_kline_context_filter(opp, params):
            reason = 'kline_context'
            missed_reasons[reason] = missed_reasons.get(reason, 0) + 1
            continue
        
        # ç¬¬3å±‚ï¼šå¸‚åœºç»“æ„è¿‡æ»¤
        if not passes_market_structure_filter(opp, params):
            reason = 'market_structure'
            missed_reasons[reason] = missed_reasons.get(reason, 0) + 1
            continue
        
        # ç¬¬4å±‚ï¼šS/Rå†å²è¿‡æ»¤
        if not passes_sr_history_filter(opp, params):
            reason = 'sr_history'
            missed_reasons[reason] = missed_reasons.get(reason, 0) + 1
            continue
        
        # é€šè¿‡æ‰€æœ‰è¿‡æ»¤ï¼Œè®°å½•
        captured.append(opp)
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if len(captured) == 0:
        return {
            'total_opportunities': len(opportunities),
            'captured_count': 0,
            'capture_rate': 0,
            'avg_profit': 0,
            'win_rate': 0,
            'time_exit_rate': 0,
            'missed_reasons': missed_reasons
        }
    
    # è®¡ç®—åˆ©æ¶¦ï¼ˆä½¿ç”¨actual_profit_pctä½œä¸ºæ¨¡æ‹Ÿåˆ©æ¶¦ï¼‰
    profits = [c['actual_profit_pct'] for c in captured]
    avg_profit = np.mean(profits)
    win_rate = len([p for p in profits if p > 0]) / len(profits)
    
    return {
        'total_opportunities': len(opportunities),
        'captured_count': len(captured),
        'capture_rate': len(captured) / len(opportunities),
        'avg_profit': avg_profit,
        'win_rate': win_rate,
        'time_exit_rate': 0.5,  # ç®€åŒ–ï¼šå‡è®¾50% time_exit
        'missed_reasons': missed_reasons,
        'captured_details': captured  # è¯¦ç»†æ•°æ®ï¼ˆç”¨äºè¿›ä¸€æ­¥åˆ†æï¼‰
    }


def passes_basic_filter(opp: Dict, params: Dict) -> bool:
    """åŸºç¡€å‚æ•°è¿‡æ»¤"""
    return (
        opp['signal_score'] >= params.get('min_signal_score', 50) and
        opp['consensus'] >= params.get('min_consensus', 2) and
        opp['risk_reward'] >= params.get('min_risk_reward', 1.5)
    )


def passes_kline_context_filter(opp: Dict, params: Dict) -> bool:
    """Kçº¿ä¸Šä¸‹æ–‡è¿‡æ»¤"""
    # æ£€æŸ¥é˜³çº¿/é˜´çº¿æ¯”ä¾‹
    bullish_ratio = opp.get('kline_ctx_bullish_ratio', 0)
    min_ratio = params.get('min_kline_bullish_ratio', 0.6)
    
    if opp['direction'] == 'long':
        if bullish_ratio < min_ratio:
            return False
    else:  # short
        if (1 - bullish_ratio) < min_ratio:
            return False
    
    # æ£€æŸ¥ä»·æ ¼å˜åŒ–å¹…åº¦
    price_chg = abs(opp.get('kline_ctx_price_chg_pct', 0))
    if price_chg < params.get('min_price_chg_pct', 0.5):
        return False
    
    return True


def passes_market_structure_filter(opp: Dict, params: Dict) -> bool:
    """å¸‚åœºç»“æ„è¿‡æ»¤"""
    # æ£€æŸ¥æ˜¯å¦åªåšè¶‹åŠ¿å¸‚åœº
    if params.get('allowed_mkt_struct') == 'trend_only':
        swing_type = opp.get('mkt_struct_swing', '')
        if swing_type not in ['HH-HL', 'LL-LH']:
            return False
    
    # æ£€æŸ¥è¶‹åŠ¿å¹´é¾„
    trend_age = opp.get('mkt_struct_age_hours', 0)
    min_age = params.get('min_trend_age_hours', 0.5)
    if trend_age < min_age:
        return False
    
    return True


def passes_sr_history_filter(opp: Dict, params: Dict) -> bool:
    """S/Rå†å²è¿‡æ»¤"""
    # æ ¹æ®æ–¹å‘é€‰æ‹©å¯¹åº”çš„S/R
    if opp['direction'] == 'long':
        test_cnt = opp.get('support_hist_test_cnt', 0)
        false_bd = opp.get('support_hist_false_bd', 0)
    else:
        test_cnt = opp.get('resist_hist_test_cnt', 0)
        false_bd = opp.get('resist_hist_false_bo', 0)
    
    # æ£€æŸ¥æµ‹è¯•æ¬¡æ•°
    max_test = params.get('max_sr_test_count', 999)
    if test_cnt > max_test:
        return False
    
    # æ£€æŸ¥å‡çªç ´ï¼ˆå›ºå®šâ‰¤2æ¬¡ï¼‰
    if false_bd > 2:
        return False
    
    return True


# ============================================================
# ã€æ­¥éª¤4ã€‘æœ¬åœ°ç»Ÿè®¡åˆ†æå‡½æ•°
# ============================================================

def calculate_param_sensitivity_local(all_results: List[Dict]) -> Dict:
    """
    ã€æœ¬åœ°è®¡ç®—ã€‘å‚æ•°æ•æ„Ÿåº¦åˆ†æ
    
    è®¡ç®—æ¯ä¸ªå‚æ•°å˜åŒ–æ—¶ï¼Œscoreçš„å¹³å‡å˜åŒ–é‡
    """
    sensitivity = {}
    
    # æŒ‰å‚æ•°åˆ†ç»„
    param_names = list(all_results[0]['params'].keys())
    
    for param_name in param_names:
        # è·å–è¯¥å‚æ•°çš„æ‰€æœ‰å–å€¼
        param_values = sorted(set([r['params'][param_name] for r in all_results]))
        
        if len(param_values) < 2:
            continue
        
        # è®¡ç®—ç›¸é‚»å–å€¼ä¹‹é—´çš„scoreå˜åŒ–
        score_changes = []
        for i in range(len(param_values) - 1):
            v1, v2 = param_values[i], param_values[i+1]
            
            # æ‰¾åˆ°è¯¥å‚æ•°=v1å’Œv2çš„ç»“æœ
            results_v1 = [r for r in all_results if r['params'][param_name] == v1]
            results_v2 = [r for r in all_results if r['params'][param_name] == v2]
            
            if results_v1 and results_v2:
                avg_score_v1 = np.mean([r['score'] for r in results_v1])
                avg_score_v2 = np.mean([r['score'] for r in results_v2])
                
                # è®¡ç®—å•ä½å˜åŒ–çš„å½±å“
                param_change = abs(v2 - v1) if isinstance(v1, (int, float)) else 1
                score_change = (avg_score_v2 - avg_score_v1) / param_change
                score_changes.append(score_change)
        
        if score_changes:
            avg_impact = np.mean(score_changes)
            sensitivity[param_name] = {
                'avg_impact': round(avg_impact, 3),
                'std_impact': round(np.std(score_changes), 3),
                'importance': 'high' if abs(avg_impact) > 0.1 else 'medium' if abs(avg_impact) > 0.05 else 'low'
            }
    
    return sensitivity


def analyze_context_features_local(opportunities: List[Dict], best_params: Dict) -> Dict:
    """
    ã€æœ¬åœ°è®¡ç®—ã€‘ä¸Šä¸‹æ–‡ç‰¹å¾åˆ†æ
    
    åˆ†æV8.3.21å­—æ®µä¸æˆåŠŸçš„å…³ç³»
    """
    # ä½¿ç”¨æœ€ä¼˜å‚æ•°æ¨¡æ‹Ÿï¼ŒåŒºåˆ†capturedå’Œmissed
    result = simulate_params_with_v8321_filter(opportunities, best_params)
    captured = result.get('captured_details', [])
    
    if len(captured) == 0:
        return {'error': 'æ— æ•è·æœºä¼š'}
    
    analysis = {}
    
    # åˆ†æ1ï¼šKçº¿ä¸Šä¸‹æ–‡
    analysis['kline_context'] = analyze_kline_context_impact(captured)
    
    # åˆ†æ2ï¼šå¸‚åœºç»“æ„
    analysis['market_structure'] = analyze_market_structure_impact(captured)
    
    # åˆ†æ3ï¼šS/Rå†å²
    analysis['sr_history'] = analyze_sr_history_impact(captured)
    
    # ç”Ÿæˆå…³é”®æ´å¯Ÿ
    analysis['key_insights'] = generate_insights_from_analysis(analysis)
    
    return analysis


def analyze_kline_context_impact(captured: List[Dict]) -> Dict:
    """åˆ†æKçº¿ä¸Šä¸‹æ–‡ä¸æˆåŠŸç‡çš„å…³ç³»"""
    # æŒ‰é˜³çº¿æ¯”ä¾‹åˆ†ç»„
    groups = {
        '0.6-0.7': [],
        '0.7-0.8': [],
        '0.8-1.0': []
    }
    
    for opp in captured:
        ratio = opp.get('kline_ctx_bullish_ratio', 0)
        if 0.6 <= ratio < 0.7:
            groups['0.6-0.7'].append(opp)
        elif 0.7 <= ratio < 0.8:
            groups['0.7-0.8'].append(opp)
        elif 0.8 <= ratio <= 1.0:
            groups['0.8-1.0'].append(opp)
    
    # è®¡ç®—å„ç»„ç»Ÿè®¡
    result = {}
    for range_name, group in groups.items():
        if len(group) > 0:
            profits = [o['actual_profit_pct'] for o in group]
            result[range_name] = {
                'count': len(group),
                'avg_profit': round(np.mean(profits), 1),
                'win_rate': round(len([p for p in profits if p > 0]) / len(profits), 2)
            }
    
    # ç”Ÿæˆç»“è®º
    if result:
        best_range = max(result.keys(), key=lambda k: result[k]['avg_profit'])
        result['conclusion'] = f"é˜³çº¿æ¯”ä¾‹{best_range}æ—¶æ•ˆæœæœ€å¥½ï¼ˆå¹³å‡åˆ©æ¶¦{result[best_range]['avg_profit']:.1f}%ï¼‰"
    
    return result


def analyze_market_structure_impact(captured: List[Dict]) -> Dict:
    """åˆ†æå¸‚åœºç»“æ„ä¸æˆåŠŸç‡çš„å…³ç³»"""
    # æŒ‰swingç±»å‹åˆ†ç»„
    groups = {}
    for opp in captured:
        swing_type = opp.get('mkt_struct_swing', 'unknown')
        if swing_type not in groups:
            groups[swing_type] = []
        groups[swing_type].append(opp)
    
    # è®¡ç®—å„ç»„ç»Ÿè®¡
    result = {}
    for swing_type, group in groups.items():
        if len(group) > 0:
            profits = [o['actual_profit_pct'] for o in group]
            result[swing_type] = {
                'count': len(group),
                'avg_profit': round(np.mean(profits), 1)
            }
    
    # ç”Ÿæˆç»“è®º
    if result:
        best_type = max(result.keys(), key=lambda k: result[k]['avg_profit'])
        result['conclusion'] = f"{best_type}ç»“æ„æ•ˆæœæœ€å¥½ï¼ˆå¹³å‡åˆ©æ¶¦{result[best_type]['avg_profit']:.1f}%ï¼‰"
    
    return result


def analyze_sr_history_impact(captured: List[Dict]) -> Dict:
    """åˆ†æS/Rå†å²ä¸æˆåŠŸç‡çš„å…³ç³»"""
    # æŒ‰æµ‹è¯•æ¬¡æ•°åˆ†ç»„
    groups = {
        '1-2æ¬¡': [],
        '3-5æ¬¡': [],
        '5æ¬¡+': []
    }
    
    for opp in captured:
        test_cnt = opp.get('resist_hist_test_cnt', 0) if opp['direction'] == 'short' else opp.get('support_hist_test_cnt', 0)
        
        if 1 <= test_cnt <= 2:
            groups['1-2æ¬¡'].append(opp)
        elif 3 <= test_cnt <= 5:
            groups['3-5æ¬¡'].append(opp)
        elif test_cnt > 5:
            groups['5æ¬¡+'].append(opp)
    
    # è®¡ç®—å„ç»„ç»Ÿè®¡
    result = {}
    for range_name, group in groups.items():
        if len(group) > 0:
            profits = [o['actual_profit_pct'] for o in group]
            result[range_name] = {
                'count': len(group),
                'avg_profit': round(np.mean(profits), 1)
            }
    
    # ç”Ÿæˆç»“è®º
    if result:
        best_range = max(result.keys(), key=lambda k: result[k]['avg_profit'])
        result['conclusion'] = f"S/Ræµ‹è¯•{best_range}æ—¶æ•ˆæœæœ€å¥½ï¼ˆå¹³å‡åˆ©æ¶¦{result[best_range]['avg_profit']:.1f}%ï¼‰"
    
    return result


def generate_insights_from_analysis(analysis: Dict) -> List[str]:
    """ä»åˆ†æä¸­ç”Ÿæˆå…³é”®æ´å¯Ÿ"""
    insights = []
    
    # Kçº¿ä¸Šä¸‹æ–‡æ´å¯Ÿ
    if 'kline_context' in analysis and 'conclusion' in analysis['kline_context']:
        insights.append(f"ğŸ’¡ {analysis['kline_context']['conclusion']}")
    
    # å¸‚åœºç»“æ„æ´å¯Ÿ
    if 'market_structure' in analysis and 'conclusion' in analysis['market_structure']:
        insights.append(f"ğŸ’¡ {analysis['market_structure']['conclusion']}")
    
    # S/Rå†å²æ´å¯Ÿ
    if 'sr_history' in analysis and 'conclusion' in analysis['sr_history']:
        insights.append(f"ğŸ’¡ {analysis['sr_history']['conclusion']}")
    
    return insights


def detect_anomalies_local(all_results: List[Dict], param_sensitivity: Dict) -> List[Dict]:
    """
    ã€æœ¬åœ°æ£€æµ‹ã€‘å¼‚å¸¸æƒ…å†µ
    
    åŸºäºè§„åˆ™æ£€æµ‹å¼‚å¸¸ï¼Œä¸éœ€è¦AI
    """
    anomalies = []
    
    # å¼‚å¸¸1ï¼šæŸä¸ªå‚æ•°å¯¼è‡´æ•è·ç‡éª¤é™
    for param_name in param_sensitivity.keys():
        # æ‰¾åˆ°è¯¥å‚æ•°çš„æç«¯å€¼
        param_results = {}
        for r in all_results:
            pval = r['params'][param_name]
            if pval not in param_results:
                param_results[pval] = []
            param_results[pval].append(r['metrics'].get('capture_rate', 0))
        
        # è®¡ç®—æ¯ä¸ªå€¼çš„å¹³å‡æ•è·ç‡
        param_avg_capture = {k: np.mean(v) for k, v in param_results.items()}
        
        # æ£€æµ‹éª¤é™
        values = sorted(param_avg_capture.keys())
        for i in range(len(values) - 1):
            v1, v2 = values[i], values[i+1]
            drop = param_avg_capture[v2] - param_avg_capture[v1]
            
            if drop < -0.2:  # ä¸‹é™è¶…è¿‡20%
                anomalies.append({
                    'type': 'capture_rate_drop',
                    'param': param_name,
                    'from_value': v1,
                    'to_value': v2,
                    'drop': round(drop, 2),
                    'severity': 'high' if drop < -0.3 else 'medium',
                    'description': f'{param_name}ä»{v1}â†’{v2}æ—¶ï¼Œæ•è·ç‡ä¸‹é™{abs(drop)*100:.0f}%'
                })
    
    # å¼‚å¸¸2ï¼šæ•´ä½“æ•è·ç‡è¿‡ä½
    avg_capture_rate = np.mean([r['metrics'].get('capture_rate', 0) for r in all_results])
    if avg_capture_rate < 0.3:
        anomalies.append({
            'type': 'low_capture_rate',
            'value': round(avg_capture_rate, 2),
            'severity': 'high',
            'description': f'æ•´ä½“æ•è·ç‡è¿‡ä½ï¼ˆ{avg_capture_rate*100:.0f}%ï¼‰ï¼Œå‚æ•°å¯èƒ½è¿‡ä¸¥'
        })
    
    return anomalies


# ============================================================
# ã€æ­¥éª¤5ã€‘è¯„åˆ†å‡½æ•°å’Œè¾…åŠ©å‡½æ•°
# ============================================================

def calculate_v8321_optimization_score(result: Dict) -> float:
    """
    ã€V8.3.21ã€‘å¤šç»´åº¦è¯„åˆ†å‡½æ•°
    
    æƒé‡ï¼š
    - å¹³å‡åˆ©æ¶¦: 40%
    - æ•è·ç‡: 35%
    - èƒœç‡: 25%
    """
    if result['captured_count'] == 0:
        return 0.0
    
    # å½’ä¸€åŒ–æŒ‡æ ‡
    profit_score = min(1.0, max(0, result['avg_profit'] / 10))  # 10%ä¸ºæ»¡åˆ†
    capture_score = result['capture_rate']  # å·²ç»æ˜¯0-1
    win_score = result['win_rate']  # å·²ç»æ˜¯0-1
    
    # åŠ æƒ
    total_score = (
        profit_score * 0.40 +
        capture_score * 0.35 +
        win_score * 0.25
    )
    
    return total_score


def extract_key_metrics(result: Dict) -> Dict:
    """æå–å…³é”®æŒ‡æ ‡"""
    return {
        'capture_rate': result.get('capture_rate', 0),
        'avg_profit': result.get('avg_profit', 0),
        'win_rate': result.get('win_rate', 0),
        'time_exit_rate': result.get('time_exit_rate', 0)
    }


def calculate_score_distribution(all_results: List[Dict]) -> Dict:
    """è®¡ç®—åˆ†æ•°åˆ†å¸ƒ"""
    scores = [r['score'] for r in all_results]
    return {
        'mean': round(np.mean(scores), 3),
        'std': round(np.std(scores), 3),
        'min': round(np.min(scores), 3),
        'max': round(np.max(scores), 3),
        'q25': round(np.percentile(scores, 25), 3),
        'q50': round(np.percentile(scores, 50), 3),
        'q75': round(np.percentile(scores, 75), 3)
    }


def compress_optimization_results(top_10: List[Dict], 
                                   param_sensitivity: Dict,
                                   context_analysis: Dict,
                                   anomalies: List[Dict]) -> Dict:
    """
    å‹ç¼©ä¼˜åŒ–ç»“æœï¼ˆç”¨äºAIå†³ç­–ï¼‰
    
    å°†è¯¦ç»†æ•°æ®å‹ç¼©æˆæ‘˜è¦
    """
    return {
        'top_3_configs': [
            {
                'rank': i + 1,
                'score': r['score'],
                'params_summary': format_params_compact(r['params']),
                'metrics': r['metrics']
            }
            for i, r in enumerate(top_10[:3])
        ],
        'param_sensitivity_summary': {
            k: v for k, v in sorted(param_sensitivity.items(), 
                                    key=lambda x: abs(x[1]['avg_impact']), 
                                    reverse=True)[:5]  # åªä¿ç•™Top 5
        },
        'context_insights': context_analysis.get('key_insights', []),
        'anomalies_summary': [
            {
                'type': a['type'],
                'severity': a['severity'],
                'description': a['description']
            }
            for a in anomalies[:3]  # åªä¿ç•™Top 3
        ]
    }


def format_params_compact(params: Dict) -> str:
    """ç´§å‡‘æ ¼å¼åŒ–å‚æ•°"""
    return ', '.join([f"{k}={v}" for k, v in list(params.items())[:3]]) + '...'


def estimate_token_count(data: Dict) -> int:
    """ä¼°ç®—tokenæ•°é‡"""
    import json
    json_str = json.dumps(data)
    # ç²—ç•¥ä¼°ç®—ï¼šæ¯4ä¸ªå­—ç¬¦â‰ˆ1 token
    return len(json_str) // 4


# ============================================================
# ä¸»å‡½æ•°ç¤ºä¾‹
# ============================================================

if __name__ == "__main__":
    print("V8.3.21å›æµ‹ä¼˜åŒ–æ¨¡å—")
    print("ä½¿ç”¨æ–¹æ³•ï¼šä»ä¸»ç¨‹åºå¯¼å…¥ optimize_params_v8321_lightweight")

