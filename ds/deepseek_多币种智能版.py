import os
import time
import csv
import schedule
from openai import OpenAI
import ccxt
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
from dotenv import load_dotenv
import requests
from pathlib import Path
from scipy.signal import argrelextrema
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import hashlib
import hmac
from typing import Dict, List, Any, Optional
import re  # ğŸ”§ V7.6.7: ç”¨äºAIå“åº”è§£æ
from urllib.parse import urlencode

# ğŸ†• V8.3.22: å¯¼å…¥å¼€ä»“æ—¶æœºåˆ†ææ¨¡å—
# ğŸ†• V8.3.23: AIè‡ªä¸»å­¦ä¹ ç‰ˆ
# ğŸ”§ V8.3.25.8: ä½¿ç”¨æ–°çš„V2åˆ†ææ¨¡å—ï¼ˆå®Œæ•´çš„å¸‚åœºæœºä¼šå¯¹æ¯”åˆ†æï¼‰
from entry_exit_timing_analyzer_v2 import (
    analyze_entry_timing_v2,
    analyze_exit_timing_v2
)
# ä¿ç•™AIæ·±åº¦åˆ†æåŠŸèƒ½
from entry_timing_analyzer import (
    generate_ai_entry_insights, 
    generate_ai_exit_insights
)

# ğŸ”§ æ˜ç¡®æŒ‡å®š .env æ–‡ä»¶è·¯å¾„
_env_file = Path(__file__).parent / '.env'
if not _env_file.exists():
    raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° .env æ–‡ä»¶: {_env_file}")
load_dotenv(_env_file, override=True)

# ğŸ”§ V8.3.32.13: æ¨¡å‹æ˜¾ç¤ºåç§°ï¼ˆç”¨äºBarkæ¨é€ï¼‰
MODEL_DISPLAY_NAME = "DS"  # DS = DeepSeek

# ==================== ã€V8.3.16ã€‘ä¼˜åŒ–é…ç½®å¼€å…³ ====================
ENABLE_V770_FULL_OPTIMIZATION = False  # V7.7.0å®Œæ•´ä¼˜åŒ–ï¼ˆ7-10åˆ†é’Ÿï¼‰
ENABLE_V770_QUICK_SEARCH = True        # V7.7.0å¿«é€Ÿæ¢ç´¢ï¼ˆ3åˆ†é’Ÿï¼‰- ä¸ºV8.3.12æä¾›åˆå§‹å‚æ•°
ENABLE_PER_SYMBOL_OPTIMIZATION = False  # Per-Symbolä¼˜åŒ–ï¼ˆ56-91åˆ†é’Ÿï¼‰
ENABLE_CONDITIONAL_AI_CALL = True       # æ¡ä»¶AIè°ƒç”¨ï¼ˆä»…Time Exit>80%æ—¶ï¼‰
AI_AGGRESSIVENESS_DYNAMIC = True        # åŠ¨æ€AIæ¿€è¿›åº¦ï¼ˆæ ¹æ®Time Exitç‡è°ƒæ•´ï¼‰

# ==================== è¾…åŠ©å‡½æ•° ====================

def extract_json_from_ai_response(ai_content: str) -> dict:
    """
    ä»AIå“åº”ä¸­æå–JSONå¯¹è±¡ï¼ˆé²æ£’ç‰ˆæœ¬ï¼‰
    
    å°è¯•é¡ºåºï¼š
    1. æ¸…ç†ç‰¹æ®Šæ ‡ç­¾ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
    2. æå–Markdownä»£ç å—ä¸­çš„JSON (```json ... ```)
    3. æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡ï¼ˆéè´ªå©ªåŒ¹é…ï¼‰
    4. å°è¯•è§£ææ•´ä¸ªå†…å®¹ä¸ºJSON
    
    Args:
        ai_content: AIè¿”å›çš„åŸå§‹æ–‡æœ¬
        
    Returns:
        è§£æåçš„å­—å…¸å¯¹è±¡
        
    Raises:
        ValueError: å¦‚æœæ— æ³•æå–æœ‰æ•ˆçš„JSON
    """
    ai_content = ai_content.strip()
    
    # æ–¹æ³•0: ç§»é™¤ç‰¹æ®Šæ ‡ç­¾ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
    # æŸäº›æ¨¡å‹å¯èƒ½è¿”å›ï¼š<think>æ¨ç†è¿‡ç¨‹</think>\n{JSON}
    think_match = re.search(r'<think>.*?</think>\s*', ai_content, re.DOTALL)
    if think_match:
        ai_content = ai_content[think_match.end():].strip()
    
    # æ¸…ç†å‡½æ•°ï¼šç§»é™¤æ— æ•ˆçš„æ§åˆ¶å­—ç¬¦
    def clean_json_str(s):
        # ç§»é™¤æ— æ•ˆçš„æ§åˆ¶å­—ç¬¦ï¼ˆä¿ç•™ \n \r \tï¼‰
        return re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f]', '', s)
    
    # æ–¹æ³•1: æå–Markdownä»£ç å—
    md_match = re.search(r'```(?:json)?\s*\n([\s\S]*?)\n```', ai_content)
    if md_match:
        try:
            cleaned = clean_json_str(md_match.group(1))
            return json.loads(cleaned)
        except json.JSONDecodeError:
            pass
    
    # æ–¹æ³•2: æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡ï¼ˆéè´ªå©ªåŒ¹é…+é€’å½’æ‹¬å·è®¡æ•°ï¼‰
    start_idx = ai_content.find('{')
    if start_idx != -1:
        brace_count = 0
        for i, char in enumerate(ai_content[start_idx:], start=start_idx):
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    # æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
                    json_str = ai_content[start_idx:i+1]
                    try:
                        cleaned = clean_json_str(json_str)
                        return json.loads(cleaned)
                    except json.JSONDecodeError:
                        pass
                    break
    
    # æ–¹æ³•3: å°è¯•è§£ææ•´ä¸ªå†…å®¹
    try:
        cleaned = clean_json_str(ai_content)
        return json.loads(cleaned)
    except json.JSONDecodeError:
        pass
    
    raise ValueError(f"æ— æ³•ä»AIå“åº”ä¸­æå–æœ‰æ•ˆJSON")

# ==================== AIè°ƒç”¨ä¼˜åŒ–å™¨ ====================

class MarketStateFingerprint:
    """å¸‚åœºçŠ¶æ€æŒ‡çº¹ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate(market_data: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆå¸‚åœºçŠ¶æ€æŒ‡çº¹ï¼Œä»…å…³æ³¨å½±å“å†³ç­–çš„å…³é”®å˜åŒ–
        
        å…³é”®å› ç´ ï¼ˆä»»ä¸€å˜åŒ–å¿…é¡»é‡æ–°åˆ†æï¼‰ï¼š
        1. è¶‹åŠ¿åè½¬ï¼ˆ4H/1H/15mï¼‰
        2. RSIè¿›å…¥/ç¦»å¼€è¶…ä¹°è¶…å–åŒº
        3. MACDé‡‘å‰/æ­»å‰
        4. ä»·æ ¼çªç ´å…³é”®æ”¯æ’‘é˜»åŠ›ä½
        5. æˆäº¤é‡å¼‚å¸¸ï¼ˆ>200%å¹³å‡å€¼ï¼‰
        6. æŒ‡æ ‡å…±æŒ¯æ•°å˜åŒ–ï¼ˆ3/5 vs 4/5ï¼‰
        7. æŒä»“çŠ¶æ€æ”¹å˜
        """
        
        # ç¦»æ•£åŒ–å…³é”®æŒ‡æ ‡ï¼ˆé¿å…å¾®å°æ³¢åŠ¨è§¦å‘é‡æ–°åˆ†æï¼‰
        key_state = {
            'trend_4h': market_data.get('trend_4h', ''),
            'trend_1h': market_data.get('trend_1h', ''),
            'trend_15m': market_data.get('trend_15m', ''),
            
            # RSIåŒºé—´åŒ–ï¼ˆè€Œéç²¾ç¡®å€¼ï¼‰
            'rsi_14_zone': _discretize_rsi(market_data.get('rsi', {}).get('rsi_14', 50)),
            'rsi_7_zone': _discretize_rsi(market_data.get('rsi', {}).get('rsi_7', 50)),
            
            # MACDæ–¹å‘ï¼ˆè€Œéç²¾ç¡®å€¼ï¼‰
            'macd_direction': 'bull' if market_data.get('macd', {}).get('histogram', 0) > 0 else 'bear',
                'macd_1h_direction': 'bull' if market_data.get('mid_term', {}).get('macd_histogram', 0) > 0 else 'bear',
            
            # ä»·æ ¼ç›¸å¯¹æ”¯æ’‘é˜»åŠ›ä½ç½®ï¼ˆÂ±3%å†…è®¤ä¸ºç›¸åŒï¼‰
            'price_position': _get_price_position(
                market_data.get('current_price', 0),
                market_data.get('support_resistance', {})
            ),
            
            # æˆäº¤é‡çŠ¶æ€
            'volume_status': market_data.get('volume_status', 'normal'),
            
            # æŒ‡æ ‡å…±æŒ¯ç­‰çº§ï¼ˆåˆ†ä¸ºå¼±/ä¸­/å¼ºï¼‰
            'consensus_level': _get_consensus_level(market_data.get('indicator_consensus', 0)),
            
            # æŒä»“çŠ¶æ€
            'has_position': market_data.get('has_position', False),
            'position_side': market_data.get('position_side', 'none'),
        }
        
        # ç”Ÿæˆå“ˆå¸ŒæŒ‡çº¹
        fingerprint_str = json.dumps(key_state, sort_keys=True)
        return hashlib.md5(fingerprint_str.encode()).hexdigest()[:12]


def _discretize_rsi(rsi: float) -> str:
    """RSIç¦»æ•£åŒ–ä¸ºåŒºé—´"""
    if rsi >= 70:
        return 'overbought'  # è¶…ä¹°
    elif rsi >= 60:
        return 'high'  # åé«˜
    elif rsi >= 40:
        return 'neutral'  # ä¸­æ€§
    elif rsi >= 30:
        return 'low'  # åä½
    else:
        return 'oversold'  # è¶…å–


def _get_price_position(price: float, sr_levels: Dict) -> str:
    """åˆ¤æ–­ä»·æ ¼ç›¸å¯¹æ”¯æ’‘é˜»åŠ›çš„ä½ç½®"""
    if not price or not sr_levels:
        return 'neutral'
    
    # å®‰å…¨è·å–æ”¯æ’‘é˜»åŠ›ä½ï¼ˆå¤„ç†Noneæƒ…å†µï¼‰
    support_data = sr_levels.get('nearest_support') or {}
    resistance_data = sr_levels.get('nearest_resistance') or {}
    nearest_support = support_data.get('price', 0) if isinstance(support_data, dict) else 0
    nearest_resistance = resistance_data.get('price', 0) if isinstance(resistance_data, dict) else 0
    
    if nearest_support and abs(price - nearest_support) / price < 0.03:
        return 'at_support'  # åœ¨æ”¯æ’‘ä½
    elif nearest_resistance and abs(price - nearest_resistance) / price < 0.03:
        return 'at_resistance'  # åœ¨é˜»åŠ›ä½
    elif nearest_support and nearest_resistance:
        range_size = nearest_resistance - nearest_support
        position = (price - nearest_support) / range_size if range_size > 0 else 0.5
        if position < 0.3:
            return 'near_support'
        elif position > 0.7:
            return 'near_resistance'
        else:
            return 'mid_range'
    
    return 'neutral'


def _get_consensus_level(consensus: int) -> str:
    """æŒ‡æ ‡å…±æŒ¯ç­‰çº§"""
    if consensus >= 4:
        return 'strong'  # å¼ºå…±æŒ¯
    elif consensus >= 3:
        return 'medium'  # ä¸­ç­‰
    else:
        return 'weak'  # å¼±


class AICallOptimizer:
    """AIè°ƒç”¨ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.last_fingerprints = {}  # {symbol: fingerprint}
        self.last_portfolio_call_time = None  # ä¸Šæ¬¡ç»„åˆå†³ç­–æ—¶é—´
        self.call_stats = {
            'total': 0,
            'saved': 0,
            'forced': 0,  # å¼ºåˆ¶è°ƒç”¨æ¬¡æ•°ï¼ˆå…³é”®å˜åŒ–ï¼‰
        }
        # è¯¦ç»†è®°å½•ï¼ˆç”¨äºé‚®ä»¶æŠ¥å‘Šï¼‰
        self.daily_details = {
            'skip_reasons': [],  # è·³è¿‡åŸå› åˆ—è¡¨
            'force_reasons': [],  # å¼ºåˆ¶è°ƒç”¨åŸå› åˆ—è¡¨
            'saved_cost_estimate': 0.0,  # ä¼°ç®—èŠ‚çœæˆæœ¬
            'start_time': datetime.now(),  # ç»Ÿè®¡å¼€å§‹æ—¶é—´
        }
    
    def should_call_portfolio_ai(
        self,
        market_data_list: List[Dict[str, Any]],
        current_positions: List[Dict[str, Any]]
    ) -> tuple:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨ç»„åˆå†³ç­–AIï¼ˆé’ˆå¯¹å¤šå¸ç§åŒæ—¶åˆ†æçš„åœºæ™¯ï¼‰
        
        Returns:
            (æ˜¯å¦è°ƒç”¨, åŸå› è¯´æ˜)
        """
        self.call_stats['total'] += 1
        
        # 1. æœ‰æŒä»“æ—¶å¿…é¡»è°ƒç”¨ï¼ˆä¿æŠ¤åˆ©æ¶¦/æ­¢æŸï¼‰
        if current_positions and len(current_positions) > 0:
            self.call_stats['forced'] += 1
            self._update_fingerprints(market_data_list)
            # è®°å½•è¯¦æƒ…
            self.daily_details['force_reasons'].append({
                'time': datetime.now().strftime('%H:%M:%S'),
                'reason': 'æœ‰æŒä»“ç›‘æ§',
                'positions': len(current_positions)
            })
            return True, "ğŸ”´ æœ‰æŒä»“ï¼Œå¿…é¡»å®æ—¶ç›‘æ§"
        
        # 2. é¦–æ¬¡è°ƒç”¨
        if not self.last_fingerprints:
            self._update_fingerprints(market_data_list)
            return True, "ğŸŸ¢ é¦–æ¬¡åˆ†æ"
        
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¸ç§å‘ç”Ÿå…³é”®å˜åŒ–
        changed_symbols = []
        critical_changes = []
        
        for data in market_data_list:
            if data is None:
                continue
            
            symbol = data.get('symbol', '')
            coin_name = symbol.split('/')[0] if symbol else ''
            
            if not coin_name:
                continue
            
            # ç”Ÿæˆå½“å‰æŒ‡çº¹
            current_fp = MarketStateFingerprint.generate(data)
            last_fp = self.last_fingerprints.get(coin_name)
            
            # æ£€æŸ¥å…³é”®å˜åŒ–
            force_call, reason = self._check_critical_change(data)
            if force_call:
                critical_changes.append(f"{coin_name}: {reason}")
            
            # æ£€æŸ¥çŠ¶æ€å˜åŒ–
            if last_fp != current_fp:
                changed_symbols.append(coin_name)
        
        # 4. æœ‰å…³é”®å˜åŒ–å¿…é¡»è°ƒç”¨
        if critical_changes:
            self.call_stats['forced'] += 1
            self._update_fingerprints(market_data_list)
            # è®°å½•è¯¦æƒ…
            self.daily_details['force_reasons'].append({
                'time': datetime.now().strftime('%H:%M:%S'),
                'reason': 'å…³é”®ä¿¡å·',
                'details': ', '.join(critical_changes[:2])
            })
            return True, f"ğŸ”´ å…³é”®å˜åŒ–: {', '.join(critical_changes[:2])}"
        
        # 5. æœ‰å¸ç§çŠ¶æ€å˜åŒ–åˆ™è°ƒç”¨
        if changed_symbols:
            self._update_fingerprints(market_data_list)
            return True, f"ğŸŸ¡ å¸‚åœºæ›´æ–°: {', '.join(changed_symbols[:3])}"
        
        # 6. è·ä¸Šæ¬¡è°ƒç”¨è¶…è¿‡30åˆ†é’Ÿï¼Œå¼ºåˆ¶åˆ·æ–°
        if self.last_portfolio_call_time:
            from datetime import timedelta
            time_since_last = datetime.now() - self.last_portfolio_call_time
            if time_since_last >= timedelta(minutes=30):
                self.call_stats['forced'] += 1
                self._update_fingerprints(market_data_list)
                # è®°å½•è¯¦æƒ…
                self.daily_details['force_reasons'].append({
                    'time': datetime.now().strftime('%H:%M:%S'),
                    'reason': 'å®šæœŸåˆ·æ–°',
                    'details': f'è·ä¸Šæ¬¡{time_since_last.seconds//60}åˆ†é’Ÿ'
                })
                return True, "ğŸ”´ è·ä¸Šæ¬¡>30åˆ†é’Ÿï¼Œå¼ºåˆ¶åˆ·æ–°"
        
        # 7. æ‰€æœ‰å¸ç§çŠ¶æ€æ— å˜åŒ–ï¼Œå¯ä»¥è·³è¿‡
        self.call_stats['saved'] += 1
        time_passed = (datetime.now() - self.last_portfolio_call_time).seconds // 60 if self.last_portfolio_call_time else 0
        
        # è®°å½•è¯¦æƒ… + ä¼°ç®—èŠ‚çœæˆæœ¬
        cost_per_call = 0.014  # DeepSeek APIå¹³å‡æˆæœ¬ï¼ˆå…ƒ/æ¬¡ï¼Œdeepseek-reasonerçº¦0.014ï¼‰
        self.daily_details['saved_cost_estimate'] += cost_per_call
        self.daily_details['skip_reasons'].append({
            'time': datetime.now().strftime('%H:%M:%S'),
            'reason': 'çŠ¶æ€æ— å˜åŒ–',
            'duration': f'{time_passed}åˆ†é’Ÿ',
            'saved_cost': cost_per_call
        })
        
        return False, f"âœ… è·³è¿‡: æ‰€æœ‰å¸ç§çŠ¶æ€æ— å˜åŒ– (å·²{time_passed}åˆ†é’Ÿ)"
    
    def _update_fingerprints(self, market_data_list: List[Dict[str, Any]]):
        """æ›´æ–°æ‰€æœ‰å¸ç§çš„æŒ‡çº¹"""
        for data in market_data_list:
            if data is None:
                continue
            symbol = data.get('symbol', '')
            coin_name = symbol.split('/')[0] if symbol else ''
            if coin_name:
                self.last_fingerprints[coin_name] = MarketStateFingerprint.generate(data)
        self.last_portfolio_call_time = datetime.now()
    
    def _check_critical_change(self, market_data: Dict[str, Any]) -> tuple:
        """æ£€æŸ¥å•ä¸ªå¸ç§æ˜¯å¦æœ‰å…³é”®å˜åŒ–ï¼ˆå¿…é¡»ç«‹å³åˆ†æï¼‰"""
        
        # å…³é”®å½¢æ€å‡ºç°
        pa = market_data.get('price_action', {})
        if pa.get('pin_bar') in ['bullish_pin', 'bearish_pin']:
            return True, "Pin Bar"
        if pa.get('engulfing') in ['bullish_engulfing', 'bearish_engulfing']:
            return True, "åæ²¡å½¢æ€"
        if pa.get('breakout'):
            return True, "çªç ´ä¿¡å·"
        
        # æˆäº¤é‡å¼‚å¸¸
        if market_data.get('volume_analysis', {}).get('volume_ratio', 0) > 200:
            return True, "å¼‚å¸¸æ”¾é‡"
        
        return False, ""
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–ç»Ÿè®¡"""
        saved_rate = (self.call_stats['saved'] / self.call_stats['total'] * 100) if self.call_stats['total'] > 0 else 0
        
        return {
            'total_decisions': self.call_stats['total'],
            'api_calls': self.call_stats['forced'] + (self.call_stats['total'] - self.call_stats['saved'] - self.call_stats['forced']),
            'calls_saved': self.call_stats['saved'],
            'save_rate': f"{saved_rate:.1f}%",
            'cost_reduction': f"çº¦{saved_rate * 0.8:.0f}%",  # è€ƒè™‘DeepSeekè‡ªèº«ç¼“å­˜
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.call_stats = {'total': 0, 'saved': 0, 'forced': 0}
    
    def get_daily_report_html(self) -> str:
        """ç”Ÿæˆæ¯æ—¥ä¼˜åŒ–æŠ¥å‘Šï¼ˆHTMLæ ¼å¼ï¼Œç”¨äºé‚®ä»¶ï¼‰"""
        stats = self.get_stats()
        
        # ç»Ÿè®¡æ—¶é•¿
        duration = datetime.now() - self.daily_details['start_time']
        hours = duration.total_seconds() / 3600
        
        # æŒ‰åŸå› åˆ†ç»„ç»Ÿè®¡è·³è¿‡æ¬¡æ•°
        skip_by_reason = {}
        for skip in self.daily_details['skip_reasons']:
            reason = skip['reason']
            skip_by_reason[reason] = skip_by_reason.get(reason, 0) + 1
        
        # æœ€è¿‘è·³è¿‡è®°å½•ï¼ˆæœ€å¤šæ˜¾ç¤º10æ¡ï¼‰
        recent_skips = self.daily_details['skip_reasons'][-10:]
        
        # æŒ‰åŸå› åˆ†ç»„ç»Ÿè®¡å¼ºåˆ¶è°ƒç”¨
        force_by_reason = {}
        for force in self.daily_details['force_reasons']:
            reason = force['reason']
            force_by_reason[reason] = force_by_reason.get(reason, 0) + 1
        
        html = f"""
<div style="background: #f8f9fa; padding: 20px; border-radius: 8px; margin: 20px 0;">
    <h2 style="color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;">
        ğŸš€ AIè°ƒç”¨ä¼˜åŒ–æŠ¥å‘Š
    </h2>
    
    <div style="background: white; padding: 15px; border-radius: 5px; margin: 15px 0;">
        <h3 style="color: #27ae60;">ğŸ“Š æ€»ä½“ç»Ÿè®¡ï¼ˆè¿‡å»{hours:.1f}å°æ—¶ï¼‰</h3>
        <table style="width: 100%; border-collapse: collapse;">
            <tr style="background: #ecf0f1;">
                <td style="padding: 10px; border: 1px solid #bdc3c7;"><strong>æ€»å†³ç­–æ¬¡æ•°</strong></td>
                <td style="padding: 10px; border: 1px solid #bdc3c7;">{stats['total_decisions']} æ¬¡</td>
            </tr>
            <tr>
                <td style="padding: 10px; border: 1px solid #bdc3c7;"><strong>å®é™…APIè°ƒç”¨</strong></td>
                <td style="padding: 10px; border: 1px solid #bdc3c7; color: #e74c3c;">{stats['api_calls']} æ¬¡</td>
            </tr>
            <tr style="background: #ecf0f1;">
                <td style="padding: 10px; border: 1px solid #bdc3c7;"><strong>æ™ºèƒ½è·³è¿‡</strong></td>
                <td style="padding: 10px; border: 1px solid #bdc3c7; color: #27ae60;"><strong>{stats['calls_saved']} æ¬¡</strong></td>
            </tr>
            <tr>
                <td style="padding: 10px; border: 1px solid #bdc3c7;"><strong>èŠ‚çœç‡</strong></td>
                <td style="padding: 10px; border: 1px solid #bdc3c7; color: #f39c12;"><strong>{stats['save_rate']}</strong></td>
            </tr>
            <tr style="background: #d5f4e6;">
                <td style="padding: 10px; border: 1px solid #bdc3c7;"><strong>ğŸ’° èŠ‚çœæˆæœ¬</strong></td>
                <td style="padding: 10px; border: 1px solid #bdc3c7; color: #27ae60;">
                    <strong>çº¦ Â¥{self.daily_details['saved_cost_estimate']:.2f} å…ƒ</strong>
                </td>
            </tr>
        </table>
    </div>
    
    <div style="background: white; padding: 15px; border-radius: 5px; margin: 15px 0;">
        <h3 style="color: #27ae60;">âœ… è·³è¿‡æ˜ç»†ï¼ˆèŠ‚çœæˆæœ¬ï¼‰</h3>
        <table style="width: 100%; border-collapse: collapse; font-size: 12px;">
            <tr style="background: #27ae60; color: white;">
                <th style="padding: 8px; border: 1px solid #bdc3c7;">åŸå› ç±»å‹</th>
                <th style="padding: 8px; border: 1px solid #bdc3c7;">æ¬¡æ•°</th>
            </tr>
"""
        
        for reason, count in skip_by_reason.items():
            html += f"""
            <tr>
                <td style="padding: 8px; border: 1px solid #bdc3c7;">{reason}</td>
                <td style="padding: 8px; border: 1px solid #bdc3c7; text-align: center;">{count}</td>
            </tr>
"""
        
        html += """
        </table>
        
        <h4 style="color: #7f8c8d; margin-top: 15px;">æœ€è¿‘10æ¬¡è·³è¿‡è®°å½•</h4>
        <table style="width: 100%; border-collapse: collapse; font-size: 11px;">
            <tr style="background: #ecf0f1;">
                <th style="padding: 6px; border: 1px solid #bdc3c7;">æ—¶é—´</th>
                <th style="padding: 6px; border: 1px solid #bdc3c7;">åŸå› </th>
                <th style="padding: 6px; border: 1px solid #bdc3c7;">æŒç»­æ—¶é•¿</th>
                <th style="padding: 6px; border: 1px solid #bdc3c7;">èŠ‚çœ</th>
            </tr>
"""
        
        for skip in recent_skips:
            html += f"""
            <tr>
                <td style="padding: 6px; border: 1px solid #bdc3c7;">{skip['time']}</td>
                <td style="padding: 6px; border: 1px solid #bdc3c7;">{skip['reason']}</td>
                <td style="padding: 6px; border: 1px solid #bdc3c7;">{skip.get('duration', '-')}</td>
                <td style="padding: 6px; border: 1px solid #bdc3c7; color: #27ae60;">Â¥{skip['saved_cost']:.3f}</td>
            </tr>
"""
        
        html += """
        </table>
    </div>
    
    <div style="background: white; padding: 15px; border-radius: 5px; margin: 15px 0;">
        <h3 style="color: #e74c3c;">ğŸ”´ å¼ºåˆ¶è°ƒç”¨æ˜ç»†ï¼ˆä¿è¯æ•ˆæœï¼‰</h3>
        <table style="width: 100%; border-collapse: collapse; font-size: 12px;">
            <tr style="background: #e74c3c; color: white;">
                <th style="padding: 8px; border: 1px solid #bdc3c7;">è§¦å‘åŸå› </th>
                <th style="padding: 8px; border: 1px solid #bdc3c7;">æ¬¡æ•°</th>
            </tr>
"""
        
        for reason, count in force_by_reason.items():
            html += f"""
            <tr>
                <td style="padding: 8px; border: 1px solid #bdc3c7;">{reason}</td>
                <td style="padding: 8px; border: 1px solid #bdc3c7; text-align: center;">{count}</td>
            </tr>
"""
        
        html += """
        </table>
        <p style="color: #7f8c8d; font-size: 12px; margin-top: 10px;">
            â„¹ï¸ å¼ºåˆ¶è°ƒç”¨ç¡®ä¿ï¼šæœ‰æŒä»“æ—¶å®æ—¶ç›‘æ§ã€å…³é”®ä¿¡å·ç«‹å³åˆ†æã€å®šæœŸåˆ·æ–°é˜²é—æ¼
        </p>
    </div>
    
    <div style="background: #fff3cd; padding: 12px; border-radius: 5px; border-left: 4px solid #ffc107;">
        <strong>ğŸ’¡ ä¼˜åŒ–æ•ˆæœè¯´æ˜ï¼š</strong>
        <ul style="margin: 5px 0; padding-left: 20px;">
            <li>âœ… æœ‰æŒä»“æ—¶ä¿æŒ100%ç›‘æ§ï¼Œä¸å½±å“æ­¢æŸå’Œåˆ©æ¶¦ä¿æŠ¤</li>
            <li>âœ… å…³é”®ä¿¡å·ï¼ˆPin Barã€åæ²¡ã€çªç ´ï¼‰ç«‹å³åˆ†æï¼Œä¸é”™è¿‡æœºä¼š</li>
            <li>âœ… å¸‚åœºçŠ¶æ€æ— å˜åŒ–æ—¶æ™ºèƒ½è·³è¿‡ï¼ŒèŠ‚çœæˆæœ¬</li>
            <li>âœ… æœ€å¤š30åˆ†é’Ÿå¼ºåˆ¶åˆ·æ–°ä¸€æ¬¡ï¼Œé˜²æ­¢é—æ¼</li>
        </ul>
    </div>
</div>
"""
        
        return html
    
    def reset_daily_details(self):
        """é‡ç½®æ¯æ—¥è¯¦ç»†è®°å½•ï¼ˆé€šå¸¸åœ¨æ¯æ—¥æŠ¥å‘Šå‘é€åè°ƒç”¨ï¼‰"""
        self.daily_details = {
            'skip_reasons': [],
            'force_reasons': [],
            'saved_cost_estimate': 0.0,
            'start_time': datetime.now(),
        }


# å…¨å±€AIè°ƒç”¨ä¼˜åŒ–å™¨å®ä¾‹
ai_optimizer = AICallOptimizer()

# ==================== AIè°ƒç”¨ä¼˜åŒ–å™¨ç»“æŸ ====================

# åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
if not deepseek_api_key:
    raise ValueError("âŒ DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ .env.deepseek æ–‡ä»¶")
# å»é™¤å¯èƒ½çš„ç©ºæ ¼å’Œæ¢è¡Œç¬¦
deepseek_api_key = deepseek_api_key.strip()
deepseek_client = OpenAI(
    api_key=deepseek_api_key, base_url="https://api.deepseek.com"
)

# åˆå§‹åŒ–äº¤æ˜“æ‰€ï¼ˆå¸å®‰/OKX äºŒé€‰ä¸€ï¼‰
EXCHANGE_TYPE = os.getenv("EXCHANGE_TYPE", "binance")  # é»˜è®¤å¸å®‰

if EXCHANGE_TYPE == "binance":
    # ğŸ”§ V7.7.0.20: æ”¯æŒç»Ÿä¸€è´¦æˆ·æ¨¡å¼ï¼ˆPortfolio Marginï¼‰
    # ç»Ÿä¸€è´¦æˆ·ä½¿ç”¨ portfolioMargin é€‰é¡¹è‡ªåŠ¨åˆ‡æ¢åˆ° papi ç«¯ç‚¹
    USE_PORTFOLIO_MARGIN = os.getenv("USE_PORTFOLIO_MARGIN", "true").lower() == "true"
    
    # è¯»å–å¹¶æ¸…ç† API keys
    binance_api_key = os.getenv("BINANCE_API_KEY", "").strip()
    binance_secret_key = os.getenv("BINANCE_SECRET_KEY", "").strip()
    
    exchange = ccxt.binance({
        "options": {
            "defaultType": "future",
            "portfolioMargin": USE_PORTFOLIO_MARGIN,  # ç»Ÿä¸€è´¦æˆ·æ¨¡å¼
            "recvWindow": 60000,  # ã€ä¿®å¤ã€‘å¢å¤§åˆ°60ç§’ï¼Œé¿å…ç³»ç»Ÿå¡é¡¿æ—¶æ—¶é—´æˆ³è¿‡æœŸï¼ˆé»˜è®¤5ç§’ï¼‰
        },
        "apiKey": binance_api_key,
        "secret": binance_secret_key,
        "timeout": 30000,  # ã€ä¿®å¤ã€‘å¢å¤§è¶…æ—¶æ—¶é—´åˆ°30ç§’ï¼ˆé»˜è®¤10ç§’ï¼‰
        "enableRateLimit": True,  # ã€ä¿®å¤ã€‘å¯ç”¨é€Ÿç‡é™åˆ¶ä¿æŠ¤
    })
    
    print(f"ğŸ”§ å¸å®‰äº¤æ˜“æ‰€åˆå§‹åŒ–: {'ç»Ÿä¸€è´¦æˆ·æ¨¡å¼ (papi)' if USE_PORTFOLIO_MARGIN else 'æ ‡å‡†åˆçº¦æ¨¡å¼ (fapi)'}")
    
    # ã€æ–°å¢ã€‘æ£€æŸ¥æ—¶é—´åŒæ­¥ï¼Œé¿å…timestampé”™è¯¯
    try:
        server_time = exchange.fetch_time()
        local_time = int(time.time() * 1000)
        time_diff = abs(server_time - local_time)
        if time_diff > 5000:  # å·®å¼‚è¶…è¿‡5ç§’
            print(f"âš ï¸  æœåŠ¡å™¨æ—¶é—´å·®å¼‚: {time_diff}ms (>{5}s)")
            print(f"   æœ¬åœ°æ—¶é—´: {datetime.fromtimestamp(local_time/1000)}")
            print(f"   å¸å®‰æ—¶é—´: {datetime.fromtimestamp(server_time/1000)}")
            print(f"   å»ºè®®æ‰§è¡Œ: sudo ntpdate -u time.nist.gov")
        else:
            print(f"âœ“ æ—¶é—´åŒæ­¥æ­£å¸¸ (å·®å¼‚{time_diff}ms)")
    except Exception as e:
        print(f"âš ï¸  æ—¶é—´åŒæ­¥æ£€æŸ¥å¤±è´¥: {e}")
else:
    # è¯»å–å¹¶æ¸…ç† OKX API keys
    okx_api_key = os.getenv("OKX_API_KEY", "").strip()
    okx_secret = os.getenv("OKX_SECRET", "").strip()
    okx_password = os.getenv("OKX_PASSWORD", "").strip()
    
    exchange = ccxt.okx(
        {
            "options": {
                "defaultType": "swap",
            },
            "apiKey": okx_api_key,
            "secret": okx_secret,
            "password": okx_password,
        }
    )

# äº¤æ˜“å‚æ•°é…ç½®
TRADE_CONFIG = {
    "symbols": [
        "BTC/USDT:USDT",
        "ETH/USDT:USDT",
        "SOL/USDT:USDT",
        "BNB/USDT:USDT",
        "XRP/USDT:USDT",
        "DOGE/USDT:USDT",
        "LTC/USDT:USDT",
    ],
    "max_leverage": 5,  # æœ€å¤§æ æ†5å€
    "initial_capital": int(
        os.getenv("INITIAL_CAPITAL", "100")
    ),  # ä»ç¯å¢ƒå˜é‡è¯»å–åˆå§‹èµ„é‡‘
    "use_dynamic_position": True,  # åŠ¨æ€è°ƒæ•´ä»“ä½ï¼ˆæ ¹æ®æ€»èµ„äº§ï¼‰
    "position_ratio": 1.0,  # æ€»èµ„äº§çš„100%å¯ç”¨äºä»“ä½
    "min_risk_reward": 1.5,  # æœ€å°ç›ˆäºæ¯”1:1.5
    "timeframe": "15m",
    "test_mode": os.getenv("TEST_MODE", "false").lower()
    == "true",  # ä»ç¯å¢ƒå˜é‡è¯»å–æµ‹è¯•æ¨¡å¼
    "bark_key": os.getenv("BARK_KEY", "kqMFY7827om3TQMR2iziNR"),  # Barkæ¨é€å¯†é’¥
}

# ==================== V7.6.5: ä¿¡å·åˆ†çº§é…ç½® ====================

SIGNAL_TIER_PARAMS = {
    "HIGH": {
        "min_risk_reward": 1.5,  # é«˜è´¨é‡ä¿¡å·å…è®¸æ›´ä½ç›ˆäºæ¯”
        "atr_multiplier": 1.0,    # æ ‡å‡†ATRå€æ•°ï¼ˆç›¸å¯¹base_atrï¼‰
        "position_multiplier": 1.3,  # ä»“ä½æ”¾å¤§30%
        "description": "YTCé«˜è´¨é‡ä¿¡å·ï¼Œ3å±‚è¶‹åŠ¿å…±æŒ¯ï¼Œé«˜èƒœç‡é¢„æœŸ",
        "rationale": "High-win-rate signals allow tighter stops (R:R 1.5) while maintaining positive expected value. Example: If win rate is 55%, expected return = 0.55Ã—1.5 - 0.45Ã—1 = 0.375 > 0"
    },
    "MEDIUM": {
        "min_risk_reward": 2.0,   # æ ‡å‡†ç›ˆäºæ¯”
        "atr_multiplier": 1.0,     # æ ‡å‡†ATR
        "position_multiplier": 1.0,  # æ ‡å‡†ä»“ä½
        "description": "æ ‡å‡†ä¿¡å·ï¼Œå¤šå±‚è¶‹åŠ¿æ”¯æŒï¼Œä¸­ç­‰èƒœç‡",
        "rationale": "Standard approach for moderate confidence signals. Balanced R:R of 2.0 provides cushion for 40-45% win rate scenarios."
            },
    "LOW": {
        "min_risk_reward": 2.5,   # ä¿å®ˆç›ˆäºæ¯”
        "atr_multiplier": 1.2,     # æ›´å®½æ­¢æŸï¼ˆé¿å…å™ªéŸ³æ‰«æŸï¼‰
        "position_multiplier": 0.7,  # å‡å°ä»“ä½30%
        "description": "ä½è´¨é‡ä¿¡å·ï¼Œå¼±è¶‹åŠ¿å¯¹é½ï¼Œéœ€è¦æ›´é«˜ç›ˆäºæ¯”ä¿æŠ¤",
        "rationale": "Low-confidence signals require higher R:R (2.5) to compensate for lower win rate (~35-40%). Wider stops prevent premature stop-outs in choppy markets."
            }
}

# ==================== V7.6.5: å¸ç§ä¸ªæ€§åŒ–ç”»åƒ ====================

SYMBOL_PROFILES = {
    "BTC/USDT:USDT": {
        "name": "æ¯”ç‰¹å¸",
        "volatility": "LOW",
        "liquidity": "HIGH",
        "trend_style": "STABLE",
        "recommended_holding_hours": 6,
        "atr_multiplier_adjustment": 1.0,
        "false_breakout_rate": "LOW",
        "characteristics": "å¤§ç›˜é¾™å¤´ï¼Œè¶‹åŠ¿æ˜ç¡®ï¼Œå‡çªç ´å°‘ï¼Œé€‚åˆä¸­çº¿æŒæœ‰"
    },
    "ETH/USDT:USDT": {
        "name": "ä»¥å¤ªåŠ",
        "volatility": "MEDIUM",
        "liquidity": "HIGH",
        "trend_style": "STABLE",
        "recommended_holding_hours": 5,
        "atr_multiplier_adjustment": 1.05,
        "false_breakout_rate": "LOW",
        "characteristics": "ä¸»æµå¸ï¼ŒæµåŠ¨æ€§å¥½ï¼Œæ³¢åŠ¨ç•¥å¤§äºBTCï¼Œè¶‹åŠ¿è·Ÿéšæ€§å¼º"
    },
    "SOL/USDT:USDT": {
        "name": "Solana",
        "volatility": "HIGH",
        "liquidity": "MEDIUM",
        "trend_style": "EXPLOSIVE",
        "recommended_holding_hours": 3,
        "atr_multiplier_adjustment": 1.2,
        "false_breakout_rate": "MEDIUM",
        "characteristics": "é«˜æ³¢åŠ¨ï¼Œçˆ†å‘åŠ›å¼ºï¼Œå‡çªç ´è¾ƒå¤šï¼Œé€‚åˆçŸ­çº¿å¿«è¿›å¿«å‡º"
    },
    "BNB/USDT:USDT": {
        "name": "å¸å®‰å¸",
        "volatility": "MEDIUM",
        "liquidity": "HIGH",
        "trend_style": "STABLE",
        "recommended_holding_hours": 4,
        "atr_multiplier_adjustment": 1.0,
        "false_breakout_rate": "LOW",
        "characteristics": "å¹³å°å¸ï¼Œå—å¸å®‰ç”Ÿæ€å½±å“ï¼Œè¶‹åŠ¿ç¨³å®š"
    },
    "XRP/USDT:USDT": {
        "name": "ç‘æ³¢å¸",
        "volatility": "HIGH",
        "liquidity": "MEDIUM",
        "trend_style": "NEWS_DRIVEN",
        "recommended_holding_hours": 2,
        "atr_multiplier_adjustment": 1.15,
        "false_breakout_rate": "HIGH",
        "characteristics": "æ¶ˆæ¯é¢æ•æ„Ÿï¼Œæ³¢åŠ¨å¤§ï¼Œå‡çªç ´å¤šï¼Œéœ€è¦å¿«é€Ÿååº”"
    },
    "DOGE/USDT:USDT": {
        "name": "ç‹—ç‹—å¸",
        "volatility": "EXTREME",
        "liquidity": "MEDIUM",
        "trend_style": "SENTIMENT",
        "recommended_holding_hours": 1,
        "atr_multiplier_adjustment": 1.3,
        "false_breakout_rate": "HIGH",
        "characteristics": "Memeå¸ï¼Œæƒ…ç»ªé©±åŠ¨ï¼Œæ³¢åŠ¨æå¤§ï¼Œä¸é€‚åˆè¶‹åŠ¿è·Ÿè¸ª"
    },
    "LTC/USDT:USDT": {
        "name": "è±ç‰¹å¸",
        "volatility": "MEDIUM",
        "liquidity": "MEDIUM",
        "trend_style": "STABLE",
        "recommended_holding_hours": 4,
        "atr_multiplier_adjustment": 1.0,
        "false_breakout_rate": "MEDIUM",
        "characteristics": "è€ç‰Œå¸ï¼Œè·ŸéšBTCï¼Œæ³¢åŠ¨é€‚ä¸­ï¼Œè¶‹åŠ¿æ¸…æ™°"
    }
}

# æ•°æ®å­˜å‚¨è·¯å¾„ï¼ˆDeepSeekä¸“ç”¨ç›®å½•ï¼‰
DATA_DIR = Path(__file__).parent / "trading_data" / "deepseek"
DATA_DIR.mkdir(parents=True, exist_ok=True)
TRADES_FILE = DATA_DIR / "trades_history.csv"
POSITIONS_FILE = DATA_DIR / "current_positions.csv"
STATUS_FILE = DATA_DIR / "system_status.json"
AI_DECISIONS_FILE = DATA_DIR / "ai_decisions.json"  # AIå†³ç­–å†å²
PNL_HISTORY_FILE = DATA_DIR / "pnl_history.csv"  # ç›ˆäºå†å²
CHAT_HISTORY_FILE = DATA_DIR / "chat_history.json"  # èŠå¤©è®°å½•
LEARNING_CONFIG_FILE = DATA_DIR / "learning_config.json"  # å­¦ä¹ å‚æ•°

# å…¨å±€å˜é‡
price_history = {}  # æ¯ä¸ªå¸ç§çš„ä»·æ ¼å†å²
signal_history = {}  # æ¯ä¸ªå¸ç§çš„ä¿¡å·å†å²


def send_bark_notification(title, content):
    """å‘é€Barkæ¨é€é€šçŸ¥ï¼ˆæ”¯æŒå¤šä¸ªåœ°å€ + DeepSeekåˆ†ç»„ï¼‰"""
    try:
        from urllib.parse import quote

        # ğŸ”§ V8.2.6: é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…URLè¿‡é•¿å¯¼è‡´404
        # GETè¯·æ±‚URLé•¿åº¦é™åˆ¶é€šå¸¸ä¸º2048å­—ç¬¦
        # ä¸­æ–‡URLç¼–ç åé•¿åº¦çº¦ä¸ºåŸå­—ç¬¦æ•°Ã—3ï¼Œæ‰€ä»¥é™åˆ¶è¦æ›´å°
        MAX_TITLE_LEN = 50   # ç¼–ç å~150å­—ç¬¦
        MAX_CONTENT_LEN = 600  # ç¼–ç å~1800å­—ç¬¦ï¼ˆBark URLé™åˆ¶çº¦2048å­—èŠ‚ï¼‰
        
        # æˆªæ–­è¿‡é•¿çš„æ ‡é¢˜å’Œå†…å®¹
        if len(title) > MAX_TITLE_LEN:
            title = title[:MAX_TITLE_LEN-3] + "..."
            print(f"[Barkæ¨é€] æ ‡é¢˜è¿‡é•¿ï¼Œå·²æˆªæ–­åˆ°{MAX_TITLE_LEN}å­—ç¬¦")
        
        if len(content) > MAX_CONTENT_LEN:
            content = content[:MAX_CONTENT_LEN-3] + "..."
            print(f"[Barkæ¨é€] å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­åˆ°{MAX_CONTENT_LEN}å­—ç¬¦")

        # 3ä¸ªBarkæ¨é€åœ°å€
        bark_key_config = TRADE_CONFIG.get("bark_key", "")
        bark_keys = [
            bark_key_config,
            "JhWxKdo8Chb2w9RJjSpX6m",
            "qHALdYkNgfvNe4qTT8v8UA",
        ]

        # è¿‡æ»¤æ‰ç©ºçš„key
        bark_keys = [k for k in bark_keys if k]

        print(f"[Barkæ¨é€] å‡†å¤‡å‘é€åˆ° {len(bark_keys)} ä¸ªè®¾å¤‡")
        print(f"[Barkæ¨é€] æ ‡é¢˜: {title}")
        print(f"[Barkæ¨é€] å†…å®¹: {content}")

        if not bark_keys:
            print("âš ï¸ æ²¡æœ‰é…ç½®Barkæ¨é€åœ°å€ï¼Œè·³è¿‡æ¨é€")
            return
    
        success_count = 0
        fail_count = 0

        for idx, bark_key in enumerate(bark_keys, 1):
            try:
                # URLç¼–ç æ ‡é¢˜å’Œå†…å®¹ï¼Œæ”¯æŒä¸­æ–‡
                encoded_title = quote(title)
                encoded_content = quote(content)

                # æ·»åŠ groupå‚æ•°ï¼Œå°†æ¨é€å½’ç±»åˆ°"DeepSeek"æ–‡ä»¶å¤¹
                url = f"https://api.day.app/{bark_key}/{encoded_title}/{encoded_content}?group=DeepSeek"
                
                # ğŸ”§ V7.7.0.16: æ£€æŸ¥URLé•¿åº¦
                if len(url) > 1800:  # é¢„ç•™ä¸€äº›å®‰å…¨ä½™é‡
                    print(f"[Barkæ¨é€] è®¾å¤‡{idx}: âš ï¸ URLè¿‡é•¿({len(url)}å­—ç¬¦)ï¼Œå¯èƒ½å¤±è´¥")

                print(f"[Barkæ¨é€] è®¾å¤‡{idx}: æ­£åœ¨å‘é€åˆ° {bark_key[:8]}...")

                response = requests.get(url, timeout=10)

                print(f"[Barkæ¨é€] è®¾å¤‡{idx}: å“åº”çŠ¶æ€ç  {response.status_code}")

                if response.status_code == 200:
                    success_count += 1
                    print(f"[Barkæ¨é€] è®¾å¤‡{idx}: âœ… æ¨é€æˆåŠŸ")
                else:
                    fail_count += 1
                    print(
                        f"[Barkæ¨é€] è®¾å¤‡{idx}: âŒ æ¨é€å¤±è´¥ - çŠ¶æ€ç  {response.status_code}"
                    )
                    print(f"[Barkæ¨é€] è®¾å¤‡{idx}: å“åº”å†…å®¹: {response.text[:200]}")

            except requests.exceptions.Timeout:
                fail_count += 1
                print(f"[Barkæ¨é€] è®¾å¤‡{idx}: âŒ è¯·æ±‚è¶…æ—¶ ({bark_key[:8]}...)")
            except requests.exceptions.RequestException as e:
                fail_count += 1
                print(
                    f"[Barkæ¨é€] è®¾å¤‡{idx}: âŒ ç½‘ç»œé”™è¯¯ ({bark_key[:8]}...): {str(e)[:100]}"
                )
            except Exception as e:
                fail_count += 1
                print(
                    f"[Barkæ¨é€] è®¾å¤‡{idx}: âŒ æœªçŸ¥é”™è¯¯ ({bark_key[:8]}...): {str(e)[:100]}"
                )

        print(
            f"[Barkæ¨é€] æ¨é€å®Œæˆ: æˆåŠŸ {success_count}/{len(bark_keys)}, å¤±è´¥ {fail_count}/{len(bark_keys)}"
        )

        if success_count > 0:
            print(
                f"âœ“ Barké€šçŸ¥å·²å‘é€åˆ° {success_count}/{len(bark_keys)} ä¸ªè®¾å¤‡: {title}"
            )
        else:
            print(f"âœ— Barké€šçŸ¥å…¨éƒ¨å¤±è´¥ï¼è¯·æ£€æŸ¥ç½‘ç»œæˆ–Bark Keyé…ç½®")

    except Exception as e:
        print(f"âœ— Barkæ¨é€å‡½æ•°å¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()


def send_email_notification(subject, body_html, model_name="DeepSeek"):
    """å‘é€é‚®ä»¶é€šçŸ¥ï¼ˆç”¨äºAIå‚æ•°ä¼˜åŒ–è¯¦ç»†æŠ¥å‘Šï¼‰"""
    try:
        # é‚®ä»¶é…ç½®
        email_config = {
            "smtp_server": "smtp.qq.com",
            "smtp_port": 465,
            "use_ssl": True,
            "username": "1273428868@qq.com",
            "password": "avxuefczxafohdbg",
            "from_address": "1273428868@qq.com",
            "to_address": "baiyuperson@88.com",
        }
        
        print(f"[é‚®ä»¶é€šçŸ¥] å‡†å¤‡å‘é€é‚®ä»¶: {subject}")
        print(f"[é‚®ä»¶é€šçŸ¥] model_nameè¾“å…¥å€¼: {model_name}")
        
        # åˆ›å»ºé‚®ä»¶
        msg = MIMEMultipart('alternative')
        # æ ¹æ®model_nameæ·»åŠ å‰ç¼€ï¼ˆæ˜ å°„ï¼šdeepseek->DeepSeekï¼‰
        display_name = "DeepSeek" if "deepseek" in model_name.lower() else model_name
        print(f"[é‚®ä»¶é€šçŸ¥] æ˜ å°„ådisplay_name: {display_name}")
        msg['Subject'] = f"[{display_name}] {subject}"
        print(f"[é‚®ä»¶é€šçŸ¥] æœ€ç»ˆé‚®ä»¶ä¸»é¢˜: {msg['Subject']}")
        msg['From'] = email_config['from_address']
        msg['To'] = email_config['to_address']
        msg['Date'] = datetime.now().strftime('%a, %d %b %Y %H:%M:%S +0800')
        
        # æ·»åŠ HTMLå†…å®¹
        html_part = MIMEText(body_html, 'html', 'utf-8')
        msg.attach(html_part)
        
        # å‘é€é‚®ä»¶
        if email_config['use_ssl']:
            server = smtplib.SMTP_SSL(email_config['smtp_server'], email_config['smtp_port'], timeout=30)
        else:
            server = smtplib.SMTP(email_config['smtp_server'], email_config['smtp_port'], timeout=30)
        
        server.login(email_config['username'], email_config['password'])
        server.send_message(msg)
        server.quit()
        
        print(f"[é‚®ä»¶é€šçŸ¥] âœ… é‚®ä»¶å‘é€æˆåŠŸ: {subject}")
        return True
        
    except Exception as e:
        print(f"[é‚®ä»¶é€šçŸ¥] âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def save_open_position(trade_info):
    """ä¿å­˜å¼€ä»“è®°å½•ï¼ˆæ–°å¢ï¼‰- åŠ å›ºç‰ˆ"""
    import fcntl
    import shutil
    from pathlib import Path

    # å®šä¹‰æ ‡å‡†åˆ—é¡ºåºï¼Œç¡®ä¿ä¸€è‡´æ€§
    STANDARD_COLUMNS = [
        "å¼€ä»“æ—¶é—´",
        "å¹³ä»“æ—¶é—´",
        "å¸ç§",
        "æ–¹å‘",
        "æ•°é‡",
        "å¼€ä»“ä»·æ ¼",
        "å¹³ä»“ä»·æ ¼",
        "ä»“ä½(U)",
        "æ æ†ç‡",
        "æ­¢æŸ",
        "æ­¢ç›ˆ",
        "ç›ˆäºæ¯”",
        "ç›ˆäº(U)",
        "å¼€ä»“ç†ç”±",
        "å¹³ä»“ç†ç”±",
        "ä¿¡å·åˆ†æ•°",
        "å…±æŒ¯æŒ‡æ ‡æ•°",
    ]

    max_retries = 3
    for attempt in range(max_retries):
        lock_file = None
        try:
            # 1. åˆ›å»ºæ–‡ä»¶é”ï¼Œé¿å…å¹¶å‘å†™å…¥
            lock_path = TRADES_FILE.parent / f"{TRADES_FILE.name}.lock"
            lock_file = open(lock_path, "w")
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)

            # 2. åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœæ–‡ä»¶å­˜åœ¨ï¼‰
            if TRADES_FILE.exists():
                backup_path = TRADES_FILE.parent / f"{TRADES_FILE.name}.backup"
                shutil.copy2(TRADES_FILE, backup_path)

            # 3. åˆ›å»ºæ–°æ•°æ®DataFrameï¼Œç¡®ä¿åˆ—é¡ºåºæ­£ç¡®
            df_new = pd.DataFrame([trade_info])
            # æŒ‰æ ‡å‡†åˆ—é¡ºåºé‡æ–°æ’åˆ—
            df_new = df_new.reindex(columns=STANDARD_COLUMNS)
        
            # 4. è¯»å–ç°æœ‰æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if TRADES_FILE.exists():
                df_existing = pd.read_csv(TRADES_FILE, encoding="utf-8")
                # æ¸…ç†åˆ—åä¸­çš„ç©ºæ ¼å’ŒBOMå­—ç¬¦
                df_existing.columns = df_existing.columns.str.strip().str.replace(
                    "\ufeff", ""
                )
                # ç¡®ä¿åˆ—é¡ºåºä¸€è‡´
                df_existing = df_existing.reindex(columns=STANDARD_COLUMNS)
                # åˆå¹¶æ•°æ®ï¼ˆç§»é™¤ç©ºè¡Œé¿å…FutureWarningï¼‰
                df_combined = pd.concat([df_existing.dropna(how='all'), df_new.dropna(how='all')], ignore_index=True)
            else:
                df_combined = df_new
        
            # 5. ä¿å­˜åˆ°CSVï¼ˆä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼Œç„¶åé‡å‘½åï¼Œç¡®ä¿åŸå­æ“ä½œï¼‰
            temp_file = TRADES_FILE.parent / f"{TRADES_FILE.name}.tmp"
            df_combined.to_csv(temp_file, index=False, encoding="utf-8")

            # 6. åŸå­æ€§æ›¿æ¢æ–‡ä»¶
            temp_file.replace(TRADES_FILE)

            print(f"âœ“ å¼€ä»“è®°å½•å·²ä¿å­˜: {TRADES_FILE}")

            # 7. é‡Šæ”¾æ–‡ä»¶é”
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
            lock_file.close()

            # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
            break

        except BlockingIOError:
            # æ–‡ä»¶è¢«é”å®šï¼Œç­‰å¾…åé‡è¯•
            print(f"âš ï¸ æ–‡ä»¶è¢«é”å®šï¼Œç­‰å¾…é‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
            if lock_file:
                lock_file.close()
            import time

            time.sleep(0.5)
            continue

        except Exception as e:
            print(f"âœ— ä¿å­˜å¼€ä»“è®°å½•å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            import traceback
            traceback.print_exc()

            # å¦‚æœæœ‰å¤‡ä»½ï¼Œå°è¯•æ¢å¤
            backup_path = TRADES_FILE.parent / f"{TRADES_FILE.name}.backup"
            if backup_path.exists() and attempt == max_retries - 1:
                print(f"âš ï¸ å°è¯•ä»å¤‡ä»½æ¢å¤...")
                try:
                    shutil.copy2(backup_path, TRADES_FILE)
                    print(f"âœ“ å·²ä»å¤‡ä»½æ¢å¤")
                except:
                    pass

            # æ¸…ç†é”
            if lock_file:
                try:
                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                    lock_file.close()
                except:
                    pass

            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œä¸å†é‡è¯•
            if attempt == max_retries - 1:
                print(f"âœ— ä¿å­˜å¼€ä»“è®°å½•å¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
                # æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚çŸ¥é“ä¿å­˜å¤±è´¥
                raise
            else:
                import time

                time.sleep(0.5)
                continue


def update_close_position(coin_name, side, close_time, close_price, pnl, close_reason, close_pct=100):
    """æ›´æ–°å¹³ä»“è®°å½•ï¼ˆæ‰¾åˆ°å¯¹åº”çš„å¼€ä»“è®°å½•å¹¶æ›´æ–°ï¼‰- æ”¯æŒåˆ†æ‰¹å¹³ä»“"""
    import fcntl
    import shutil
    from pathlib import Path

    max_retries = 3
    for attempt in range(max_retries):
        lock_file = None
        try:
            # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not TRADES_FILE.exists():
                print(f"âœ— äº¤æ˜“è®°å½•æ–‡ä»¶ä¸å­˜åœ¨")
                return
        
            # 2. åˆ›å»ºæ–‡ä»¶é”ï¼Œé¿å…å¹¶å‘å†™å…¥
            lock_path = TRADES_FILE.parent / f"{TRADES_FILE.name}.lock"
            lock_file = open(lock_path, "w")
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)

            # 3. åˆ›å»ºå¤‡ä»½
            backup_path = TRADES_FILE.parent / f"{TRADES_FILE.name}.backup"
            shutil.copy2(TRADES_FILE, backup_path)

            # 4. è¯»å–ç°æœ‰æ•°æ®
            df = pd.read_csv(TRADES_FILE, encoding="utf-8")
            # æ¸…ç†åˆ—åä¸­çš„ç©ºæ ¼å’ŒBOMå­—ç¬¦
            df.columns = df.columns.str.strip().str.replace("\ufeff", "")

            # 5. æ‰¾åˆ°è¯¥å¸ç§ã€è¯¥æ–¹å‘ã€æœªå¹³ä»“çš„æœ€åä¸€æ¡è®°å½•
            mask = (
                (df["å¸ç§"] == coin_name)
                & (df["æ–¹å‘"] == side)
                & (df["å¹³ä»“æ—¶é—´"].isna())
            )
            matching_rows = df[mask]
        
            if matching_rows.empty:
                print(f"âš ï¸ æœªæ‰¾åˆ° {coin_name} {side} çš„å¼€ä»“è®°å½•")
                # é‡Šæ”¾é”
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                lock_file.close()
                return
        
            # 6. å¤„ç†å¹³ä»“è®°å½•
            last_idx = matching_rows.index[-1]
            original_row = df.loc[last_idx].copy()
            
            if close_pct >= 100:
                # å®Œå…¨å¹³ä»“ï¼šç›´æ¥æ›´æ–°è®°å½•
                df.at[last_idx, "å¹³ä»“æ—¶é—´"] = close_time
                df.at[last_idx, "å¹³ä»“ä»·æ ¼"] = close_price
                df.at[last_idx, "ç›ˆäº(U)"] = pnl
                df.at[last_idx, "å¹³ä»“ç†ç”±"] = close_reason
            else:
                # åˆ†æ‰¹å¹³ä»“ï¼šåˆ›å»ºä¸€æ¡å·²å¹³ä»“è®°å½•ï¼Œä¿ç•™ä¸€æ¡æœªå¹³ä»“è®°å½•
                # æ›´æ–°å½“å‰è®°å½•ä¸ºå·²å¹³ä»“ï¼ˆä»£è¡¨å¹³æ‰çš„éƒ¨åˆ†ï¼‰
                df.at[last_idx, "å¹³ä»“æ—¶é—´"] = close_time
                df.at[last_idx, "å¹³ä»“ä»·æ ¼"] = close_price
                df.at[last_idx, "ç›ˆäº(U)"] = pnl
                df.at[last_idx, "å¹³ä»“ç†ç”±"] = close_reason
                
                # åˆ›å»ºæ–°è®°å½•ä»£è¡¨å‰©ä½™ä»“ä½ï¼ˆå¤åˆ¶åŸè®°å½•ï¼Œæ¸…ç©ºå¹³ä»“ä¿¡æ¯ï¼‰
                remaining_row = original_row.copy()
                remaining_row["å¹³ä»“æ—¶é—´"] = pd.NA
                remaining_row["å¹³ä»“ä»·æ ¼"] = pd.NA
                remaining_row["ç›ˆäº(U)"] = pd.NA
                remaining_row["å¹³ä»“ç†ç”±"] = pd.NA
                remaining_row["å¼€ä»“ç†ç”±"] = original_row["å¼€ä»“ç†ç”±"] + f" [å‰©ä½™{100-close_pct:.0f}%]"
                
                # å°†æ–°è®°å½•è¿½åŠ åˆ°DataFrame
                df = pd.concat([df, pd.DataFrame([remaining_row])], ignore_index=True)
                print(f"  ğŸ“ å·²åˆ›å»ºå‰©ä½™{100-close_pct:.0f}%ä»“ä½çš„æ–°è®°å½•")

            # 7. ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œç„¶ååŸå­æ€§æ›¿æ¢
            temp_file = TRADES_FILE.parent / f"{TRADES_FILE.name}.tmp"
            df.to_csv(temp_file, index=False, encoding="utf-8")
            temp_file.replace(TRADES_FILE)

            print(f"âœ“ å¹³ä»“è®°å½•å·²æ›´æ–°: {TRADES_FILE}")

            # 8. é‡Šæ”¾æ–‡ä»¶é”
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
            lock_file.close()

            # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
            break

        except BlockingIOError:
            # æ–‡ä»¶è¢«é”å®šï¼Œç­‰å¾…åé‡è¯•
            print(f"âš ï¸ æ–‡ä»¶è¢«é”å®šï¼Œç­‰å¾…é‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
            if lock_file:
                lock_file.close()
            import time

            time.sleep(0.5)
            continue

        except Exception as e:
            print(f"âœ— æ›´æ–°å¹³ä»“è®°å½•å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            import traceback
            traceback.print_exc()

            # å¦‚æœæœ‰å¤‡ä»½ï¼Œå°è¯•æ¢å¤
            backup_path = TRADES_FILE.parent / f"{TRADES_FILE.name}.backup"
            if backup_path.exists() and attempt == max_retries - 1:
                print(f"âš ï¸ å°è¯•ä»å¤‡ä»½æ¢å¤...")
                try:
                    shutil.copy2(backup_path, TRADES_FILE)
                    print(f"âœ“ å·²ä»å¤‡ä»½æ¢å¤")
                except:
                    pass

            # æ¸…ç†é”
            if lock_file:
                try:
                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                    lock_file.close()
                except:
                    pass

            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
            if attempt == max_retries - 1:
                print(f"âœ— æ›´æ–°å¹³ä»“è®°å½•å¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
                # æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚çŸ¥é“æ›´æ–°å¤±è´¥
                raise
            else:
                import time

                time.sleep(0.5)
                continue


def save_positions_snapshot(positions, total_value):
    """ä¿å­˜å½“å‰æŒä»“å¿«ç…§ï¼ˆåŒ…å«å®Œæ•´äº¤æ˜“ä¿¡æ¯ï¼šå¼€ä»“æ—¶é—´ã€æ­¢ç›ˆæ­¢æŸã€å¼€ä»“ç†ç”±ç­‰ï¼‰"""
    try:
        records = []
        for pos in positions:
            records.append(
                {
                    "æ›´æ–°æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "å¼€ä»“æ—¶é—´": pos.get("open_time", ""),
                    "å¸ç§": pos["symbol"].split("/")[0],
                    "æ–¹å‘": "å¤š" if pos["side"] == "long" else "ç©º",
                    "æ•°é‡": pos["size"],
                    "å¼€ä»“ä»·": pos["entry_price"],
                    "å½“å‰ç›ˆäº(U)": pos["unrealized_pnl"],
                    "æ æ†": pos["leverage"],
                    "ä¿è¯é‡‘(U)": pos.get("margin", 0),
                    "æ­¢æŸ": pos.get("stop_loss", 0),
                    "æ­¢ç›ˆ": pos.get("take_profit", 0),
                    "ç›ˆäºæ¯”": pos.get("risk_reward", 0),
                    "å¼€ä»“ç†ç”±": pos.get("open_reason", ""),
                }
            )
        
        if records:
            df = pd.DataFrame(records)
            df.to_csv(POSITIONS_FILE, index=False, encoding="utf-8")
        else:
            # æ— æŒä»“æ—¶æ¸…ç©ºæ–‡ä»¶
            pd.DataFrame(
                columns=[
                    "æ›´æ–°æ—¶é—´",
                    "å¼€ä»“æ—¶é—´",
                    "å¸ç§",
                    "æ–¹å‘",
                    "æ•°é‡",
                    "å¼€ä»“ä»·",
                    "å½“å‰ç›ˆäº(U)",
                    "æ æ†",
                    "ä¿è¯é‡‘(U)",
                    "æ­¢æŸ",
                    "æ­¢ç›ˆ",
                    "ç›ˆäºæ¯”",
                    "å¼€ä»“ç†ç”±",
                ]
            ).to_csv(POSITIONS_FILE, index=False, encoding="utf-8")
        
        print(f"âœ“ æŒä»“å¿«ç…§å·²æ›´æ–°: {POSITIONS_FILE}")
    except Exception as e:
        print(f"âœ— ä¿å­˜æŒä»“å¿«ç…§å¤±è´¥: {e}")


def clear_symbol_orders(symbol, verbose=True):
    """
    V7.9.3 æ¸…ç†æŒ‡å®šå¸ç§çš„æ‰€æœ‰æ­¢æŸæ­¢ç›ˆè®¢å•ï¼ˆåŒ…æ‹¬æ¡ä»¶å•ï¼‰
    
    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚ BTC/USDT:USDTï¼‰
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
    
    Returns:
        (æˆåŠŸæ•°é‡, å¤±è´¥æ•°é‡)
    """
    success_count = 0
    fail_count = 0
    
    # ç¬¬1æ­¥ï¼šå–æ¶ˆæ™®é€šè®¢å•
    try:
        open_orders = exchange.fetch_open_orders(symbol)
        if verbose and len(open_orders) > 0:
            print(f"  å‘ç° {len(open_orders)} ä¸ªæ™®é€šè®¢å•")
        
        for order in open_orders:
            order_type = order.get('type', '').upper()
            order_id = order.get('id', '')
            
            # ğŸ”§ ä¿®å¤ï¼šreduceOnly å¯èƒ½æ˜¯å­—ç¬¦ä¸² "true" æˆ–å¸ƒå°”å€¼ True
            reduce_only = order['info'].get('reduceOnly')
            is_reduce_only = (reduce_only == True or reduce_only == 'true' or reduce_only == 'True')
            
            # è¯†åˆ«æ­¢æŸæ­¢ç›ˆè®¢å•ç±»å‹
            is_tp_sl_type = order_type in [
                'STOP_MARKET',
                'TAKE_PROFIT_MARKET',
                'STOP',
                'TAKE_PROFIT',
                'TRAILING_STOP_MARKET',
            ]
            
            # æ¸…ç†æ‰€æœ‰æ­¢æŸæ­¢ç›ˆç›¸å…³è®¢å•
            if is_reduce_only or is_tp_sl_type:
                try:
                    exchange.cancel_order(order_id, symbol)
                    success_count += 1
                    if verbose:
                        short_id = order_id[:8] + '...' if len(order_id) > 8 else order_id
                        print(f"  âœ“ å·²å–æ¶ˆæ™®é€šè®¢å•: {order_type} (ID: {short_id})")
                except Exception as e:
                    fail_count += 1
                    if verbose:
                        err_msg = str(e)[:50]
                        print(f"  âŒ å–æ¶ˆå¤±è´¥: {order_type} - {err_msg}")
    except Exception as e:
        if verbose:
            print(f"  âš ï¸ æŸ¥è¯¢æ™®é€šè®¢å•å¼‚å¸¸: {e}")
    
    # ç¬¬2æ­¥ï¼šå–æ¶ˆæ¡ä»¶å•ï¼ˆPortfolio Marginç‰¹æœ‰ï¼‰
    # æ¡ä»¶å•æ˜¯æ­¢æŸ/æ­¢ç›ˆç­–ç•¥è®¢å•ï¼Œéœ€è¦ä½¿ç”¨ä¸“é—¨çš„API
    try:
        # è½¬æ¢symbolæ ¼å¼: BTC/USDT:USDT -> BTCUSDT
        if '/' in symbol:
            binance_symbol = symbol.split('/')[0] + symbol.split(':')[0].split('/')[1]
        else:
            binance_symbol = symbol
        
        # ä½¿ç”¨ccxtçš„åº•å±‚æ–¹æ³•è°ƒç”¨papi API
        # GET /papi/v1/um/conditional/openOrders
        timestamp = int(time.time() * 1000)
        
        # å°è¯•æŸ¥è¯¢æ¡ä»¶å•
        try:
            params = {
                'symbol': binance_symbol,
                'timestamp': timestamp
            }
            
            # æŒ‰å­—æ¯é¡ºåºæ’åºå¹¶ç”Ÿæˆquery string
            sorted_params = sorted(params.items())
            query_string = urlencode(sorted_params)
            
            # ç”Ÿæˆç­¾å
            signature = hmac.new(
                exchange.secret.encode('utf-8'),
                query_string.encode('utf-8'),
                hashlib.sha256
            ).hexdigest()
            
            # æ„å»ºå®Œæ•´URL
            url = f"https://papi.binance.com/papi/v1/um/conditional/openOrders?{query_string}&signature={signature}"
            
            headers = {'X-MBX-APIKEY': exchange.apiKey}
            response = requests.get(url, headers=headers)
            
            if response.status_code == 200:
                conditional_orders = response.json()
                
                if verbose and len(conditional_orders) > 0:
                    print(f"  å‘ç° {len(conditional_orders)} ä¸ªæ¡ä»¶å•")
                
                for order in conditional_orders:
                    strategy_id = order.get('strategyId')
                    strategy_type = order.get('strategyType', 'N/A')
                    reduce_only = order.get('reduceOnly')
                    order_status = order.get('strategyStatus', 'UNKNOWN')
                    
                    # å°è¯•å–æ¶ˆæ‰€æœ‰reduceOnlyçš„æ¡ä»¶å•ï¼ˆå·²æˆäº¤/å·²å–æ¶ˆä¼šè¿”å›400ï¼Œå·²å¤„ç†ä¸ºä¸æŠ¥é”™ï¼‰
                    if reduce_only:
                        try:
                            # DELETE /papi/v1/um/conditional/order
                            cancel_timestamp = int(time.time() * 1000)
                            
                            cancel_params = {
                                'symbol': binance_symbol,
                                'strategyId': int(strategy_id),
                                'timestamp': cancel_timestamp
                            }
                            
                            # æŒ‰å­—æ¯é¡ºåºæ’åºå¹¶ç”Ÿæˆquery string
                            sorted_params = sorted(cancel_params.items())
                            cancel_query = urlencode(sorted_params)
                            
                            # ç”Ÿæˆç­¾å
                            cancel_signature = hmac.new(
                                exchange.secret.encode('utf-8'),
                                cancel_query.encode('utf-8'),
                                hashlib.sha256
                            ).hexdigest()
                            
                            # æ„å»ºå®Œæ•´URL
                            url = f"https://papi.binance.com/papi/v1/um/conditional/order?{cancel_query}&signature={cancel_signature}"
                            
                            # è°ƒç”¨å–æ¶ˆAPI
                            cancel_response = requests.delete(url, headers=headers)
                            
                            if cancel_response.status_code == 200:
                                success_count += 1
                                if verbose:
                                    print(f"  âœ“ å·²å–æ¶ˆæ¡ä»¶å•: {strategy_type} (ç­–ç•¥ID: {strategy_id})")
                            elif cancel_response.status_code == 400:
                                # HTTP 400é€šå¸¸è¡¨ç¤ºè®¢å•å·²æˆäº¤æˆ–å·²å–æ¶ˆï¼Œä¸è®¡å…¥å¤±è´¥
                                if verbose:
                                    try:
                                        error_detail = cancel_response.json().get('msg', 'è®¢å•çŠ¶æ€ä¸å…è®¸å–æ¶ˆ')
                                    except:
                                        error_detail = 'è®¢å•çŠ¶æ€ä¸å…è®¸å–æ¶ˆ'
                                    
                                    if 'ä¸å­˜åœ¨' in error_detail or 'does not exist' in error_detail.lower() or 'filled' in error_detail.lower():
                                        print(f"  â„¹ï¸ æ¡ä»¶å•å·²å¤„ç†: {strategy_type} (å·²æˆäº¤æˆ–å·²å–æ¶ˆ)")
                                    else:
                                        print(f"  âš ï¸ å–æ¶ˆæ¡ä»¶å•è·³è¿‡: {strategy_type} - {error_detail[:50]}")
                            else:
                                fail_count += 1
                                if verbose:
                                    print(f"  âŒ å–æ¶ˆæ¡ä»¶å•å¤±è´¥: {strategy_type} - HTTP {cancel_response.status_code}")
                        except Exception as e:
                            fail_count += 1
                            if verbose:
                                print(f"  âŒ å–æ¶ˆæ¡ä»¶å•å¤±è´¥: {str(e)[:50]}")
        except Exception as e:
            # æ¡ä»¶å•æŸ¥è¯¢å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹
            if verbose:
                error_msg = str(e)
                if "does not exist" not in error_msg:
                    print(f"  âš ï¸ æŸ¥è¯¢æ¡ä»¶å•å¼‚å¸¸: {error_msg[:50]}")
    except Exception as e:
        if verbose:
            print(f"  âš ï¸ å¤„ç†æ¡ä»¶å•å¼‚å¸¸: {str(e)[:50]}")
    
    # æ±‡æ€»ç»“æœ
    if verbose and (success_count > 0 or fail_count > 0):
        print(f"  æ¸…ç†å®Œæˆ: æˆåŠŸ{success_count}ä¸ª, å¤±è´¥{fail_count}ä¸ª")
    elif verbose and success_count == 0 and fail_count == 0:
        print(f"  æ— éœ€è¦æ¸…ç†çš„è®¢å•")
    
    return success_count, fail_count


def _precision_to_decimal_places(precision_value):
    """
    å°†precisionå€¼è½¬æ¢ä¸ºå°æ•°ä½æ•°ï¼ˆæ•´æ•°ï¼‰
    
    Binance APIå¯èƒ½è¿”å›ä¸¤ç§æ ¼å¼ï¼š
    - æ•´æ•°ï¼šå¦‚ 2 è¡¨ç¤º2ä½å°æ•°
    - æµ®ç‚¹æ•°ï¼šå¦‚ 0.01 è¡¨ç¤º2ä½å°æ•°ï¼Œ0.001 è¡¨ç¤º3ä½å°æ•°
    
    Args:
        precision_value: æ•´æ•°æˆ–æµ®ç‚¹æ•°
    
    Returns:
        int: å°æ•°ä½æ•°
    """
    if isinstance(precision_value, int):
        return precision_value
    elif isinstance(precision_value, float):
        # é€šè¿‡è®¡ç®—æµ®ç‚¹æ•°çš„å°æ•°ä½æ•°æ¥ç¡®å®šç²¾åº¦
        # ä¾‹å¦‚: 0.01 -> 2, 0.001 -> 3, 0.1 -> 1
        import math
        if precision_value <= 0:
            return 0
        return max(0, int(round(-math.log10(precision_value))))
    else:
        return 2  # é»˜è®¤2ä½å°æ•°


def set_tpsl_orders_via_papi(symbol: str, side: str, amount: float, stop_loss: float = None, take_profit: float = None, verbose: bool = True):
    """
    V7.9.3 é€šè¿‡papiç«¯ç‚¹ä¸ºä»“ä½è®¾ç½®æ­¢ç›ˆæ­¢æŸè®¢å•ï¼ˆV8.5.1.3: æ·»åŠ ç²¾åº¦å¤„ç†ï¼‰
    
    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚ BTC/USDT:USDTï¼‰
        side: ä»“ä½æ–¹å‘ 'long' æˆ– 'short'
        amount: è®¢å•æ•°é‡
        stop_loss: æ­¢æŸä»·æ ¼
        take_profit: æ­¢ç›ˆä»·æ ¼
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
    
    Returns:
        (æ­¢æŸæˆåŠŸ, æ­¢ç›ˆæˆåŠŸ)
    """
    sl_success = False
    tp_success = False
    
    # è½¬æ¢symbolæ ¼å¼: BTC/USDT:USDT -> BTCUSDT
    if '/' in symbol:
        binance_symbol = symbol.split('/')[0] + symbol.split(':')[0].split('/')[1]
    else:
        binance_symbol = symbol
    
    # ğŸ†• V8.5.1.3: è·å–å¸‚åœºç²¾åº¦ä¿¡æ¯
    try:
        markets = exchange.load_markets()
        market_info = markets.get(symbol, {})
        amount_precision_raw = market_info.get('precision', {}).get('amount', 3)
        price_precision_raw = market_info.get('precision', {}).get('price', 2)
        
        # ğŸ”§ V8.5.1.4: è½¬æ¢precisionä¸ºæ•´æ•°ï¼ˆæ”¯æŒæµ®ç‚¹æ•°æ ¼å¼ï¼‰
        amount_precision = _precision_to_decimal_places(amount_precision_raw)
        price_precision = _precision_to_decimal_places(price_precision_raw)
        
        # å¯¹æ•°é‡å’Œä»·æ ¼è¿›è¡Œç²¾åº¦èˆå…¥
        amount = round(amount, amount_precision)
        if stop_loss:
            stop_loss = round(stop_loss, price_precision)
        if take_profit:
            take_profit = round(take_profit, price_precision)
    except Exception as e:
        if verbose:
            print(f"  âš ï¸ è·å–å¸‚åœºç²¾åº¦å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
        # ä½¿ç”¨é»˜è®¤ç²¾åº¦
        amount = round(amount, 3)
        if stop_loss:
            stop_loss = round(stop_loss, 2)
        if take_profit:
            take_profit = round(take_profit, 2)
    
    # å¹³ä»“æ–¹å‘ï¼ˆä¸æŒä»“ç›¸åï¼‰
    close_side = 'SELL' if side == 'long' else 'BUY'
    
    headers = {'X-MBX-APIKEY': exchange.apiKey}
    
    # 1. è®¾ç½®æ­¢æŸè®¢å•ï¼ˆä½¿ç”¨STOP_MARKETï¼‰
    if stop_loss and stop_loss > 0:
        try:
            timestamp = int(time.time() * 1000)
            params = {
                'symbol': binance_symbol,
                'side': close_side,
                'strategyType': 'STOP_MARKET',
                'stopPrice': str(stop_loss),
                'quantity': str(amount),
                'reduceOnly': 'true',
                'timestamp': timestamp
            }
            
            # æŒ‰å­—æ¯é¡ºåºæ’åºå¹¶ç”Ÿæˆquery string
            sorted_params = sorted(params.items())
            query_string = urlencode(sorted_params)
            
            # ç”Ÿæˆç­¾å
            signature = hmac.new(
                exchange.secret.encode('utf-8'),
                query_string.encode('utf-8'),
                hashlib.sha256
            ).hexdigest()
            
            # æ„å»ºå®Œæ•´URL
            url = f"https://papi.binance.com/papi/v1/um/conditional/order?{query_string}&signature={signature}"
            response = requests.post(url, headers=headers)
            
            if response.status_code == 200:
                sl_success = True
                if verbose:
                    print(f"  âœ“ æ­¢æŸå•å·²è®¾ç½®: ${stop_loss:,.2f} (papi)")
            else:
                if verbose:
                    print(f"  âŒ æ­¢æŸå•è®¾ç½®å¤±è´¥: HTTP {response.status_code} - {response.text[:100]}")
        except Exception as e:
            if verbose:
                print(f"  âŒ æ­¢æŸå•è®¾ç½®å¼‚å¸¸: {str(e)[:80]}")
    
    # 2. è®¾ç½®æ­¢ç›ˆè®¢å•ï¼ˆä½¿ç”¨TAKE_PROFIT_MARKETï¼‰
    if take_profit and take_profit > 0:
        try:
            timestamp = int(time.time() * 1000)
            params = {
                'symbol': binance_symbol,
                'side': close_side,
                'strategyType': 'TAKE_PROFIT_MARKET',
                'stopPrice': str(take_profit),
                'quantity': str(amount),
                'reduceOnly': 'true',
                'timestamp': timestamp
            }
            
            # æŒ‰å­—æ¯é¡ºåºæ’åºå¹¶ç”Ÿæˆquery string
            sorted_params = sorted(params.items())
            query_string = urlencode(sorted_params)
            
            # ç”Ÿæˆç­¾å
            signature = hmac.new(
                exchange.secret.encode('utf-8'),
                query_string.encode('utf-8'),
                hashlib.sha256
            ).hexdigest()
            
            # æ„å»ºå®Œæ•´URL
            url = f"https://papi.binance.com/papi/v1/um/conditional/order?{query_string}&signature={signature}"
            response = requests.post(url, headers=headers)
            
            if response.status_code == 200:
                tp_success = True
                if verbose:
                    print(f"  âœ“ æ­¢ç›ˆå•å·²è®¾ç½®: ${take_profit:,.2f} (papi)")
            else:
                if verbose:
                    print(f"  âŒ æ­¢ç›ˆå•è®¾ç½®å¤±è´¥: HTTP {response.status_code} - {response.text[:100]}")
        except Exception as e:
            if verbose:
                print(f"  âŒ æ­¢ç›ˆå•è®¾ç½®å¼‚å¸¸: {str(e)[:80]}")
    
    return sl_success, tp_success


def sync_csv_with_exchange_positions(current_positions):
    """
    åŒæ­¥CSVè®°å½•å’Œäº¤æ˜“æ‰€å®é™…æŒä»“
    æ£€æµ‹è¢«æ­¢æŸ/æ­¢ç›ˆè‡ªåŠ¨å¹³æ‰çš„æŒä»“ï¼Œæ›´æ–°CSVè®°å½•
    """
    try:
        # 1. è¯»å–CSVä¸­æœªå¹³ä»“çš„è®°å½•
        if not TRADES_FILE.exists():
            return
        
        df = pd.read_csv(TRADES_FILE, encoding="utf-8")
        df.columns = df.columns.str.strip().str.replace("\ufeff", "")
        
        # æ‰¾å‡ºæœªå¹³ä»“çš„è®°å½•
        open_trades = df[df["å¹³ä»“æ—¶é—´"].isna()]
        
        if open_trades.empty:
            return
        
        # 2. æ„å»ºäº¤æ˜“æ‰€å®é™…æŒä»“çš„æ˜ å°„
        exchange_positions = {}
        for pos in current_positions:
            coin = pos["symbol"].split("/")[0]
            side = "å¤š" if pos["side"] == "long" else "ç©º"
            key = f"{coin}_{side}"
            exchange_positions[key] = pos
        
        # 3. å¯¹æ¯”æ‰¾å‡ºCSVæœ‰ä½†äº¤æ˜“æ‰€æ²¡æœ‰çš„æŒä»“
        synced_count = 0
        for idx, trade in open_trades.iterrows():
            coin = trade.get("å¸ç§", "")
            side = trade.get("æ–¹å‘", "")
            key = f"{coin}_{side}"
            
            # å¦‚æœCSVæœ‰è®°å½•ä½†äº¤æ˜“æ‰€æ²¡æœ‰æŒä»“ï¼Œè¯´æ˜å·²è¢«è‡ªåŠ¨å¹³ä»“
            if key not in exchange_positions:
                symbol = f"{coin}/USDT:USDT"
                
                print(f"âš ï¸ æ£€æµ‹åˆ°{coin} {side}ä»“å·²è¢«è‡ªåŠ¨å¹³ä»“ï¼Œæ­£åœ¨åŒæ­¥CSV...")
                
                # ğŸ†• å°è¯•ä»äº¤æ˜“æ‰€è·å–å®é™…å¹³ä»“ä¿¡æ¯
                close_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                close_price = 0
                pnl = 0
                
                try:
                    # è·å–è¯¥å¸ç§æœ€è¿‘çš„æˆäº¤è®°å½•
                    recent_trades = exchange.fetch_my_trades(symbol, limit=20)
                    
                    # æ‰¾åˆ°å¹³ä»“ç›¸å…³çš„æˆäº¤ï¼ˆsellä¸ºå¹³å¤šï¼Œbuyä¸ºå¹³ç©ºï¼‰
                    expected_side = "sell" if side == "å¤š" else "buy"
                    
                    for t in reversed(recent_trades):  # ä»æœ€æ–°å¾€å‰æ‰¾
                        if t['side'] == expected_side:
                            close_price = float(t['price'])
                            close_time = datetime.fromtimestamp(t['timestamp']/1000).strftime("%Y-%m-%d %H:%M:%S")
                            
                            # è®¡ç®—ç›ˆäºï¼šéœ€è¦å¼€ä»“ä»·
                            open_price = float(trade.get("å¼€ä»“ä»·æ ¼", 0) or 0)
                            amount = float(trade.get("æ•°é‡", 0) or 0)
                            
                            if open_price > 0 and amount > 0:
                                if side == "å¤š":
                                    pnl = (close_price - open_price) * amount
                                else:  # ç©º
                                    pnl = (open_price - close_price) * amount
                            
                            print(f"  âœ“ æ‰¾åˆ°å®é™…å¹³ä»“è®°å½•: ${close_price:.2f} @ {close_time}, ç›ˆäº{pnl:+.2f}U")
                            break
                except Exception as e:
                    print(f"  âš ï¸ è·å–æˆäº¤è®°å½•å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
                
                # æ¸…ç†æ®‹ç•™è®¢å•ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„è®¢å•æ¸…ç†å‡½æ•°ï¼‰
                try:
                    print("  æ­£åœ¨æ¸…ç†æ®‹ç•™çš„æ­¢æŸæ­¢ç›ˆè®¢å•...")
                    success, fail = clear_symbol_orders(symbol, verbose=True)
                except Exception as e:
                    print(f"  âš ï¸ æ¸…ç†è®¢å•å¤±è´¥: {e}")
                
                # æ›´æ–°CSVè®°å½•
                update_close_position(
                    coin,
                    side,
                    close_time,
                    close_price,
                    pnl,
                    "ç³»ç»Ÿæ£€æµ‹ï¼šå·²è¢«æ­¢æŸ/æ­¢ç›ˆè‡ªåŠ¨å¹³ä»“",
                )
                
                # ã€V7.9æ–°å¢ã€‘å‘é€Barké€šçŸ¥ï¼ˆç³»ç»Ÿè‡ªåŠ¨å¹³ä»“ï¼‰
                try:
                    # ä»tradeè·å–å¼€ä»“ä¿¡æ¯
                    open_time_str = trade.get('å¼€ä»“æ—¶é—´', '')
                    entry_price = float(trade.get('å¼€ä»“ä»·æ ¼', 0) or 0)
                    
                    # è¯»å–ä¿¡å·ç±»å‹å’ŒæŒä»“æ—¶é—´
                    signal_type = 'unknown'
                    expected_holding = 0
                    actual_holding_minutes = 0
                    
                    # ä»position_contextsè¯»å–
                    model_name = os.getenv("MODEL_NAME", "deepseek")
                    context_file = Path("trading_data") / model_name / "position_contexts.json"
                    if context_file.exists():
                        with open(context_file, 'r', encoding='utf-8') as f:
                            contexts = json.load(f)
                            if coin in contexts:
                                signal_type = contexts[coin].get('signal_type', 'unknown')
                                expected_holding = contexts[coin].get('expected_holding_minutes', 0)
                    
                    # è®¡ç®—å®é™…æŒä»“æ—¶é—´
                    if isinstance(open_time_str, str) and open_time_str:
                        open_dt = datetime.strptime(open_time_str, "%Y-%m-%d %H:%M:%S")
                        close_dt = datetime.strptime(close_time, "%Y-%m-%d %H:%M:%S")
                        actual_holding_minutes = (close_dt - open_dt).total_seconds() / 60
                    
                    # æ ¼å¼åŒ–é€šçŸ¥
                    type_emoji = "âš¡" if signal_type == 'scalping' else "ğŸŒŠ" if signal_type == 'swing' else "â“"
                    pnl_emoji = "ğŸ“ˆ" if pnl > 0 else "ğŸ“‰"
                    
                    # åˆ¤æ–­æ˜¯å¦è¾¾æ ‡
                    è¾¾æ ‡çŠ¶æ€ = ""
                    if expected_holding > 0 and actual_holding_minutes > 0:
                        diff_pct = (actual_holding_minutes / expected_holding - 1) * 100
                        if abs(diff_pct) < 20:
                            è¾¾æ ‡çŠ¶æ€ = "âœ“è¾¾æ ‡"
                        elif diff_pct < 0:
                            è¾¾æ ‡çŠ¶æ€ = f"âš ï¸æ—©å¹³{abs(diff_pct):.0f}%"
                        else:
                            è¾¾æ ‡çŠ¶æ€ = f"â°è¶…æ—¶{diff_pct:.0f}%"
                    
                    # åˆ¤æ–­æ˜¯æ­¢ç›ˆè¿˜æ˜¯æ­¢æŸ
                    if pnl > 0:
                        è§¦å‘ç±»å‹ = "æ­¢ç›ˆ"
                    else:
                        è§¦å‘ç±»å‹ = "æ­¢æŸ"
                    
                    # ä¸­æ–‡åŒ–ç±»å‹åç§°
                    type_name_cn = "è¶…çŸ­çº¿" if signal_type == 'scalping' else "æ³¢æ®µ" if signal_type == 'swing' else "æœªçŸ¥"
                    send_bark_notification(
                        f"[DeepSeek]{coin}è‡ªåŠ¨å¹³ä»“{pnl_emoji}",
                        f"{side}ä»“ {è§¦å‘ç±»å‹}è§¦å‘ {pnl:+.2f}U\n{type_emoji}{type_name_cn} {actual_holding_minutes:.0f}åˆ† {è¾¾æ ‡çŠ¶æ€}\nå¼€${entry_price:.0f}â†’å¹³${close_price:.0f}"
                            )
                except Exception as e:
                    print(f"  âš ï¸ å‘é€Barké€šçŸ¥å¤±è´¥: {e}")
                
                # æ¸…ç†å†³ç­–ä¸Šä¸‹æ–‡
                try:
                    clear_position_context(coin=coin)
                except:
                    pass
                
                synced_count += 1
        
        if synced_count > 0:
            print(f"âœ“ CSVåŒæ­¥å®Œæˆï¼Œæ›´æ–°äº† {synced_count} æ¡è‡ªåŠ¨å¹³ä»“è®°å½•")
        
    except Exception as e:
        print(f"âš ï¸ CSVåŒæ­¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def save_system_status(status_data):
    """ä¿å­˜ç³»ç»ŸçŠ¶æ€"""
    try:
        with open(STATUS_FILE, "w", encoding="utf-8") as f:
            json.dump(status_data, f, ensure_ascii=False, indent=2)
        print(f"âœ“ ç³»ç»ŸçŠ¶æ€å·²æ›´æ–°: {STATUS_FILE}")
    except Exception as e:
        print(f"âœ— ä¿å­˜ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")


def save_ai_decision(decision_data):
    """ä¿å­˜AIå†³ç­–å†å²"""
    try:
        decision_record = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ€è€ƒè¿‡ç¨‹": decision_data.get("æ€è€ƒè¿‡ç¨‹", ""),
            "analysis": decision_data.get("analysis", ""),
            "risk_assessment": decision_data.get("risk_assessment", ""),
            "actions": decision_data.get("actions", []),
        }
        
        # åŠ è½½ç°æœ‰å†å²
        if AI_DECISIONS_FILE.exists():
            with open(AI_DECISIONS_FILE, "r", encoding="utf-8") as f:
                history = json.load(f)
        else:
            history = []
        
        # æ·»åŠ æ–°è®°å½•
        history.append(decision_record)
        
        # ğŸ”§ V8.3.32.9: ä¿ç•™æœ€è¿‘200æ¡ï¼ˆè¦†ç›–çº¦2å¤©ï¼Œæ¯å¤©96æ¡ï¼‰
        if len(history) > 200:
            history = history[-200:]
        
        # ä¿å­˜
        with open(AI_DECISIONS_FILE, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        print(f"âœ“ AIå†³ç­–å·²è®°å½•: {AI_DECISIONS_FILE}")
    except Exception as e:
        print(f"âœ— ä¿å­˜AIå†³ç­–å¤±è´¥: {e}")


def save_pnl_snapshot(current_positions, balance, total_position_value):
    """ä¿å­˜ç›ˆäºå¿«ç…§ï¼ˆç”¨äºç»˜åˆ¶æŠ˜çº¿å›¾ï¼‰"""
    try:
        total_pnl = sum(p["unrealized_pnl"] for p in current_positions)
        
        snapshot = {
            "æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "ä½™é¢": balance,
            "æ€»ä»“ä½ä»·å€¼": total_position_value,
            "æœªå®ç°ç›ˆäº": total_pnl,
            "æ€»èµ„äº§": balance + total_pnl,
        }
        
        df_new = pd.DataFrame([snapshot])
        
        if PNL_HISTORY_FILE.exists():
            df_existing = pd.read_csv(PNL_HISTORY_FILE)
            df_combined = pd.concat([df_existing.dropna(how='all'), df_new.dropna(how='all')], ignore_index=True)
        else:
            df_combined = df_new
        
        # åªä¿ç•™æœ€è¿‘1000æ¡è®°å½•
        if len(df_combined) > 1000:
            df_combined = df_combined.tail(1000)
        
        df_combined.to_csv(PNL_HISTORY_FILE, index=False, encoding="utf-8")
        print(f"âœ“ ç›ˆäºå¿«ç…§å·²ä¿å­˜: {PNL_HISTORY_FILE}")
    except Exception as e:
        print(f"âœ— ä¿å­˜ç›ˆäºå¿«ç…§å¤±è´¥: {e}")


def get_default_config():
    """è·å–é»˜è®¤é…ç½®ï¼ˆåˆ†å±‚ç»“æ„ï¼‰V7.7.0.19æ‰©å±•"""
    return {
        "version": "2.1",  # ğŸ”§ V7.7.0.19: é…ç½®ç‰ˆæœ¬å‡çº§
        "last_update": None,
        # === å…¨å±€å‚æ•°ï¼ˆæ‰€æœ‰å¸ç§çš„å…œåº•é…ç½®ï¼‰ ===
        "global": {
            # é£é™©æ§åˆ¶ ã€V7.8ä¼˜åŒ–ã€‘æé«˜ç›ˆäºæ¯”è¦æ±‚ï¼Œç¡®ä¿é«˜è´¨é‡æœºä¼š
            "min_risk_reward": 3.0,  # ä»1.5æé«˜åˆ°3.0
            "atr_stop_multiplier": 1.5,
            "max_loss_per_trade": 0.02,  # å•ç¬”æœ€å¤§äºæŸ2%
            "max_consecutive_losses": 3,  # æœ€å¤§è¿ç»­äºæŸ
            "trailing_stop_trigger": 1.5,  # ç›ˆåˆ©1.5%å¯åŠ¨ç§»åŠ¨æ­¢æŸ
            # ä»“ä½ç®¡ç†
            "base_position_ratio": 0.20,  # åŸºç¡€ä»“ä½20%
            "max_position_ratio": 0.30,  # æœ€å¤§å•ç¬”30%
            "high_signal_multiplier": 1.5,  # HIGHä¿¡å·åŠ ä»“
            "max_total_positions": 3,  # æœ€å¤š3ä¸ªä»“ä½
            # è¿›åœºæ—¶æœº ã€V7.8ä¼˜åŒ–ã€‘é™ä½å…±æŒ¯è¦æ±‚ï¼Œé…åˆè¶‹åŠ¿å¼ºåº¦è¯„åˆ†
            "min_indicator_consensus": 2,  # ä»4é™åˆ°2ï¼Œä½†è¦æ±‚æ›´é«˜ç›ˆäºæ¯”
            "key_level_penalty": 1.0,  # å…³é”®ä½æƒ©ç½š
            "min_trend_strength": 0.6,  # æœ€å°è¶‹åŠ¿å¼ºåº¦
            "require_candlestick_signal": False,  # ä¸å¼ºåˆ¶è¦æ±‚è£¸K
            # å‡ºåœºç­–ç•¥
            "partial_take_profit": True,  # åˆ†æ‰¹æ­¢ç›ˆ
            "max_hold_time_hours": 24,  # æœ€å¤§æŒä»“24å°æ—¶
            "close_on_opposite_signal": True,  # åå‘ä¿¡å·å¹³ä»“
            # AIå†³ç­–è´¨é‡ ã€V7.8ä¼˜åŒ–ã€‘é™ä½åˆ†æ•°è¦æ±‚ï¼Œå› ä¸ºæ–°å¢äº†è¶‹åŠ¿å¼ºåº¦è¯„åˆ†
            "min_signal_score": 55,  # ä»70é™åˆ°55ï¼ˆç¡®ä¿èƒ½æ•è·æ›´å¤šé«˜è´¨é‡æœºä¼šï¼‰
            
            # ğŸ†• V7.7.0.19: YTCå‰æå¤±æ•ˆé˜ˆå€¼ï¼ˆå¯AIä¼˜åŒ–ï¼‰
            "invalidation_thresholds": {
                "momentum_slope_min": 0.05,      # æœ€å°åŠ¨èƒ½é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼è§†ä¸ºåœæ»ï¼‰
                "min_profit_threshold": 5,       # æœ€å°ç›ˆåˆ©é˜ˆå€¼ï¼ˆç¾å…ƒï¼‰
                "max_holding_hours": 24,         # æœ€å¤§æŒä»“æ—¶é—´ï¼ˆå°æ—¶ï¼‰
                "time_invalidation_pct": 0.8,    # æ—¶é—´å¤±æ•ˆæ¯”ä¾‹ï¼ˆ80%ï¼‰
                "reversal_confidence_min": 0.7,  # åè½¬ä¿¡å·æœ€ä½ç½®ä¿¡åº¦
                "allow_ai_confirmation": True,   # ç³»ç»Ÿåˆ¤æ–­å‰æå¤±æ•ˆæ—¶ï¼Œæ˜¯å¦è¯·æ±‚AIç¡®è®¤
            },
            
            # ğŸ†• V7.7.0.19: æ­¢æŸæ­¢ç›ˆåŠ¨æ€è°ƒæ•´ç­–ç•¥
            "tp_sl_strategy": {
                "allow_dynamic_adjustment": True,    # æ˜¯å¦å…è®¸æŒä»“æœŸé—´è°ƒæ•´æ­¢ç›ˆæ­¢æŸ
                "tp_extension_multiplier": 1.0,      # æ­¢ç›ˆæ‰©å±•å€æ•°ï¼ˆ1.0=ä¸æ‰©å±•ï¼Œ2.0=æ‰©2å€ï¼‰
                "sl_tightening_enabled": False,      # æ˜¯å¦å…è®¸æ”¶ç´§æ­¢æŸ
                "adjustment_cooldown_minutes": 60,   # è°ƒæ•´å†·å´æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
                "min_adjustment_threshold_pct": 2.0, # æœ€å°è°ƒæ•´å¹…åº¦ï¼ˆ%ï¼‰
            },
            
            # ã€V8.0 é‡æ„ã€‘Scalping è¶…çŸ­çº¿ä¸“ç”¨å‚æ•°ï¼ˆå®Œå…¨åˆ†ç¦»ï¼Œç‹¬ç«‹ä¼˜åŒ–ï¼‰
            "scalping_params": {
                # === ä¿¡å·ç­›é€‰ ===
                "min_signal_score": 65,              # ğŸ”§ V8.3.17: åˆå§‹å€¼65ï¼Œç”±Grid Searchä¼˜åŒ–ï¼ˆæµ‹è¯•65/75/85ï¼‰
                "min_indicator_consensus": 2,         # å…±æŒ¯è¦æ±‚ï¼ˆä¿æŒçµæ´»ï¼‰
                "min_risk_reward": 1.8,              # ğŸ”§ V8.3.17: åˆå§‹å€¼1.8ï¼Œç”±Grid Searchä¼˜åŒ–ï¼ˆæµ‹è¯•1.5/2.0/2.5ï¼‰
                
                # === æ­¢ç›ˆæ­¢æŸï¼ˆæ ¸å¿ƒï¼‰===
                "atr_stop_multiplier": 1.0,          # ğŸ†• V8.0: æ­¢æŸå€æ•°ï¼ˆç´§å‡‘ï¼‰
                "atr_tp_multiplier": 1.5,            # ğŸ†• V8.0: æ­¢ç›ˆå€æ•°ï¼ˆå¿«é€Ÿå…‘ç°ï¼‰
                # æˆ–ä½¿ç”¨ç›ˆäºæ¯”è®¡ç®—ï¼štp = sl Ã— min_risk_reward
                "use_independent_tp": True,          # ğŸ†• æ˜¯å¦ä½¿ç”¨ç‹¬ç«‹æ­¢ç›ˆå€æ•°ï¼ˆä¸ä¾èµ–R:Rï¼‰
                
                # === æ—¶é—´ç®¡ç† ===
                "max_holding_hours": 2,              # æœ€é•¿æŒä»“2å°æ—¶
                "protection_period_minutes": 0,      # æ— ä¿æŠ¤æœŸï¼ˆå¿«è¿›å¿«å‡ºï¼‰
                
                # === ä»“ä½ç®¡ç† ===
                "base_position_ratio": 0.15,         # åŸºç¡€ä»“ä½15%
                "max_position_ratio": 0.20,          # æœ€å¤§ä»“ä½20%
                "max_leverage": 3,                   # æœ€å¤§æ æ†3x
                "max_concurrent_positions": 2,       # æœ€å¤š2ä¸ªè¶…çŸ­çº¿ä»“ä½
                
                # === é£é™©æ§åˆ¶ ===
                "total_risk_budget": 0.03,           # æ€»é£é™©é¢„ç®—3%
                "max_loss_per_trade": 0.015,         # å•ç¬”æœ€å¤§äºæŸ1.5%
                "trailing_stop_trigger": 1.0,        # ğŸ”§ V8.0: ç›ˆåˆ©1%å¯åŠ¨ç§»åŠ¨æ­¢æŸ
                
                # === äº¤æ˜“é¢‘ç‡æ§åˆ¶ ===
                "cooldown_same_coin_minutes": 30,    # åŒå¸ç§å†·å´30åˆ†é’Ÿ
                "cooldown_any_coin_minutes": 15,     # ä»»æ„å¸ç§å†·å´15åˆ†é’Ÿ
                "max_trades_per_hour": 4,            # æ¯å°æ—¶æœ€å¤š4ç¬”
            },
            
            # ã€V8.0 é‡æ„ã€‘Swing æ³¢æ®µä¸“ç”¨å‚æ•°ï¼ˆå®Œå…¨åˆ†ç¦»ï¼Œç‹¬ç«‹ä¼˜åŒ–ï¼‰
            "swing_params": {
                # === ä¿¡å·ç­›é€‰ ===
                "min_signal_score": 70,              # ğŸ”§ V8.0: æ›´é«˜è¦æ±‚ï¼Œç¡®ä¿è¶‹åŠ¿è´¨é‡
                "min_indicator_consensus": 2,         # å…±æŒ¯è¦æ±‚æ ‡å‡†
                "min_risk_reward": 3.0,              # ğŸ”§ V8.0: æé«˜åˆ°3.0ï¼ˆè®©åˆ©æ¶¦å¥”è·‘ï¼‰
                "min_trend_strength": 0.7,           # æœ€å°è¶‹åŠ¿å¼ºåº¦
                
                # === æ­¢ç›ˆæ­¢æŸï¼ˆæ ¸å¿ƒï¼‰===
                "atr_stop_multiplier": 2.0,          # ğŸ†• V8.0: æ­¢æŸå€æ•°ï¼ˆå®½æ¾ï¼‰
                "atr_tp_multiplier": 6.0,            # ğŸ†• V8.0: æ­¢ç›ˆå€æ•°ï¼ˆè®©åˆ©æ¶¦å¥”è·‘ï¼‰
                # æˆ–ä½¿ç”¨ç›ˆäºæ¯”è®¡ç®—ï¼štp = sl Ã— min_risk_reward
                "use_independent_tp": True,          # ğŸ†• æ˜¯å¦ä½¿ç”¨ç‹¬ç«‹æ­¢ç›ˆå€æ•°
                
                # === æ—¶é—´ç®¡ç† ===
                "max_holding_hours": 48,             # ğŸ”§ V8.0: å»¶é•¿åˆ°48å°æ—¶
                "protection_period_minutes": 120,    # ä¿æŠ¤æœŸ2å°æ—¶ï¼ˆå…ç–«å™ªéŸ³ï¼‰
                "use_htf_levels": True,              # ä½¿ç”¨é«˜æ—¶é—´æ¡†æ¶æ­¢ç›ˆæ­¢æŸ
                
                # === ä»“ä½ç®¡ç† ===
                "base_position_ratio": 0.25,         # åŸºç¡€ä»“ä½25%
                "max_position_ratio": 0.35,          # æœ€å¤§ä»“ä½35%
                "max_leverage": 5,                   # æœ€å¤§æ æ†5x
                "max_concurrent_positions": 2,       # æœ€å¤š2ä¸ªæ³¢æ®µä»“ä½
                
                # === é£é™©æ§åˆ¶ ===
                "total_risk_budget": 0.05,           # æ€»é£é™©é¢„ç®—5%
                "max_loss_per_trade": 0.02,          # å•ç¬”æœ€å¤§äºæŸ2%
                "trailing_stop_trigger": 2.0,        # ğŸ”§ V8.0: ç›ˆåˆ©2%å¯åŠ¨ç§»åŠ¨æ­¢æŸ
                
                # === å¤šå‘¨æœŸç¡®è®¤ ===
                "multi_timeframe_threshold": 2,      # ğŸ”§ V8.0: é™ä½åˆ°2ï¼ˆ15m+1hï¼‰
                "trailing_stop_enabled": True,       # å¯ç”¨è¿½è¸ªæ­¢æŸ
                "trailing_stop_trigger_pct": 2.0,    # ç›ˆåˆ©2%å¯åŠ¨è¿½è¸ª
                "trailing_stop_distance_atr": 1.0,   # è¿½è¸ªè·ç¦»ï¼ˆ1å€ATRï¼‰
                "partial_exit_enabled": True,        # å¯ç”¨åˆ†æ‰¹å¹³ä»“
                "partial_exit_first_target_pct": 50, # ç¬¬ä¸€ç›®æ ‡å¹³ä»“50%
            },
            
            # ã€V7.9æ–°å¢ã€‘ä¿¡å·ä¼˜å…ˆçº§ç­–ç•¥
            "signal_priority": {
                "prefer_swing_on_strong_trend": True,      # å¼ºè¶‹åŠ¿ä¼˜å…ˆSwing
                "prefer_scalping_on_high_volatility": True,# é«˜æ³¢åŠ¨ä¼˜å…ˆScalping
                "trend_strength_threshold": 0.7,           # å¼ºè¶‹åŠ¿é˜ˆå€¼
                "volatility_threshold": 2.0,               # é«˜æ³¢åŠ¨é˜ˆå€¼
                "allow_both_types_simultaneously": True,   # å…è®¸åŒæ—¶æŒæœ‰ä¸¤ç§ç±»å‹
            },
        },
        # === å¸ç§é£é™©åˆ†çº§ ===
        "risk_profiles": {
            "BTC/USDT:USDT": "low_risk",
            "ETH/USDT:USDT": "low_risk",
            "SOL/USDT:USDT": "high_risk",
            "BNB/USDT:USDT": "medium_risk",
            "XRP/USDT:USDT": "medium_risk",
            "DOGE/USDT:USDT": "high_risk",
            "LTC/USDT:USDT": "low_risk",
        },
        # === é£é™©ç­‰çº§å®‰å…¨ç³»æ•° ã€V7.9.1ä¼˜åŒ–ï¼šä»ç¡¬ç¼–ç æ”¹ä¸ºAIåŸºå‡†Ã—ç³»æ•°ã€‘===
        "risk_safety_multipliers": {
            "low_risk": {
                "min_risk_reward_multiplier": 1.1,   # AIå­¦ä¹ å€¼Ã—1.1ï¼ˆBTC/ETHç¨³å®šï¼‰
                "min_signal_score_bonus": 10,        # AIå­¦ä¹ å€¼+10åˆ†
                "atr_stop_multiplier": 1.2,
                "min_indicator_consensus": 2,
                "base_position_ratio": 0.25,
            },
            "medium_risk": {
                "min_risk_reward_multiplier": 1.2,   # AIå­¦ä¹ å€¼Ã—1.2ï¼ˆBNB/XRPä¸­ç­‰ï¼‰
                "min_signal_score_bonus": 15,        # AIå­¦ä¹ å€¼+15åˆ†
                "atr_stop_multiplier": 1.5,
                "min_indicator_consensus": 2,
                "base_position_ratio": 0.20,
            },
            "high_risk": {
                "min_risk_reward_multiplier": 1.3,   # AIå­¦ä¹ å€¼Ã—1.3ï¼ˆSOL/DOGEæ³¢åŠ¨å¤§ï¼‰
                "min_signal_score_bonus": 20,        # AIå­¦ä¹ å€¼+20åˆ†
                "atr_stop_multiplier": 1.8,
                "min_indicator_consensus": 3,
                "base_position_ratio": 0.15,
            },
        },
        
        # ã€V7.9.1ã€‘å¦‚æœAIæœªå­¦ä¹ ï¼ˆper_symbolæ— æ•°æ®ï¼‰ï¼Œå›é€€åˆ°è¿™äº›æœ€ä½åŸºå‡†
        "risk_fallback_minimums": {
            "low_risk": {"min_risk_reward": 1.8, "min_signal_score": 60},
            "medium_risk": {"min_risk_reward": 2.0, "min_signal_score": 65},
            "high_risk": {"min_risk_reward": 2.2, "min_signal_score": 70},
        },
        # === æ¯ä¸ªå¸ç§çš„ç‹¬ç«‹å­¦ä¹ å‚æ•° ===
        "per_symbol": {},
        # === å¸‚åœºç¯å¢ƒå‚æ•° ===
        "market_regime": {
            "current_regime": "unknown",  # trend/range/high_volatility
            "last_check": None,
            "pause_trading": False,
        },
    }




# ============= V7.0 æ™ºèƒ½å†·é™æœŸä¸å¤ç›˜ç³»ç»Ÿ =============


def get_trading_experience_level():
    """è·å–äº¤æ˜“ç»éªŒç­‰çº§ï¼ˆV7.5æ–°å¢ï¼‰"""
    try:
        if not TRADES_FILE.exists():
            return 0, "æ–°æ‰‹"
        
        df = pd.read_csv(TRADES_FILE)
        df = df[df["å¹³ä»“æ—¶é—´"].notna()]  # åªçœ‹å·²å¹³ä»“äº¤æ˜“
        trade_count = len(df)
        
        if trade_count < 5:
            return trade_count, "æ–°æ‰‹"
        elif trade_count < 20:
            return trade_count, "å­¦ä¹ æœŸ"
        elif trade_count < 50:
            return trade_count, "æˆé•¿æœŸ"
        else:
            return trade_count, "æˆç†ŸæœŸ"
    except Exception as e:
        print(f"âš ï¸ è·å–äº¤æ˜“ç»éªŒå¤±è´¥: {e}")
        return 0, "æ–°æ‰‹"


def get_safe_params_by_experience(trade_count, ai_config=None):
    """æ ¹æ®äº¤æ˜“ç»éªŒè¿”å›å®‰å…¨å‚æ•°ï¼ˆV7.8.3 åŠ¨æ€AIå‚æ•°+å®‰å…¨ç³»æ•°ï¼‰
    
    æ–°ç­–ç•¥ï¼šåŸºäºAIä¼˜åŒ–å‚æ•°ï¼Œç”¨å®‰å…¨ç³»æ•°è°ƒæ•´
    - 0-4ç¬”ï¼šAIå‚æ•°Ã—1.5å€ä¿å®ˆç³»æ•°ï¼ˆæ–°æ‰‹æ¨¡å¼ï¼‰
    - 5-19ç¬”ï¼šAIå‚æ•°Ã—1.3å€ä¿å®ˆç³»æ•°ï¼ˆå­¦ä¹ æœŸï¼‰
    - 20-49ç¬”ï¼šAIå‚æ•°Ã—1.1å€ä¿å®ˆç³»æ•°ï¼ˆæˆé•¿æœŸï¼‰
    - 50+ç¬”ï¼šç›´æ¥ä½¿ç”¨AIå‚æ•°ï¼ˆæˆç†ŸæœŸï¼‰
    
    Args:
        trade_count: äº¤æ˜“ç¬”æ•°
        ai_config: AIä¼˜åŒ–çš„é…ç½®å­—å…¸ï¼ˆåŒ…å«globalå‚æ•°ï¼‰
    """
    # è·å–AIä¼˜åŒ–çš„åŸºç¡€å‚æ•°
    if ai_config is None:
        try:
            ai_config = load_learning_config()
        except:
            ai_config = get_default_config()
    
    ai_global = ai_config.get('global', {})
    base_rr = ai_global.get('min_risk_reward', 1.5)
    base_atr = ai_global.get('atr_stop_multiplier', 1.5)
    base_consensus = ai_global.get('min_indicator_consensus', 2)
    base_score = ai_global.get('min_signal_score', 55)
    
    if trade_count < 5:
        # æ–°æ‰‹æ¨¡å¼ï¼š1.5å€ä¿å®ˆç³»æ•° + æœ€é«˜æ ‡å‡†
        return {
            "min_risk_reward": max(base_rr * 1.5, 2.5),  # AIÃ—1.5ï¼Œæœ€ä½2.5
            "atr_stop_multiplier": max(base_atr * 1.3, 2.0),  # æ›´å®½æ­¢æŸ
            "min_indicator_consensus": min(5, max(4, base_consensus)),  # è‡³å°‘4ä¸ª
            "base_position_ratio": 0.10,  # æœ€å°ä»“ä½
            "min_signal_score": min(90, base_score + 35),  # AI+35åˆ†ï¼Œæœ€é«˜90
            "max_total_positions": 1,  # åªå…è®¸1ä¸ªæŒä»“
            "max_hold_time_hours": 12,  # çŸ­çº¿æŒä»“
            "_mode": "æ–°æ‰‹æ¨¡å¼(AIÃ—1.5)",
            "_ai_base": f"R:R={base_rr:.1f}â†’{max(base_rr * 1.5, 2.5):.1f}",
        }
    elif trade_count < 20:
        # å­¦ä¹ æœŸï¼š1.3å€ä¿å®ˆç³»æ•°
        return {
            "min_risk_reward": max(base_rr * 1.3, 2.0),  # AIÃ—1.3ï¼Œæœ€ä½2.0
            "atr_stop_multiplier": max(base_atr * 1.2, 1.8),
            "min_indicator_consensus": min(4, max(3, base_consensus)),  # 3-4ä¸ª
            "base_position_ratio": 0.15,
            "min_signal_score": min(85, base_score + 25),  # AI+25åˆ†ï¼Œæœ€é«˜85
            "max_total_positions": 2,
            "max_hold_time_hours": 18,
            "_mode": "å­¦ä¹ æœŸ(AIÃ—1.3)",
            "_ai_base": f"R:R={base_rr:.1f}â†’{max(base_rr * 1.3, 2.0):.1f}",
        }
    elif trade_count < 50:
        # æˆé•¿æœŸï¼š1.1å€ä¿å®ˆç³»æ•°
        return {
            "min_risk_reward": max(base_rr * 1.1, 1.5),  # AIÃ—1.1ï¼Œæœ€ä½1.5
            "atr_stop_multiplier": max(base_atr * 1.05, 1.6),
            "min_indicator_consensus": max(2, base_consensus),  # è‡³å°‘2ä¸ª
            "base_position_ratio": 0.18,
            "min_signal_score": min(70, base_score + 10),  # AI+10åˆ†ï¼Œæœ€é«˜70
            "max_total_positions": 2,
            "max_hold_time_hours": 24,
            "_mode": "æˆé•¿æœŸ(AIÃ—1.1)",
            "_ai_base": f"R:R={base_rr:.1f}â†’{max(base_rr * 1.1, 1.5):.1f}",
        }
    else:
        # æˆç†ŸæœŸï¼šç›´æ¥ä½¿ç”¨AIå‚æ•°
        return None


def calculate_market_volatility():
    """è®¡ç®—å¸‚åœºæ³¢åŠ¨ç‡ï¼ˆç”¨äºåŠ¨æ€å†·å´åˆ¤æ–­ï¼‰"""
    try:
        # è¯»å–æœ€è¿‘çš„ç›ˆäºå¿«ç…§ï¼Œè·å–å¸‚åœºæ³¢åŠ¨æƒ…å†µ
        if not PNL_HISTORY_FILE.exists():
            return 1.0  # é»˜è®¤æ­£å¸¸æ³¢åŠ¨
        
        df = pd.read_csv(PNL_HISTORY_FILE)
        if len(df) < 10:
            return 1.0
        
        # è®¡ç®—æœ€è¿‘24å°æ—¶çš„æ³¢åŠ¨ç‡ï¼ˆèµ„äº§å˜åŒ–çš„æ ‡å‡†å·®ï¼‰
        recent = df.tail(48)  # å‡è®¾15åˆ†é’Ÿä¸€æ¬¡ï¼Œ48æ¬¡=12å°æ—¶
        if 'æ€»èµ„äº§' in recent.columns:
            returns = recent['æ€»èµ„äº§'].pct_change().dropna()
            volatility = returns.std()
            # å½’ä¸€åŒ–ï¼šæ­£å¸¸æ³¢åŠ¨ä¸º1.0ï¼Œé«˜æ³¢åŠ¨>1.5ï¼Œæç«¯æ³¢åŠ¨>2.0
            normalized_volatility = volatility / 0.01  # å‡è®¾1%ä¸ºåŸºå‡†æ³¢åŠ¨
            return min(max(normalized_volatility, 0.5), 3.0)  # é™åˆ¶åœ¨0.5-3.0ä¹‹é—´
        
        return 1.0
    except Exception as e:
        print(f"âš ï¸ è®¡ç®—å¸‚åœºæ³¢åŠ¨ç‡å¤±è´¥: {e}")
        return 1.0


def should_trigger_cooldown_dynamic(recent_trades, total_assets, market_volatility=1.0):
    """V7.5åŠ¨æ€å†·å´æœŸè§¦å‘æ£€æŸ¥ï¼ˆæ™ºèƒ½åˆ¤æ–­ï¼‰
    
    è€ƒè™‘å› ç´ ï¼š
    1. äºæŸå¹…åº¦ï¼šå°äºæŸå®¹å¿åº¦æ›´é«˜
    2. æ—¶é—´å¯†åº¦ï¼šçŸ­æ—¶é—´å†…è¿ç»­äºæŸæ›´å±é™©
    3. å¸‚åœºç¯å¢ƒï¼šé«˜æ³¢åŠ¨æœŸæ”¾å®½æ ‡å‡†
    4. è¿ç»­æ€§ï¼šè¿ç»­äºæŸæ¯”åˆ†æ•£äºæŸæ›´ä¸¥é‡
    
    è¿”å›: (should_trigger, cooldown_level, reason)
    """
    from datetime import datetime
    
    if len(recent_trades) < 3:
        return False, 0, ""
    
    # è·å–æœ€è¿‘çš„äºæŸäº¤æ˜“
    loss_trades = [t for t in recent_trades if t.get('ç›ˆäº(U)', 0) < 0]
    
    if len(loss_trades) < 3:
        return False, 0, ""
    
    # å–æœ€è¿‘3ç¬”äºæŸ
    last_3_losses = loss_trades[-3:]
    
    # è®¡ç®—æ€»äºæŸç‡å’Œæ€»äºæŸé¢
    total_loss = sum(t['ç›ˆäº(U)'] for t in last_3_losses)
    total_loss_pct = abs(total_loss) / total_assets if total_assets > 0 else 0
    
    # è®¡ç®—æ—¶é—´è·¨åº¦
    try:
        first_time = pd.to_datetime(last_3_losses[0]['å¼€ä»“æ—¶é—´'])
        last_time = pd.to_datetime(last_3_losses[-1]['å¹³ä»“æ—¶é—´'])
        time_span_hours = (last_time - first_time).total_seconds() / 3600
    except:
        time_span_hours = 24  # é»˜è®¤å‡è®¾24å°æ—¶
    
    # åŠ¨æ€åˆ¤æ–­é€»è¾‘
    
    # ğŸ”´ æç«¯æƒ…å†µï¼š2å°æ—¶å†…äºæŸ>5% â†’ ç›´æ¥3çº§å†·é™
    if time_span_hours < 2 and total_loss_pct > 0.05:
        return True, 3, f"æç«¯é£é™©ï¼š{time_span_hours:.1f}å°æ—¶å†…äºæŸ{total_loss_pct*100:.1f}%"
    
    # ğŸŸ  é«˜å±æƒ…å†µï¼š6å°æ—¶å†…äºæŸ>3% â†’ 2çº§å†·é™
    if time_span_hours < 6 and total_loss_pct > 0.03:
        return True, 2, f"é«˜é£é™©ï¼š{time_span_hours:.1f}å°æ—¶å†…äºæŸ{total_loss_pct*100:.1f}%"
    
    # ğŸŸ¡ æ ‡å‡†æƒ…å†µï¼šè¿ç»­3ç¬”äºæŸ â†’ 1çº§å†·é™
    # æ£€æŸ¥æ˜¯å¦çœŸçš„è¿ç»­ï¼ˆæœ€è¿‘5ç¬”ä¸­æœ‰3ç¬”äºæŸï¼‰
    last_5 = recent_trades[-5:] if len(recent_trades) >= 5 else recent_trades
    consecutive_losses = sum(1 for t in last_5 if t.get('ç›ˆäº(U)', 0) < 0)
    
    if consecutive_losses >= 3:
        # è€ƒè™‘å¸‚åœºæ³¢åŠ¨ç‡ï¼šé«˜æ³¢åŠ¨æœŸï¼ˆå¦‚æš´è·Œï¼‰æ”¾å®½åˆ¤æ–­
        if market_volatility > 1.8:
            # å¸‚åœºæç«¯æ³¢åŠ¨ï¼ŒäºæŸå¯èƒ½ä¸æ˜¯ç­–ç•¥é—®é¢˜
            if total_loss_pct < 0.02:  # äºæŸ<2%ï¼Œå®¹å¿
                return False, 0, f"å¸‚åœºæç«¯æ³¢åŠ¨æœŸï¼Œå°å¹…äºæŸ{total_loss_pct*100:.1f}%å¯å®¹å¿"
        
        # å°é¢äºæŸå®¹å¿ï¼šå¦‚æœ3ç¬”åˆè®¡<1Uï¼Œä¸è§¦å‘
        if abs(total_loss) < 1.0:
            return False, 0, f"äºæŸé¢åº¦è¾ƒå°({abs(total_loss):.2f}U)ï¼Œæš‚ä¸è§¦å‘å†·é™æœŸ"
        
        return True, 1, f"è¿ç»­{consecutive_losses}ç¬”äºæŸ(æ€»è®¡{abs(total_loss):.2f}U)"
    
    return False, 0, ""


def should_pause_trading_v7(config):
    """V7.5æ¸è¿›å¼å†·é™æœŸæ£€æŸ¥ï¼ˆå¸¦ç›ˆåˆ©é€€å‡ºæœºåˆ¶ + åŠ¨æ€è§¦å‘ï¼‰
    
    è¿”å›: (should_pause, pause_reason, remaining_minutes)
    
    V7.5æ”¹è¿›ï¼š
    - åŠ¨æ€å†·å´è§¦å‘ï¼šè€ƒè™‘äºæŸå¹…åº¦ã€æ—¶é—´å¯†åº¦ã€å¸‚åœºç¯å¢ƒ
    - ä¼˜åŒ–ç›ˆåˆ©é€€å‡ºï¼šæ ¹æ®å†·é™ç­‰çº§è¦æ±‚ä¸åŒç›ˆåˆ©è´¨é‡
    """
    from datetime import datetime, timedelta
    
    # è·å–å½“å‰å¸‚åœºç¯å¢ƒï¼ˆå†·é™æœŸçŠ¶æ€ï¼‰
    market_regime = config.get("market_regime", {})
    pause_level = market_regime.get("pause_level", 0)  # 0=æ­£å¸¸ï¼Œ1=2hï¼Œ2=4hï¼Œ3=æš‚åœè‡³æ˜æ—¥
    pause_start = market_regime.get("pause_start", None)
    pause_until = market_regime.get("pause_until", None)
    
    # å¦‚æœæ²¡æœ‰æš‚åœï¼Œè¿”å›æ­£å¸¸
    if pause_level == 0:
        return False, "", 0
    
    # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æ¢å¤æ—¶é—´
    now = datetime.now()
    if pause_until:
        pause_until_dt = datetime.fromisoformat(pause_until)
        
        # ğŸ†• V7.5: æ£€æŸ¥å†·é™æœŸå†…æ˜¯å¦æœ‰è¶³å¤Ÿç›ˆåˆ©ï¼ˆæ ¹æ®ç­‰çº§è¦æ±‚ä¸åŒï¼‰
        if _check_profit_during_cooldown(pause_start, pause_level):
            # ç›ˆåˆ©é€€å‡ºæœºåˆ¶
            new_pause_level = max(0, pause_level - 1)
            market_regime["pause_level"] = new_pause_level
            market_regime["pause_start"] = None
            market_regime["pause_until"] = None
            config["market_regime"] = market_regime
            
            # ä¿å­˜é…ç½®
            from pathlib import Path
            import json
            config_file = Path("trading_data") / os.getenv("MODEL_NAME", "deepseek") / "learning_config.json"
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # å‘é€ç›ˆåˆ©æ¢å¤é€šçŸ¥
            send_recovery_notification_v7(
                model_name=os.getenv("MODEL_NAME", "DeepSeek"),
                recovery_type="profit_exit",
                pause_level=pause_level,
                new_pause_level=new_pause_level
            )
            
            return False, "", 0
        
        # æ­£å¸¸æ—¶é—´åˆ°è¾¾æ¢å¤
        if now >= pause_until_dt:
            # é‡ç½®å†·é™æœŸçŠ¶æ€
            market_regime["pause_level"] = 0
            market_regime["pause_start"] = None
            market_regime["pause_until"] = None
            config["market_regime"] = market_regime
            
            # ä¿å­˜é…ç½®
            from pathlib import Path
            import json
            config_file = Path("trading_data") / os.getenv("MODEL_NAME", "deepseek") / "learning_config.json"
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # å‘é€æ¢å¤é€šçŸ¥
            send_recovery_notification_v7(
                model_name=os.getenv("MODEL_NAME", "DeepSeek"),
                recovery_type="time_based",
                pause_level=pause_level,
                new_pause_level=0
            )
            
            return False, "", 0
        else:
            # è®¡ç®—å‰©ä½™æ—¶é—´
            remaining = pause_until_dt - now
            remaining_minutes = int(remaining.total_seconds() / 60)
            
            if pause_level == 3:
                reason = f"ä»Šæ—¥äº¤æ˜“å·²æš‚åœï¼ˆæ˜æ—¥00:00æ¢å¤ï¼‰"
            else:
                hours = remaining_minutes // 60
                mins = remaining_minutes % 60
                cooldown_hours = 2 if pause_level == 1 else 4
                reason = f"å†·é™æœŸä¸­ï¼ˆ{cooldown_hours}å°æ—¶ï¼‰ï¼Œå‰©ä½™{hours}h{mins}m"
            
            return True, reason, remaining_minutes
    
    return False, "", 0


def _get_trigger_losses_before_cooldown(pause_start):
    """è·å–è§¦å‘å†·é™æœŸå‰çš„äºæŸï¼ˆç”¨äºè®¡ç®—ç›ˆåˆ©é€€å‡ºé˜ˆå€¼ï¼‰"""
    try:
        from datetime import datetime
        
        pause_start_dt = datetime.fromisoformat(pause_start)
        
        # è¯»å–äº¤æ˜“å†å²
        trades_file = Path("trading_data") / os.getenv("MODEL_NAME", "deepseek") / "trades_history.csv"
        if not trades_file.exists():
            return 0
        
        df = pd.read_csv(trades_file)
        if df.empty:
            return 0
        
        # è·å–è§¦å‘å‰çš„äº¤æ˜“ï¼ˆå†·é™æœŸå¼€å§‹å‰1å°æ—¶å†…çš„äºæŸï¼‰
        df['å¹³ä»“æ—¶é—´_dt'] = pd.to_datetime(df['å¹³ä»“æ—¶é—´'], errors='coerce')
        trigger_window_start = pause_start_dt - pd.Timedelta(hours=1)
        trigger_trades = df[(df['å¹³ä»“æ—¶é—´_dt'] >= trigger_window_start) & 
                           (df['å¹³ä»“æ—¶é—´_dt'] < pause_start_dt)]
        
        if not trigger_trades.empty:
            losses = trigger_trades[trigger_trades['ç›ˆäº(U)'] < 0]
            return abs(losses['ç›ˆäº(U)'].sum())
        
        return 5.0  # é»˜è®¤å‡è®¾5UäºæŸ
    except Exception as e:
        print(f"âš ï¸ è·å–è§¦å‘äºæŸå¤±è´¥: {e}")
        return 5.0


def _check_profit_during_cooldown(pause_start, pause_level=1):
    """V7.5ä¼˜åŒ–ï¼šæ£€æŸ¥å†·é™æœŸå†…æ˜¯å¦æœ‰è¶³å¤Ÿç›ˆåˆ©é€€å‡º
    
    ç›ˆåˆ©è´¨é‡è¦æ±‚ï¼ˆæ ¹æ®å†·é™ç­‰çº§ï¼‰ï¼š
    - 1çº§å†·é™ï¼šå•ç¬”ç›ˆåˆ©>1U æˆ– æ€»ç›ˆåˆ©>2U
    - 2çº§å†·é™ï¼šæ€»ç›ˆåˆ©>è§¦å‘äºæŸçš„30%
    - 3çº§å†·é™ï¼šæ€»ç›ˆåˆ©>è§¦å‘äºæŸçš„50%
    """
    if not pause_start:
        return False
    
    try:
        from pathlib import Path
        import pandas as pd
        from datetime import datetime
        
        pause_start_dt = datetime.fromisoformat(pause_start)
        
        # è¯»å–äº¤æ˜“å†å²
        trades_file = Path("trading_data") / os.getenv("MODEL_NAME", "deepseek") / "trades_history.csv"
        if not trades_file.exists():
            return False
        
        df = pd.read_csv(trades_file)
        if df.empty:
            return False
        
        # è¿‡æ»¤å†·é™æœŸå†…çš„äº¤æ˜“
        df['å¹³ä»“æ—¶é—´_dt'] = pd.to_datetime(df['å¹³ä»“æ—¶é—´'], errors='coerce')
        cooldown_trades = df[df['å¹³ä»“æ—¶é—´_dt'] >= pause_start_dt]
        
        if cooldown_trades.empty:
            return False
        
        # è®¡ç®—å†·é™æœŸå†…çš„ç›ˆåˆ©
        profit_trades = cooldown_trades[cooldown_trades['ç›ˆäº(U)'] > 0]
        if profit_trades.empty:
            return False
        
        total_profit = profit_trades['ç›ˆäº(U)'].sum()
        max_single_profit = profit_trades['ç›ˆäº(U)'].max()
        
        # æ ¹æ®å†·é™ç­‰çº§åˆ¤æ–­
        if pause_level == 1:
            # 1çº§ï¼šå•ç¬”>1U æˆ– æ€»ç›ˆåˆ©>2U
            if max_single_profit > 1.0 or total_profit > 2.0:
                print(f"âœ… 1çº§å†·é™æœŸé€€å‡ºï¼šç›ˆåˆ©{total_profit:.2f}U (æœ€å¤§å•ç¬”{max_single_profit:.2f}U)")
                return True
        
        elif pause_level == 2:
            # 2çº§ï¼šæ€»ç›ˆåˆ©>è§¦å‘äºæŸçš„30%
            trigger_loss = _get_trigger_losses_before_cooldown(pause_start)
            required_profit = trigger_loss * 0.3
            if total_profit > required_profit:
                print(f"âœ… 2çº§å†·é™æœŸé€€å‡ºï¼šç›ˆåˆ©{total_profit:.2f}U > è¦æ±‚{required_profit:.2f}U (è§¦å‘äºæŸ{trigger_loss:.2f}Uçš„30%)")
                return True
            else:
                print(f"â³ ç›ˆåˆ©ä¸è¶³é€€å‡ºï¼š{total_profit:.2f}U < {required_profit:.2f}U")
        
        elif pause_level == 3:
            # 3çº§ï¼šæ€»ç›ˆåˆ©>è§¦å‘äºæŸçš„50%
            trigger_loss = _get_trigger_losses_before_cooldown(pause_start)
            required_profit = trigger_loss * 0.5
            if total_profit > required_profit:
                print(f"âœ… 3çº§å†·é™æœŸé€€å‡ºï¼šç›ˆåˆ©{total_profit:.2f}U > è¦æ±‚{required_profit:.2f}U (è§¦å‘äºæŸ{trigger_loss:.2f}Uçš„50%)")
                return True
            else:
                print(f"â³ ç›ˆåˆ©ä¸è¶³é€€å‡ºï¼š{total_profit:.2f}U < {required_profit:.2f}U")
        
        return False
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥å†·é™æœŸç›ˆåˆ©æ—¶å‡ºé”™: {e}")
        return False


# ============================================================
# ã€V8.3.21ã€‘æ•°æ®å¢å¼ºè¾…åŠ©å‡½æ•°ï¼ˆæ–¹æ¡ˆBï¼‰
# ============================================================

def get_kline_context(klines, count=10):
    """
    ã€V8.3.21 - ç›²ç‚¹1ã€‘è·å–Kçº¿åºåˆ—ä¸Šä¸‹æ–‡
    
    è®©AIçœ‹åˆ°æœ€è¿‘Næ ¹Kçº¿çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œç†è§£"æ¥é¾™å»è„‰"
    
    Args:
        klines: Kçº¿åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯dict {"open": float, "high": float, "low": float, "close": float, "volume": float}
        count: åˆ†ææœ€è¿‘å‡ æ ¹Kçº¿ï¼ˆé»˜è®¤10ï¼‰
    
    Returns:
        dict: Kçº¿ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    try:
        if not klines or len(klines) < 2:
            return None
        
        # å–æœ€è¿‘Næ ¹Kçº¿
        recent = klines[-min(count, len(klines)):]
        
        highs = [k['high'] for k in recent]
        lows = [k['low'] for k in recent]
        opens = [k['open'] for k in recent]
        closes = [k['close'] for k in recent]
        volumes = [k['volume'] for k in recent]
        
        # è®¡ç®—Kçº¿ç‰¹å¾
        bodies = [abs(c - o) for c, o in zip(closes, opens)]
        ranges = [h - l for h, l in zip(highs, lows)]
        
        # é˜³çº¿/é˜´çº¿æ•°é‡
        bullish = sum(1 for c, o in zip(closes, opens) if c > o)
        bearish = len(recent) - bullish
        
        # ä»·æ ¼å˜åŒ–
        price_change_pct = (closes[-1] - closes[0]) / closes[0] * 100 if closes[0] > 0 else 0
        
        # è¶‹åŠ¿åˆ¤æ–­
        is_trending_up = False
        is_trending_down = False
        if len(closes) >= 5:
            is_trending_up = closes[-1] > closes[0] and closes[-1] > closes[-5]
            is_trending_down = closes[-1] < closes[0] and closes[-1] < closes[-5]
        
        return {
            "count": len(recent),
            "highest_high": max(highs),
            "lowest_low": min(lows),
            "avg_body_size": sum(bodies) / len(bodies) if bodies else 0,
            "avg_range_size": sum(ranges) / len(ranges) if ranges else 0,
            "avg_volume": sum(volumes) / len(volumes) if volumes else 0,
            "bullish_count": bullish,
            "bearish_count": bearish,
            "bullish_ratio": bullish / len(recent) if recent else 0,
            "price_change_pct": round(price_change_pct, 2),
            "is_trending_up": is_trending_up,
            "is_trending_down": is_trending_down,
            "volatility_pct": ((max(highs) - min(lows)) / min(lows) * 100) if min(lows) > 0 else 0
        }
    except Exception as e:
        print(f"âš ï¸ get_kline_contextå¤±è´¥: {e}")
        return None


def analyze_market_structure(klines, timeframe_hours=0.25):
    """
    ã€V8.3.21 - ç›²ç‚¹2ã€‘åˆ†æå¸‚åœºç»“æ„
    
    è¯†åˆ«é«˜ä½ç‚¹åºåˆ—ã€è¶‹åŠ¿å¹´é¾„ã€ä½ç½®ç­‰ç»“æ„ä¿¡æ¯
    
    Args:
        klines: Kçº¿åˆ—è¡¨
        timeframe_hours: æ—¶é—´æ¡†æ¶ï¼ˆå°æ—¶ï¼‰ï¼Œ15m=0.25, 1h=1.0, 4h=4.0
    
    Returns:
        dict: å¸‚åœºç»“æ„ä¿¡æ¯
    """
    try:
        if not klines or len(klines) < 10:
            return None
        
        closes = [k['close'] for k in klines]
        highs = [k['high'] for k in klines]
        lows = [k['low'] for k in klines]
        
        # è¯†åˆ«swingé«˜ä½ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼šå±€éƒ¨æå€¼ï¼‰
        swing_highs = []
        swing_lows = []
        
        for i in range(2, len(klines)-2):
            high = highs[i]
            low = lows[i]
            
            # Swing High: æ¯”å‰å2æ ¹éƒ½é«˜
            if high >= max(highs[i-1], highs[i-2], highs[i+1], highs[i+2]):
                swing_highs.append((i, high))
            
            # Swing Low: æ¯”å‰å2æ ¹éƒ½ä½
            if low <= min(lows[i-1], lows[i-2], lows[i+1], lows[i+2]):
                swing_lows.append((i, low))
        
        # åˆ¤æ–­ç»“æ„ç±»å‹
        structure = "unknown"
        trend_strength = "weak"
        
        if len(swing_highs) >= 2 and len(swing_lows) >= 2:
            last_2_highs = [h for _, h in swing_highs[-2:]]
            last_2_lows = [l for _, l in swing_lows[-2:]]
            
            # HH-HL (ä¸Šå‡ç»“æ„)
            if last_2_highs[-1] > last_2_highs[0] and last_2_lows[-1] > last_2_lows[0]:
                structure = "HH-HL"
                trend_strength = "strong_bullish"
            # LL-LH (ä¸‹é™ç»“æ„)
            elif last_2_highs[-1] < last_2_highs[0] and last_2_lows[-1] < last_2_lows[0]:
                structure = "LL-LH"
                trend_strength = "strong_bearish"
            # æ··ä¹±ç»“æ„
            else:
                structure = "choppy"
                trend_strength = "weak"
        
        # è®¡ç®—è¶‹åŠ¿å¹´é¾„ï¼ˆä»æœ€è¿‘çš„swingç‚¹å¼€å§‹ï¼‰
        current_price = closes[-1]
        trend_age_candles = 0
        
        if swing_highs or swing_lows:
            all_swings = [(i, 'high') for i, _ in swing_highs] + [(i, 'low') for i, _ in swing_lows]
            all_swings.sort()
            if all_swings:
                last_swing_idx = all_swings[-1][0]
                trend_age_candles = len(klines) - last_swing_idx - 1
        
        # è®¡ç®—è¶‹åŠ¿ç´¯è®¡æ¶¨è·Œå¹…
        if trend_age_candles > 0 and trend_age_candles < len(closes):
            trend_start_price = closes[-(trend_age_candles+1)]
            trend_move_pct = ((current_price - trend_start_price) / trend_start_price * 100) if trend_start_price > 0 else 0
        else:
            trend_move_pct = 0
        
        # å½“å‰ä»·æ ¼åœ¨åŒºé—´çš„ä½ç½®ï¼ˆ0=æœ€ä½ï¼Œ1=æœ€é«˜ï¼‰
        recent_high = max(highs[-20:]) if len(highs) >= 20 else max(highs)
        recent_low = min(lows[-20:]) if len(lows) >= 20 else min(lows)
        position_in_range = ((current_price - recent_low) / (recent_high - recent_low)) if (recent_high - recent_low) > 0 else 0.5
        
        # è·ç¦»é«˜ä½ç‚¹çš„è·ç¦»
        distance_from_high = ((recent_high - current_price) / current_price * 100) if current_price > 0 else 0
        distance_from_low = ((current_price - recent_low) / current_price * 100) if current_price > 0 else 0
        
        return {
            "swing_structure": structure,
            "trend_strength": trend_strength,
            "trend_age_candles": trend_age_candles,
            "trend_age_hours": round(trend_age_candles * timeframe_hours, 1),
            "trend_move_pct": round(trend_move_pct, 2),
            "last_swing_high": swing_highs[-1][1] if swing_highs else 0,
            "last_swing_low": swing_lows[-1][1] if swing_lows else 0,
            "position_in_range": round(position_in_range, 2),
            "distance_from_high_pct": round(distance_from_high, 2),
            "distance_from_low_pct": round(distance_from_low, 2)
        }
    except Exception as e:
        print(f"âš ï¸ analyze_market_structureå¤±è´¥: {e}")
        return None


def analyze_sr_history(klines, sr_price, sr_type='resistance', tolerance_pct=0.5):
    """
    ã€V8.3.21 - ç›²ç‚¹3ã€‘åˆ†ææ”¯æ’‘/é˜»åŠ›çš„å†å²æµ‹è¯•æƒ…å†µ
    
    è¯†åˆ«è¿™ä¸ªæ”¯æ’‘/é˜»åŠ›è¢«æµ‹è¯•è¿‡å‡ æ¬¡ã€ååº”å¦‚ä½•
    
    Args:
        klines: Kçº¿åˆ—è¡¨ï¼ˆå»ºè®®è‡³å°‘50-100æ ¹ï¼‰
        sr_price: æ”¯æ’‘/é˜»åŠ›ä»·æ ¼
        sr_type: 'support' or 'resistance'
        tolerance_pct: å®¹å·®ç™¾åˆ†æ¯”ï¼ˆé»˜è®¤0.5%ï¼Œå³ä»·æ ¼åœ¨Â±0.5%èŒƒå›´å†…ç®—"æµ‹è¯•"ï¼‰
    
    Returns:
        dict: S/Rå†å²ä¿¡æ¯
    """
    try:
        if not klines or not sr_price or sr_price <= 0:
            return None
        
        test_count = 0
        reactions = []  # è®°å½•æ¯æ¬¡æµ‹è¯•åçš„ä»·æ ¼ååº”
        last_test_ago_candles = None
        false_breakouts = 0
        
        for i, kline in enumerate(klines):
            high = kline['high']
            low = kline['low']
            close = kline['close']
            
            # åˆ¤æ–­æ˜¯å¦"æµ‹è¯•"äº†S/R
            tested = False
            
            if sr_type == 'resistance':
                # é˜»åŠ›æµ‹è¯•ï¼šæœ€é«˜ä»·æ¥è¿‘æˆ–çªç ´é˜»åŠ›ä½
                if high >= sr_price * (1 - tolerance_pct/100):
                    tested = True
                    # è®°å½•ååº”ï¼šæ”¶ç›˜ä»·ç›¸å¯¹é˜»åŠ›ä½çš„è·ç¦»
                    reaction_pct = ((close - sr_price) / sr_price * 100)
                    reactions.append(reaction_pct)
                    
                    # å‡çªç ´ï¼šæœ€é«˜ä»·çªç ´ä½†æ”¶ç›˜å›è½
                    if high > sr_price and close < sr_price:
                        false_breakouts += 1
            
            elif sr_type == 'support':
                # æ”¯æ’‘æµ‹è¯•ï¼šæœ€ä½ä»·æ¥è¿‘æˆ–è·Œç ´æ”¯æ’‘ä½
                if low <= sr_price * (1 + tolerance_pct/100):
                    tested = True
                    # è®°å½•ååº”ï¼šæ”¶ç›˜ä»·ç›¸å¯¹æ”¯æ’‘ä½çš„è·ç¦»
                    reaction_pct = ((close - sr_price) / sr_price * 100)
                    reactions.append(reaction_pct)
                    
                    # å‡è·Œç ´ï¼šæœ€ä½ä»·è·Œç ´ä½†æ”¶ç›˜åå¼¹
                    if low < sr_price and close > sr_price:
                        false_breakouts += 1
            
            if tested:
                test_count += 1
                last_test_ago_candles = len(klines) - i - 1
        
        if test_count == 0:
            return None
        
        # è®¡ç®—å¹³å‡/æœ€å¤§ååº”
        if sr_type == 'resistance':
            avg_reaction = sum(reactions) / len(reactions) if reactions else 0
            max_rejection = min(reactions) if reactions else 0  # æœ€å¤§å›è°ƒï¼ˆè´Ÿæ•°ï¼‰
            description = f"è¢«æµ‹è¯•{test_count}æ¬¡"
            if false_breakouts > 0:
                description += f"ï¼Œ{false_breakouts}æ¬¡å‡çªç ´"
        else:  # support
            avg_reaction = sum(reactions) / len(reactions) if reactions else 0
            max_bounce = max(reactions) if reactions else 0  # æœ€å¤§åå¼¹ï¼ˆæ­£æ•°ï¼‰
            description = f"è¢«æµ‹è¯•{test_count}æ¬¡"
            if false_breakouts > 0:
                description += f"ï¼Œ{false_breakouts}æ¬¡å‡è·Œç ´"
        
        return {
            "test_count": test_count,
            "last_test_ago_candles": last_test_ago_candles if last_test_ago_candles is not None else 999,
            "avg_reaction_pct": round(avg_reaction, 2),
            "max_rejection_pct": round(max_rejection, 2) if sr_type == 'resistance' else round(max_bounce, 2),
            "false_breakouts": false_breakouts,
            "description": description
        }
    except Exception as e:
        print(f"âš ï¸ analyze_sr_historyå¤±è´¥: {e}")
        return None


def save_market_snapshot_v7(market_data_list):
    """ä¿å­˜å¸‚åœºå¿«ç…§ï¼ˆæ¯15åˆ†é’Ÿï¼‰ä¾›å¤ç›˜åˆ†æ"""
    try:
        from pathlib import Path
        from datetime import datetime
        import pandas as pd
        
        model_name = os.getenv("MODEL_NAME", "deepseek")
        snapshot_dir = Path("trading_data") / model_name / "market_snapshots"
        snapshot_dir.mkdir(parents=True, exist_ok=True)
        
        today = datetime.now().strftime("%Y%m%d")
        snapshot_file = snapshot_dir / f"{today}.csv"
        
        # ğŸ”§ V7.8.1 ä¿®å¤ï¼šåŠ è½½é…ç½®ç”¨äºè®¡ç®—risk_reward
        try:
            config = load_learning_config()
            if not config:
                config = get_default_config()
        except:
            config = get_default_config()
        
        # å‡†å¤‡å¿«ç…§æ•°æ®
        snapshot_data = []
        
        # ğŸ”§ V7.8.2: ä½¿ç”¨Kçº¿æ—¶é—´æˆ³ï¼ˆå¯¹é½15åˆ†é’Ÿæ•´æ•°å€ï¼‰ï¼Œé¿å…å› è€—æ—¶å¯¼è‡´æ—¶é—´é”™ä½
        current_time = None
        
        for data in market_data_list:
            if data is None:
                print("âš ï¸ è·³è¿‡æ•°æ®è·å–å¤±è´¥çš„å¸ç§ï¼ˆå¸‚åœºå¿«ç…§ï¼‰")
                continue  # è·³è¿‡è·å–å¤±è´¥çš„å¸ç§
            
            # è·å–å¸ç§åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            coin_name = data.get("symbol", "").split("/")[0]
            
            # ã€V8.3.21.2ä¿®å¤ã€‘è·å–å¹¶è½¬æ¢Kçº¿æ•°æ®æ ¼å¼
            # kline_dataæ˜¯ccxtæ ¼å¼çš„åˆ—è¡¨ï¼š[[timestamp, open, high, low, close, volume], ...]
            kline_list_raw = data.get("kline_data", [])
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œæ–¹ä¾¿åç»­å¤„ç†
            kline_list = []
            for kline in kline_list_raw:
                if isinstance(kline, list) and len(kline) >= 6:
                    kline_list.append({
                        'timestamp': kline[0],
                        'open': kline[1],
                        'high': kline[2],
                        'low': kline[3],
                        'close': kline[4],
                        'volume': kline[5]
                    })
            
            current_kline = kline_list[-1] if kline_list else {}
            
            # ã€V8.1.2ä¿®å¤ã€‘æ•°æ®è´¨é‡æ£€æŸ¥ï¼šç¡®ä¿Kçº¿æ•°æ®å®Œæ•´
            if not current_kline:
                print(f"âš ï¸ {coin_name}: kline_dataä¸ºç©ºï¼Œä½¿ç”¨fallbackå€¼ï¼ˆå¯èƒ½å¯¼è‡´OHLCç›¸ç­‰ï¼‰")
                # å°è¯•ä»dataç›´æ¥æ„å»ºOHLCï¼ˆä½¿ç”¨å½“å‰ä»·æ ¼ä½œä¸ºæ‰€æœ‰å€¼ï¼‰
                # è¿™æ˜¯æœ€åçš„fallbackï¼Œä½†è‡³å°‘ä¿è¯æ•°æ®ä¸€è‡´æ€§
                fallback_price = data.get("current_price", data.get("price", 0))
                current_kline = {
                    "open": fallback_price,
                    "high": fallback_price,
                    "low": fallback_price,
                    "close": fallback_price,
                    "volume": data.get("volume", 0)
                }
                print(f"  â†’ ä½¿ç”¨fallbackä»·æ ¼: ${fallback_price:.4f}")
            else:
                # æ•°æ®è´¨é‡æ£€æŸ¥ï¼šç¡®ä¿OHLCæ•°æ®åˆç†
                o = current_kline.get("open", 0)
                h = current_kline.get("high", 0)
                l = current_kline.get("low", 0)
                c = current_kline.get("close", 0)
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½ç›¸ç­‰ï¼ˆå¯èƒ½æ˜¯æ•°æ®é—®é¢˜ï¼‰
                if o == h == l == c and o > 0:
                    print(f"âš ï¸ {coin_name}: Kçº¿OHLCéƒ½ç›¸ç­‰ (${o:.4f})ï¼Œå¯èƒ½æ˜¯æ•°æ®è´¨é‡é—®é¢˜")
                # æ£€æŸ¥highå’Œlowçš„åˆç†æ€§
                elif h > 0 and l > 0 and (h < l or h < o or h < c or l > o or l > c):
                    print(f"âš ï¸ {coin_name}: Kçº¿æ•°æ®å¼‚å¸¸ (O:{o:.4f} H:{h:.4f} L:{l:.4f} C:{c:.4f})")
                    # ä½¿ç”¨closeä»·æ ¼ä½œä¸ºæ‰€æœ‰å€¼ï¼ˆæ›´ä¿å®ˆçš„ç­–ç•¥ï¼‰
                    current_kline = {
                        "open": c,
                        "high": c,
                        "low": c,
                        "close": c,
                        "volume": current_kline.get("volume", 0)
                    }
                    print(f"  â†’ å·²ä¿®æ­£ä¸ºcloseä»·æ ¼: ${c:.4f}")
            
            # ğŸ”§ V7.8.2: é¦–æ¬¡å¾ªç¯æ—¶ï¼Œä»Kçº¿æ—¶é—´æˆ³è®¡ç®—è§„èŒƒåŒ–æ—¶é—´ï¼ˆå¯¹é½15åˆ†é’Ÿï¼‰
            if current_time is None and current_kline.get("timestamp"):
                try:
                    import pandas as pd
                    kline_ts = current_kline["timestamp"]
                    # å¤„ç†ä¸åŒç±»å‹çš„æ—¶é—´æˆ³ï¼ˆå…ˆæ£€æŸ¥pd.Timestampï¼Œé¿å…è¢«è¯¯åˆ¤ä¸ºæ•°å€¼ï¼‰
                    if isinstance(kline_ts, pd.Timestamp):
                        # Pandas Timestampå¯¹è±¡
                        kline_dt = kline_ts.to_pydatetime()
                    elif isinstance(kline_ts, (int, float)):
                        # æ•°å€¼å‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                        kline_dt = datetime.fromtimestamp(int(kline_ts) / 1000)
                    else:
                        raise ValueError(f"æœªçŸ¥çš„æ—¶é—´æˆ³ç±»å‹: {type(kline_ts)}")
                    
                    # å‘ä¸‹å–æ•´åˆ°15åˆ†é’Ÿï¼ˆ0/15/30/45ï¼‰
                    minute = (kline_dt.minute // 15) * 15
                    normalized_dt = kline_dt.replace(minute=minute, second=0, microsecond=0)
                    current_time = normalized_dt.strftime("%H%M")
                    print(f"ğŸ“… å¸‚åœºå¿«ç…§æ—¶é—´: {current_time} (åŸºäºKçº¿æ—¶é—´æˆ³ {kline_dt.strftime('%H:%M:%S')})")
                except Exception as e:
                    print(f"âš ï¸ è§£æKçº¿æ—¶é—´æˆ³å¤±è´¥: {e}ï¼Œå›é€€åˆ°ç³»ç»Ÿæ—¶é—´")
                    current_time = datetime.now().strftime("%H%M")
            
            # å¦‚æœæ‰€æœ‰Kçº¿éƒ½æ— æ—¶é—´æˆ³ï¼Œå›é€€åˆ°ç³»ç»Ÿæ—¶é—´
            if current_time is None:
                current_time = datetime.now().strftime("%H%M")
            
            # è·å–1å°æ—¶æ•°æ®ï¼ˆV6.0æ–°å¢ï¼‰
            mid_term = data.get("mid_term", {})
            mt_sr = mid_term.get("support_resistance", {})
            
            # å®‰å…¨è·å–MACDæ•°æ®
            macd_data = data.get("macd", {}) or {}
            macd_1h = (mid_term.get("macd") or {})
            
            # å®‰å…¨è·å–æ”¯æ’‘é˜»åŠ›æ•°æ®
            nearest_resistance = (mt_sr.get("nearest_resistance") or {})
            nearest_support = (mt_sr.get("nearest_support") or {})
            
            # å®‰å…¨è·å–è£¸Kæ•°æ®
            price_action = data.get("price_action", {}) or {}
            pullback = price_action.get("pullback_type", {}) or {}
            
            # ã€V8.5.2.4.3å®Œæ•´ä¿®å¤ã€‘ç›´æ¥ä»dataè·å–indicator_consensus
            # ç°åœ¨åœ¨get_ohlcv_dataä¸­å·²ç»è®¡ç®—å¥½äº†ï¼Œæ— éœ€é‡å¤è®¡ç®—
            indicator_consensus = data.get("indicator_consensus", 0)
            
            # ã€V8.5.2.4.3å®Œæ•´ä¿®å¤ã€‘ç›´æ¥ä»dataè·å–consensus_score
            # ç°åœ¨åœ¨get_ohlcv_dataä¸­å·²ç»è®¡ç®—å¥½äº†ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
            consensus_score = data.get("consensus_score", 0)
            
            # ã€V8.2ã€‘è®¡ç®—ä¿¡å·è¯„åˆ†çš„å„ä¸ªç»´åº¦ï¼ˆä¿å­˜"åŸæ–™"è€Œé"æˆå“"ï¼‰
            # åˆå§‹åŒ–signal_typeï¼ˆé˜²æ­¢æœªå®šä¹‰é”™è¯¯ï¼‰
            signal_type = 'swing'
            
            try:
                # ã€V8.3.10.3ä¿®å¤ã€‘ç¡®ä¿dataä¸ä¸ºNone
                if not data or not isinstance(data, dict):
                    raise ValueError("Invalid market_data")
                
                # ã€V8.5.2.4.89.25ã€‘åŒä¿¡å·åˆ†è¯„ä¼°ï¼šåŒæ—¶è®¡ç®—è¶…çŸ­çº¿å’Œæ³¢æ®µè§†è§’
                scalping_components = calculate_signal_score_components(data, 'scalping')
                swing_components = calculate_signal_score_components(data, 'swing')
                
                # ç›´æ¥ä½¿ç”¨componentsä¸­çš„total_scoreï¼ˆå·²æ ¹æ®æƒé‡è®¡ç®—ï¼‰
                scalping_score = scalping_components.get('total_score', 0)
                swing_score = swing_components.get('total_score', 0)
                
                # ä¿å­˜åŒä¿¡å·åˆ†åˆ°dataä¸­
                data['scalping_signal_score'] = scalping_score
                data['swing_signal_score'] = swing_score
                
                # åˆ¤æ–­æ¨èç­–ç•¥ï¼šæ ¹æ®é…ç½®çš„é˜ˆå€¼
                scalping_threshold = 80  # è¶…çŸ­çº¿é«˜é˜ˆå€¼
                swing_threshold = 65     # æ³¢æ®µä½é˜ˆå€¼
                
                scalping_qualified = scalping_score >= scalping_threshold
                swing_qualified = swing_score >= swing_threshold
                
                # å…¼å®¹æ€§ï¼šsignal_typeå’Œcomponentsä½¿ç”¨è¾ƒé«˜åˆ†æ•°çš„é‚£ä¸ª
                # ä½†åŒæ—¶è€ƒè™‘é˜ˆå€¼ï¼ˆåˆæ ¼æ€§ï¼‰
                if scalping_qualified and (not swing_qualified or scalping_score >= swing_score):
                    signal_type = 'scalping'
                    components = scalping_components
                    data['signal_score'] = scalping_score
                    data['recommended_strategy'] = 'scalping'
                elif swing_qualified:
                    signal_type = 'swing'
                    components = swing_components
                    data['signal_score'] = swing_score
                    data['recommended_strategy'] = 'swing'
                else:
                    # éƒ½ä¸åˆæ ¼ï¼Œé€‰åˆ†æ•°é«˜çš„
                    if scalping_score >= swing_score:
                        signal_type = 'scalping'
                        components = scalping_components
                        data['signal_score'] = scalping_score
                        data['recommended_strategy'] = 'scalping'
                    else:
                        signal_type = 'swing'
                        components = swing_components
                        data['signal_score'] = swing_score
                        data['recommended_strategy'] = 'swing'
                
            except Exception as e:
                print(f"âš ï¸ è®¡ç®—è¯„åˆ†ç»´åº¦å¤±è´¥: {e}")
                # é™çº§ï¼šä½¿ç”¨é»˜è®¤å€¼
                components = {
                    'signal_type': 'scalping',
                    'total_score': 0,
                }
                data['scalping_signal_score'] = 0
                data['swing_signal_score'] = 0
                data['scalping_signal_score_weighted'] = 0
                data['swing_signal_score_weighted'] = 0
                signal_type = 'swing'
            
            # ã€V8.4ã€‘æ›´æ–°consensus_scoreçš„å½¢æ€è¯„åˆ†éƒ¨åˆ†ï¼ˆä½¿ç”¨componentsä¸­çš„æ•°æ®ï¼‰
            try:
                # è·å–å½¢æ€è¯„åˆ†
                pin_bar_score = components.get('pin_bar_score', 0)
                engulfing_score = components.get('engulfing_score', 0)
                breakout_score = components.get('breakout_score', 0)
                
                # é‡æ–°è®¡ç®—consensus_scoreï¼ˆåŠ ä¸Šå½¢æ€è¯„åˆ†ï¼‰
                # ç®€åŒ–æ–¹å¼ï¼šåœ¨åŸæœ‰åŸºç¡€ä¸Šè¿½åŠ å½¢æ€å¾—åˆ†
                pattern_score = 0
                if pin_bar_score > 0:
                    pattern_score += min(5, pin_bar_score / 2)
                if engulfing_score > 0:
                    pattern_score += min(5, engulfing_score / 2)
                if breakout_score > 0:
                    pattern_score += min(5, breakout_score / 5)
                
                consensus_score = min(100, consensus_score + int(pattern_score))
            except Exception as e:
                pass  # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨ä¹‹å‰è®¡ç®—çš„consensus_score
            
            # ã€V8.3.21ã€‘æ•°æ®å¢å¼ºï¼šè·å–Kçº¿ä¸Šä¸‹æ–‡ã€å¸‚åœºç»“æ„ã€S/Rå†å²
            # ç›²ç‚¹1ï¼šKçº¿åºåˆ—ä¸Šä¸‹æ–‡
            kline_context_15m = None
            if kline_list and len(kline_list) >= 10:
                # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                standard_klines = []
                for kline in kline_list:
                    standard_klines.append({
                        'open': kline.get('open', 0),
                        'high': kline.get('high', 0),
                        'low': kline.get('low', 0),
                        'close': kline.get('close', 0),
                        'volume': kline.get('volume', 0)
                    })
                kline_context_15m = get_kline_context(standard_klines, count=10)
            
            # ç›²ç‚¹2ï¼šå¸‚åœºç»“æ„ï¼ˆ15mçº§åˆ«ï¼‰
            market_structure_15m = None
            if kline_list and len(kline_list) >= 20:
                standard_klines = []
                for kline in kline_list:
                    standard_klines.append({
                        'open': kline.get('open', 0),
                        'high': kline.get('high', 0),
                        'low': kline.get('low', 0),
                        'close': kline.get('close', 0),
                        'volume': kline.get('volume', 0)
                    })
                market_structure_15m = analyze_market_structure(standard_klines, timeframe_hours=0.25)
            
            # ç›²ç‚¹3ï¼šæ”¯æ’‘é˜»åŠ›å†å²
            resistance_history = None
            support_history = None
            resistance = ((data.get("support_resistance") or {}).get("nearest_resistance") or {}).get("price", 0)
            support = ((data.get("support_resistance") or {}).get("nearest_support") or {}).get("price", 0)
            
            if kline_list and len(kline_list) >= 50:
                standard_klines = []
                for kline in kline_list:
                    standard_klines.append({
                        'open': kline.get('open', 0),
                        'high': kline.get('high', 0),
                        'low': kline.get('low', 0),
                        'close': kline.get('close', 0),
                        'volume': kline.get('volume', 0)
                    })
                
                if resistance > 0:
                    resistance_history = analyze_sr_history(standard_klines, resistance, sr_type='resistance')
                if support > 0:
                    support_history = analyze_sr_history(standard_klines, support, sr_type='support')
            
            # ã€V8.3.20ã€‘å¢å¼ºç‰ˆR:Rè®¡ç®— - åŸºäºè¶‹åŠ¿å¼ºåº¦åŠ¨æ€è°ƒæ•´
            atr_value = (data.get("atr") or {}).get("atr_14", 0)
            price = data.get("current_price", 0)
            resistance = ((data.get("support_resistance") or {}).get("nearest_resistance") or {}).get("price", 0)
            support = ((data.get("support_resistance") or {}).get("nearest_support") or {}).get("price", 0)
            trend_15m = data.get("trend_15m", "")
            trend_1h = mid_term.get("trend", "")
            trend_4h = data.get("trend_4h", "")
            
            if atr_value > 0 and price > 0:
                # æ­¢æŸè·ç¦»ï¼šä½¿ç”¨å½“å‰é…ç½®çš„ATRå€æ•°
                stop_distance = atr_value * config.get("atr_stop_multiplier", 2.0)
                
                # ã€å…³é”®ä¿®å¤ã€‘åŸºäºè¶‹åŠ¿å¼ºåº¦åŠ¨æ€è°ƒæ•´æ­¢ç›ˆç›®æ ‡
                # 1. åˆ¤æ–­è¶‹åŠ¿å¼ºåº¦
                is_strong_trend = (
                    ("å¤šå¤´" in trend_15m and "å¤šå¤´" in trend_1h and "å¤šå¤´" in trend_4h) or
                    ("ç©ºå¤´" in trend_15m and "ç©ºå¤´" in trend_1h and "ç©ºå¤´" in trend_4h)
                )
                is_medium_trend = "å¤šå¤´" in trend_15m or "ç©ºå¤´" in trend_15m
                
                # 2. åŠ¨æ€ç›®æ ‡å€æ•°
                if is_strong_trend:
                    target_multiplier = 6.0  # å¼ºè¶‹åŠ¿ï¼šä¸‰æ¡†æ¶ä¸€è‡´
                elif is_medium_trend:
                    target_multiplier = 4.5  # ä¸­ç­‰è¶‹åŠ¿ï¼š15mè¶‹åŠ¿æ˜ç¡®
                else:
                    target_multiplier = 3.0  # å¼±è¶‹åŠ¿/éœ‡è¡
                
                # 3. è€ƒè™‘æˆäº¤é‡æ¿€å¢
                vol = data.get("volume_analysis", {})
                if vol.get("ratio", 0) >= 2.0:
                    target_multiplier *= 1.3  # å·¨é‡é¢å¤–åŠ 30%
                
                # 4. è€ƒè™‘æŒ‡æ ‡å…±æŒ¯
                if indicator_consensus >= 4:
                    target_multiplier *= 1.2  # å¼ºå…±æŒ¯é¢å¤–åŠ 20%
                
                # 5. è®¡ç®—ç›®æ ‡è·ç¦»
                target_distance = atr_value * target_multiplier
                
                risk_reward = round(target_distance / stop_distance, 2) if stop_distance > 0 else 0
            else:
                risk_reward = 0
            
            snapshot_data.append({
                "time": current_time,
                "coin": coin_name,
                
                # === å®Œæ•´OHLCVæ•°æ®ï¼ˆç”¨äºè£¸Kå›æµ‹ï¼‰===
                "open": current_kline.get("open", data.get("price", 0)),
                "high": current_kline.get("high", data.get("high", 0)),
                "low": current_kline.get("low", data.get("low", 0)),
                "close": current_kline.get("close", data.get("price", 0)),
                "volume": current_kline.get("volume", data.get("volume", 0)),
                
                # === æŠ€æœ¯æŒ‡æ ‡ï¼ˆå·²è®¡ç®—å¥½ï¼Œé¿å…é‡å¤è®¡ç®—ï¼‰===
                "price": data.get("current_price", 0),
                "trend_4h": data.get("trend_4h", ""),
                "trend_15m": data.get("trend_15m", ""),
                "rsi_14": data.get("rsi", {}).get("rsi_14", 0),
                "rsi_7": data.get("rsi", {}).get("rsi_7", 0),
                "macd_line": macd_data.get("line", 0),
                "macd_signal": macd_data.get("signal", 0),
                "macd_histogram": macd_data.get("histogram", 0),
                "atr": (data.get("atr") or {}).get("atr_14", 0),
                "support": ((data.get("support_resistance") or {}).get("nearest_support") or {}).get("price", 0),
                "resistance": ((data.get("support_resistance") or {}).get("nearest_resistance") or {}).get("price", 0),
                "indicator_consensus": indicator_consensus,  # ã€å…¼å®¹æ€§ã€‘æŒ‡æ ‡å…±æŒ¯æ•°ï¼ˆ0-5ï¼‰
                "consensus_score": consensus_score,  # ã€V8.4æ–°å¢ã€‘ç»¼åˆç¡®è®¤åº¦è¯„åˆ†ï¼ˆ0-100ï¼‰
                # V8.2: signal_scoreå·²ç§»é™¤ï¼Œæ”¹ä¸ºä¿å­˜å„ä¸ªè¯„åˆ†ç»´åº¦ï¼ˆè§ä¸‹æ–¹çš„ volume_surge_score ç­‰å­—æ®µï¼‰
                "risk_reward": risk_reward,  # ã€V7.8å…³é”®ä¿®å¤ã€‘ç›ˆäºæ¯”
                
                # === 1å°æ—¶æ•°æ®ï¼ˆV6.5æ–°å¢ï¼‰===
                "trend_1h": mid_term.get("trend", ""),
                "ema20_1h": mid_term.get("ema20", 0),
                "ema50_1h": mid_term.get("ema50", 0),
                "macd_1h_line": macd_1h.get("line", 0),
                "macd_1h_signal": macd_1h.get("signal", 0),
                "macd_1h_histogram": macd_1h.get("histogram", 0),
                "atr_1h": mid_term.get("atr_14", 0),
                "resistance_1h": nearest_resistance.get("price", 0),
                "resistance_1h_strength": nearest_resistance.get("strength", ""),
                "support_1h": nearest_support.get("price", 0),
                "support_1h_strength": nearest_support.get("strength", ""),
                
                # === è£¸Kå½¢æ€ï¼ˆç”¨äºåˆ†æï¼‰===
                "pin_bar": price_action.get("pin_bar", ""),
                "engulfing": price_action.get("engulfing", ""),
                "pullback_type": pullback.get("type", "") if isinstance(pullback, dict) else "",
                "pullback_depth": pullback.get("depth_pct", 0) if isinstance(pullback, dict) else 0,
                
                # === ã€V8.3.19.2ã€‘ä¿¡å·è¯„åˆ†ç»´åº¦ï¼ˆç”¨äºä¿¡å·ç±»å‹è¯†åˆ«ï¼‰===
                "volume_surge_type": components.get("volume_surge_type", ""),
                "volume_surge_score": components.get("volume_surge_score", 0),
                "has_breakout": components.get("has_breakout", False),
                "breakout_score": components.get("breakout_score", 0),
                
                # === YTCå¢å¼ºå­—æ®µï¼ˆV7.5æ–°å¢ï¼Œç”¨äºå¤ç›˜åˆ†æï¼‰===
                "momentum_slope": price_action.get("momentum_slope", 0),  # åŠ¨èƒ½æ–œç‡
                "pullback_weakness_score": price_action.get("pullback_weakness_score", 0),  # å›è°ƒå¼±åŠ¿ï¼ˆ0-1ï¼‰
                "lwp_long": price_action.get("lwp_long", 0),  # å¤šå¤´LWPå‚è€ƒä»·
                "lwp_short": price_action.get("lwp_short", 0),  # ç©ºå¤´LWPå‚è€ƒä»·
                "lwp_confidence": price_action.get("lwp_confidence", "none"),  # LWPç½®ä¿¡åº¦
                
                # YTCä¿¡å·
                "ytc_signal_type": (price_action.get("ytc_signal") or {}).get("signal_type", "NONE"),  # BOF/BPB/TST/NONE
                "ytc_direction": (price_action.get("ytc_signal") or {}).get("direction", ""),  # LONG/SHORT
                "ytc_strength": (price_action.get("ytc_signal") or {}).get("strength", 0),  # ä¿¡å·å¼ºåº¦1-5
                "ytc_sr_strength": (price_action.get("ytc_signal") or {}).get("sr_strength", 0),  # S/Rå¼ºåº¦1-5
                "ytc_entry_price": (price_action.get("ytc_signal") or {}).get("entry_price", 0),  # å»ºè®®å…¥åœºä»·
                "ytc_rationale": (price_action.get("ytc_signal") or {}).get("rationale", ""),  # ä¿¡å·åŸå› 
                
                # S/Rè´¨é‡è¯„ä¼°ï¼ˆ15åˆ†é’Ÿï¼‰
                "support_strength": ((data.get("support_resistance") or {}).get("nearest_support") or {}).get("strength", 1),  # æ”¯æ’‘å¼ºåº¦1-5
                "support_polarity_switched": ((data.get("support_resistance") or {}).get("nearest_support") or {}).get("is_switched_polarity", False),  # ææ€§è½¬æ¢
                "support_fast_rejection": ((data.get("support_resistance") or {}).get("nearest_support") or {}).get("is_fast_rejection", False),  # å¿«é€Ÿæ‹’ç»
                "resistance_strength": ((data.get("support_resistance") or {}).get("nearest_resistance") or {}).get("strength", 1),  # é˜»åŠ›å¼ºåº¦1-5
                "resistance_polarity_switched": ((data.get("support_resistance") or {}).get("nearest_resistance") or {}).get("is_switched_polarity", False),
                "resistance_fast_rejection": ((data.get("support_resistance") or {}).get("nearest_resistance") or {}).get("is_fast_rejection", False),
                
                # === ã€V8.3.21ã€‘æ•°æ®å¢å¼ºå­—æ®µï¼ˆæ–¹æ¡ˆBï¼‰===
                # ç›²ç‚¹1ï¼šKçº¿åºåˆ—ä¸Šä¸‹æ–‡ï¼ˆ15mï¼‰
                "kline_ctx_count": kline_context_15m.get("count", 0) if kline_context_15m else 0,
                "kline_ctx_highest": kline_context_15m.get("highest_high", 0) if kline_context_15m else 0,
                "kline_ctx_lowest": kline_context_15m.get("lowest_low", 0) if kline_context_15m else 0,
                "kline_ctx_avg_body": kline_context_15m.get("avg_body_size", 0) if kline_context_15m else 0,
                "kline_ctx_avg_range": kline_context_15m.get("avg_range_size", 0) if kline_context_15m else 0,
                "kline_ctx_bullish_cnt": kline_context_15m.get("bullish_count", 0) if kline_context_15m else 0,
                "kline_ctx_bearish_cnt": kline_context_15m.get("bearish_count", 0) if kline_context_15m else 0,
                "kline_ctx_bullish_ratio": kline_context_15m.get("bullish_ratio", 0) if kline_context_15m else 0,
                "kline_ctx_price_chg_pct": kline_context_15m.get("price_change_pct", 0) if kline_context_15m else 0,
                "kline_ctx_is_up": kline_context_15m.get("is_trending_up", False) if kline_context_15m else False,
                "kline_ctx_is_down": kline_context_15m.get("is_trending_down", False) if kline_context_15m else False,
                "kline_ctx_volatility": kline_context_15m.get("volatility_pct", 0) if kline_context_15m else 0,
                
                # ç›²ç‚¹2ï¼šå¸‚åœºç»“æ„ï¼ˆ15mï¼‰
                "mkt_struct_swing": market_structure_15m.get("swing_structure", "") if market_structure_15m else "",
                "mkt_struct_trend_strength": market_structure_15m.get("trend_strength", "") if market_structure_15m else "",
                "mkt_struct_age_candles": market_structure_15m.get("trend_age_candles", 0) if market_structure_15m else 0,
                "mkt_struct_age_hours": market_structure_15m.get("trend_age_hours", 0) if market_structure_15m else 0,
                "mkt_struct_move_pct": market_structure_15m.get("trend_move_pct", 0) if market_structure_15m else 0,
                "mkt_struct_last_high": market_structure_15m.get("last_swing_high", 0) if market_structure_15m else 0,
                "mkt_struct_last_low": market_structure_15m.get("last_swing_low", 0) if market_structure_15m else 0,
                "mkt_struct_pos_in_range": market_structure_15m.get("position_in_range", 0) if market_structure_15m else 0,
                "mkt_struct_dist_high_pct": market_structure_15m.get("distance_from_high_pct", 0) if market_structure_15m else 0,
                "mkt_struct_dist_low_pct": market_structure_15m.get("distance_from_low_pct", 0) if market_structure_15m else 0,
                
                # ç›²ç‚¹3ï¼šé˜»åŠ›å†å²
                "resist_hist_test_cnt": resistance_history.get("test_count", 0) if resistance_history else 0,
                "resist_hist_last_test_ago": resistance_history.get("last_test_ago_candles", 999) if resistance_history else 999,
                "resist_hist_avg_reaction": resistance_history.get("avg_reaction_pct", 0) if resistance_history else 0,
                "resist_hist_max_rejection": resistance_history.get("max_rejection_pct", 0) if resistance_history else 0,
                "resist_hist_false_bo": resistance_history.get("false_breakouts", 0) if resistance_history else 0,
                "resist_hist_desc": resistance_history.get("description", "") if resistance_history else "",
                
                # ç›²ç‚¹3ï¼šæ”¯æ’‘å†å²
                "support_hist_test_cnt": support_history.get("test_count", 0) if support_history else 0,
                "support_hist_last_test_ago": support_history.get("last_test_ago_candles", 999) if support_history else 999,
                "support_hist_avg_reaction": support_history.get("avg_reaction_pct", 0) if support_history else 0,
                "support_hist_max_bounce": support_history.get("max_rejection_pct", 0) if support_history else 0,
                "support_hist_false_bd": support_history.get("false_breakouts", 0) if support_history else 0,
                "support_hist_desc": support_history.get("description", "") if support_history else "",
            })
        
        # è¿½åŠ åˆ°æ–‡ä»¶ï¼ˆæ·»åŠ quotingå‚æ•°é¿å…å­—æ®µè§£æé”™è¯¯ï¼‰
        if not snapshot_data:
            print(f"âš ï¸ å¸‚åœºå¿«ç…§ä¸ºç©ºï¼Œæ— æ•°æ®ä¿å­˜ï¼ˆæ‰€æœ‰å¸ç§è·å–å¤±è´¥ï¼‰")
            return
        
        # ã€V8.5.2æ–°å¢ã€‘å»é‡é€»è¾‘ï¼šæ£€æŸ¥å½“å‰æ—¶é—´ç‚¹æ˜¯å¦å·²æœ‰æ•°æ®
        if snapshot_file.exists():
            try:
                existing_df = pd.read_csv(snapshot_file, dtype={'time': str})
                
                # è·å–å½“å‰è¦ä¿å­˜çš„æ—¶é—´ç‚¹
                current_time_str = snapshot_data[0].get('time')
                
                if current_time_str:
                    # æ£€æŸ¥è¿™ä¸ªæ—¶é—´ç‚¹æ˜¯å¦å·²å­˜åœ¨
                    existing_times = set(existing_df['time'].values)
                    
                    if current_time_str in existing_times:
                        print(f"â­ï¸  è·³è¿‡ä¿å­˜ï¼šæ—¶é—´ç‚¹ {current_time_str} çš„æ•°æ®å·²å­˜åœ¨")
                        return  # è·³è¿‡ä¿å­˜
                    else:
                        print(f"âœ… æ—¶é—´ç‚¹ {current_time_str} å°šæœªä¿å­˜ï¼Œç»§ç»­ä¿å­˜")
                
            except Exception as e:
                print(f"âš ï¸ è¯»å–ç°æœ‰æ–‡ä»¶å¤±è´¥: {e}ï¼Œå°†ç›´æ¥è¿½åŠ ")
        
        df = pd.DataFrame(snapshot_data)
        if snapshot_file.exists():
            df.to_csv(snapshot_file, mode='a', header=False, index=False, encoding='utf-8', quoting=csv.QUOTE_MINIMAL)
        else:
            df.to_csv(snapshot_file, mode='w', header=True, index=False, encoding='utf-8', quoting=csv.QUOTE_MINIMAL)
        
        print(f"âœ“ å¸‚åœºå¿«ç…§å·²ä¿å­˜: {current_time} ({len(snapshot_data)}ä¸ªå¸ç§)")
        
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜å¸‚åœºå¿«ç…§å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def daily_review_with_kline_v7():
    """V7.0æ¯æ—¥å¤ç›˜ï¼ˆå¸¦Kçº¿å’Œå¸‚åœºå¿«ç…§åˆ†æï¼‰
    
    åˆ†æå†…å®¹ï¼š
    1. ä»Šæ—¥æ‰€æœ‰äº¤æ˜“çš„å¼€ä»“/å¹³ä»“æ—¶æœºæ˜¯å¦åˆç†
    2. é”™è¿‡äº†å“ªäº›äº¤æ˜“æœºä¼šï¼ˆåŸºäºå¸‚åœºå¿«ç…§ï¼‰
    3. ç»“åˆå…·ä½“Kçº¿ç‚¹ä½ç»™å‡ºæ”¹è¿›å»ºè®®
    """
    try:
        from pathlib import Path
        from datetime import datetime, timedelta
        import pandas as pd
        
        model_name = os.getenv("MODEL_NAME", "deepseek")
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
        
        # è¯»å–æ˜¨æ—¥äº¤æ˜“è®°å½•
        trades_file = Path("trading_data") / model_name / "trades_history.csv"
        if not trades_file.exists():
            return "æ— äº¤æ˜“è®°å½•"
        
        df = pd.read_csv(trades_file)
        df['å¹³ä»“æ—¥æœŸ'] = pd.to_datetime(df['å¹³ä»“æ—¶é—´'], errors='coerce').dt.strftime('%Y%m%d')
        yesterday_trades = df[df['å¹³ä»“æ—¥æœŸ'] == yesterday]
        
        # è¯»å–æ˜¨æ—¥å¸‚åœºå¿«ç…§
        snapshot_file = Path("trading_data") / model_name / "market_snapshots" / f"{yesterday}.csv"
        if not snapshot_file.exists():
            market_snapshots = None
        else:
            try:
                # æ·»åŠ å®¹é”™å‚æ•°
                market_snapshots = pd.read_csv(snapshot_file, on_bad_lines='skip', quoting=1, encoding='utf-8-sig')
            except Exception as e:
                print(f"âš ï¸ è¯»å–å¸‚åœºå¿«ç…§å¤±è´¥: {e}")
                try:
                    market_snapshots = pd.read_csv(snapshot_file, on_bad_lines='skip', encoding='utf-8-sig')
                except:
                    market_snapshots = None
        
        # æ„å»ºå¤ç›˜æ–‡æœ¬
        review_lines = [f"ã€{yesterday}å¤ç›˜ã€‘"]
        
        if yesterday_trades.empty:
            review_lines.append("æ˜¨æ—¥æ— äº¤æ˜“")
        else:
            review_lines.append(f"æ˜¨æ—¥äº¤æ˜“ï¼š{len(yesterday_trades)}ç¬”\n")
            
            for _, trade in yesterday_trades.iterrows():
                coin = trade.get('å¸ç§', 'N/A')
                side = trade.get('æ–¹å‘', 'N/A')
                pnl = trade.get('ç›ˆäº(U)', 0)
                entry = trade.get('å¼€ä»“ä»·æ ¼', 0)
                exit_price = trade.get('å¹³ä»“ä»·æ ¼', 0)
                entry_time = trade.get('å¼€ä»“æ—¶é—´', '')
                
                review_lines.append(f"{coin} {side}: {'+' if pnl > 0 else ''}{pnl:.2f}U ({entry}â†’{exit_price})")
                
                # å¦‚æœæœ‰å¸‚åœºå¿«ç…§ï¼Œåˆ†æå¼€ä»“æ—¶æœº
                if market_snapshots is not None and entry_time:
                    try:
                        entry_hhmm = entry_time.split()[1][:4] if ' ' in entry_time else entry_time[:4]
                        closest = market_snapshots[
                            (market_snapshots['coin'] == coin) &
                            (market_snapshots['time'] == entry_hhmm)
                        ]
                        
                        if not closest.empty:
                            row = closest.iloc[0]
                            review_lines.append(f"  å¼€ä»“ç¯å¢ƒ: ä»·æ ¼{row['price']} RSI{row['rsi_14']:.0f} å…±æŒ¯{row['indicator_consensus']}/5")
                            
                            # ç®€å•è¯„ä»·
                            if side == 'å¤š' and row['price'] < row['support'] * 1.002:
                                review_lines.append("  âœ… å¼€ä»“ä½ç½®ä½³ï¼ˆæ¥è¿‘æ”¯æ’‘ï¼‰")
                            elif side == 'ç©º' and row['price'] > row['resistance'] * 0.998:
                                review_lines.append("  âœ… å¼€ä»“ä½ç½®ä½³ï¼ˆæ¥è¿‘é˜»åŠ›ï¼‰")
                            elif row['indicator_consensus'] < 3:
                                review_lines.append("  âš ï¸ æŒ‡æ ‡å…±æŒ¯ä¸è¶³")
                    except Exception as e:
                        pass
                
                review_lines.append("")
        
        # ã€V7.9ã€‘ç»Ÿè®¡æœ€è¿‘7å¤©ï¼ˆåˆ†Scalping/Swingï¼‰
        recent_7d = df[df['å¹³ä»“æ—¥æœŸ'] >= (datetime.now() - timedelta(days=7)).strftime('%Y%m%d')]
        if not recent_7d.empty:
            win_count = len(recent_7d[recent_7d['ç›ˆäº(U)'] > 0])
            total_pnl = recent_7d['ç›ˆäº(U)'].sum()
            win_rate = win_count / len(recent_7d) * 100 if len(recent_7d) > 0 else 0
            review_lines.append(f"ã€æœ€è¿‘7å¤©ã€‘{len(recent_7d)}ç¬” èƒœç‡{win_rate:.0f}% æ€»ç›ˆäº{total_pnl:+.2f}U")
        
            # åˆ†ç±»å‹ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰signal_typeå­—æ®µï¼‰
            if 'ä¿¡å·ç±»å‹' in recent_7d.columns:
                scalping_trades = recent_7d[recent_7d['ä¿¡å·ç±»å‹'] == 'scalping']
                swing_trades = recent_7d[recent_7d['ä¿¡å·ç±»å‹'] == 'swing']
                
                if not scalping_trades.empty:
                    scalp_wins = len(scalping_trades[scalping_trades['ç›ˆäº(U)'] > 0])
                    scalp_pnl = scalping_trades['ç›ˆäº(U)'].sum()
                    scalp_wr = scalp_wins / len(scalping_trades) * 100
                    scalp_avg_hold = scalping_trades['é¢„æœŸæŒä»“(åˆ†é’Ÿ)'].mean() if 'é¢„æœŸæŒä»“(åˆ†é’Ÿ)' in scalping_trades.columns else 0
                    review_lines.append(f"  âš¡è¶…çŸ­çº¿: {len(scalping_trades)}ç¬” èƒœç‡{scalp_wr:.0f}% {scalp_pnl:+.2f}U (å‡{scalp_avg_hold:.0f}åˆ†)")
                
                if not swing_trades.empty:
                    swing_wins = len(swing_trades[swing_trades['ç›ˆäº(U)'] > 0])
                    swing_pnl = swing_trades['ç›ˆäº(U)'].sum()
                    swing_wr = swing_wins / len(swing_trades) * 100
                    swing_avg_hold = swing_trades['é¢„æœŸæŒä»“(åˆ†é’Ÿ)'].mean() if 'é¢„æœŸæŒä»“(åˆ†é’Ÿ)' in swing_trades.columns else 0
                    review_lines.append(f"  ğŸŒŠæ³¢æ®µ: {len(swing_trades)}ç¬” èƒœç‡{swing_wr:.0f}% {swing_pnl:+.2f}U (å‡{swing_avg_hold/60:.1f}h)")
        
        # ã€V7.9ã€‘è¯†åˆ«é”™è¿‡çš„æœºä¼šï¼ˆåˆ†Scalping/Swingï¼‰
        if market_snapshots is not None:
            strong_signals = market_snapshots[market_snapshots['indicator_consensus'] >= 4]
            if not strong_signals.empty:
                traded_coins = set(yesterday_trades['å¸ç§'].unique()) if not yesterday_trades.empty else set()
                missed = strong_signals[~strong_signals['coin'].isin(traded_coins)].copy()
                
                if not missed.empty:
                    # ã€æ”¹è¿›ã€‘åŸºäºå®é™…ä»·æ ¼èµ°å‘åˆ¤æ–­ç±»å‹ï¼ˆåéªŒåˆ†æï¼‰
                    # æ–¹æ³•ï¼šçœ‹å¦‚æœå…¥åœºï¼Œå®é™…èƒ½æŒæœ‰å¤šä¹…æ‰è§¦å‘æ­¢ç›ˆ/æ­¢æŸ
                    # - è¶…çŸ­çº¿ï¼š15-60åˆ†é’Ÿå†…è§¦å‘æ­¢ç›ˆ
                    # - æ³¢æ®µï¼š2-24å°æ—¶æŒæœ‰æ‰è§¦å‘æ­¢ç›ˆ
                    
                    def classify_opportunity_by_actual_movement(row):
                        """åŸºäºå®é™…ä»·æ ¼èµ°å‘åˆ†ç±»æœºä¼šç±»å‹"""
                        try:
                            coin = row['coin']
                            signal_time_str = row['time']
                            entry_price = row['price']
                            
                            # è·å–è¶‹åŠ¿åˆ¤æ–­æ–¹å‘
                            trend_4h = row.get('trend_4h', '')
                            trend_15m = row.get('trend_15m', '')
                            
                            # åˆ¤æ–­å»ºè®®æ–¹å‘ï¼ˆç®€åŒ–é€»è¾‘ï¼š4Hä¸»å¯¼ï¼‰
                            if 'å¤šå¤´' in trend_4h or 'Bullish' in trend_4h:
                                direction = 'long'
                            elif 'ç©ºå¤´' in trend_4h or 'Bearish' in trend_4h:
                                direction = 'short'
                            elif 'å¤šå¤´' in trend_15m or 'Bullish' in trend_15m:
                                direction = 'long'
                            elif 'ç©ºå¤´' in trend_15m or 'Bearish' in trend_15m:
                                direction = 'short'
                            else:
                                # æ— æ³•åˆ¤æ–­æ–¹å‘ï¼Œä½¿ç”¨ä¿¡å·åˆ†æ•°ï¼ˆå›é€€åˆ°æ—§é€»è¾‘ï¼‰
                                score = row.get('signal_score', 0)
                                return 'âš¡Scalping' if (score >= 70 and score < 80) else 'ğŸŒŠSwing'
                            
                            # è®¾ç½®æ­¢ç›ˆç›®æ ‡ï¼ˆç®€åŒ–ï¼š1.5% for scalping, 3% for swingï¼‰
                            scalping_tp_pct = 0.015  # 1.5%
                            swing_tp_pct = 0.03      # 3%
                            
                            if direction == 'long':
                                scalping_tp = entry_price * (1 + scalping_tp_pct)
                                swing_tp = entry_price * (1 + swing_tp_pct)
                            else:
                                scalping_tp = entry_price * (1 - scalping_tp_pct)
                                swing_tp = entry_price * (1 - swing_tp_pct)
                            
                            # è·å–åç»­ä»·æ ¼æ•°æ®ï¼ˆä»å¸‚åœºå¿«ç…§ï¼‰
                            from datetime import datetime, timedelta
                            signal_time = datetime.strptime(signal_time_str, '%H:%M')
                            
                            # æŸ¥æ‰¾åç»­1å°æ—¶å’Œ24å°æ—¶å†…çš„ä»·æ ¼èµ°åŠ¿
                            later_snapshots = market_snapshots[
                                (market_snapshots['coin'] == coin) & 
                                (market_snapshots['time'] > signal_time_str)
                            ].sort_values('time')
                            
                            if later_snapshots.empty:
                                # æ— åç»­æ•°æ®ï¼Œä½¿ç”¨ä¿¡å·åˆ†æ•°
                                score = row.get('signal_score', 0)
                                return 'âš¡Scalping' if (score >= 70 and score < 80) else 'ğŸŒŠSwing'
                            
                            # æ£€æŸ¥1å°æ—¶å†…æ˜¯å¦è§¦å‘scalpingæ­¢ç›ˆ
                            scalping_triggered = False
                            for _, snap in later_snapshots.head(4).iterrows():  # 4ä¸ª15åˆ†é’Ÿ=1å°æ—¶
                                high = snap.get('high', snap.get('price', 0))
                                low = snap.get('low', snap.get('price', 0))
                                
                                if direction == 'long' and high >= scalping_tp:
                                    scalping_triggered = True
                                    break
                                elif direction == 'short' and low <= scalping_tp:
                                    scalping_triggered = True
                                    break
                            
                            if scalping_triggered:
                                return 'âš¡Scalping'
                            
                            # æ£€æŸ¥24å°æ—¶å†…æ˜¯å¦è§¦å‘swingæ­¢ç›ˆ
                            swing_triggered = False
                            for _, snap in later_snapshots.head(96).iterrows():  # 96ä¸ª15åˆ†é’Ÿ=24å°æ—¶
                                high = snap.get('high', snap.get('price', 0))
                                low = snap.get('low', snap.get('price', 0))
                                
                                if direction == 'long' and high >= swing_tp:
                                    swing_triggered = True
                                    break
                                elif direction == 'short' and low <= swing_tp:
                                    swing_triggered = True
                                    break
                            
                            if swing_triggered:
                                return 'ğŸŒŠSwing'
                            
                            # éƒ½æœªè§¦å‘ï¼ŒæŒ‰è¶‹åŠ¿å¼ºåº¦åˆ¤æ–­
                            score = row.get('signal_score', 0)
                            return 'ğŸŒŠSwing' if score >= 80 else 'âš¡Scalping'
                            
                        except Exception as e:
                            # å‡ºé”™æ—¶å›é€€åˆ°ä¿¡å·åˆ†æ•°
                            score = row.get('signal_score', 0)
                            return 'âš¡Scalping' if (score >= 70 and score < 80) else 'ğŸŒŠSwing'
                    
                    missed['æ¨æµ‹ç±»å‹'] = missed.apply(classify_opportunity_by_actual_movement, axis=1)
                    
                    scalping_missed = missed[missed['æ¨æµ‹ç±»å‹'] == 'âš¡Scalping']
                    swing_missed = missed[missed['æ¨æµ‹ç±»å‹'] == 'ğŸŒŠSwing']
                    
                    if not scalping_missed.empty or not swing_missed.empty:
                        review_lines.append("\nã€é”™è¿‡çš„æœºä¼šã€‘")
                        
                        if not scalping_missed.empty:
                            review_lines.append("  âš¡è¶…çŸ­çº¿æœºä¼š:")
                            for _, row in scalping_missed.head(2).iterrows():
                                review_lines.append(
                                    f"    {row['coin']}: {row['time']} å…±æŒ¯{row['indicator_consensus']}/5 "
                                    f"ä»·æ ¼{row['price']:.0f} åˆ†{row.get('signal_score', 0):.0f}"
                                )
                        
                        if not swing_missed.empty:
                            review_lines.append("  ğŸŒŠæ³¢æ®µæœºä¼š:")
                            for _, row in swing_missed.head(2).iterrows():
                                review_lines.append(
                                    f"    {row['coin']}: {row['time']} å…±æŒ¯{row['indicator_consensus']}/5 "
                                    f"ä»·æ ¼{row['price']:.0f} åˆ†{row.get('signal_score', 0):.0f}"
                                )
        
        return "\n".join(review_lines)
        
    except Exception as e:
        return f"å¤ç›˜å¤±è´¥: {e}"


def send_recovery_notification_v7(model_name, recovery_type, pause_level, new_pause_level):
    """å‘é€å†·é™æœŸæ¢å¤é€šçŸ¥"""
    if recovery_type == "profit_exit":
        title = f"[{model_name}]ç›ˆåˆ©æ¢å¤ğŸ‰"
        content = f"å†·é™æœŸå†…è·åˆ©ï¼Œæå‰æ¢å¤äº¤æ˜“ï¼\n\næš‚åœç­‰çº§: {pause_level}çº§â†’{new_pause_level}çº§\næ¢å¤æ—¶é—´: {datetime.now().strftime('%H:%M')}"
    else:
        title = f"[{model_name}]å†·é™æœŸç»“æŸâœ…"
        content = f"å†·é™æœŸå·²ç»“æŸï¼Œæ¢å¤æ­£å¸¸äº¤æ˜“\n\næš‚åœç­‰çº§: {pause_level}çº§â†’0çº§\næ¢å¤æ—¶é—´: {datetime.now().strftime('%H:%M')}"
    
    send_bark_notification(title, content)



def load_learning_config():
    """åŠ è½½å­¦ä¹ å‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰"""
    if LEARNING_CONFIG_FILE.exists():
        try:
            with open(LEARNING_CONFIG_FILE, "r", encoding="utf-8") as f:
                config = json.load(f)

                # å¦‚æœæ˜¯æ—§ç‰ˆæœ¬é…ç½®ï¼Œè‡ªåŠ¨å‡çº§
                if "version" not in config:
                    print("âš ï¸ æ£€æµ‹åˆ°æ—§ç‰ˆé…ç½®ï¼Œè‡ªåŠ¨å‡çº§åˆ°v7.9.1...")
                    new_config = get_default_config()
                    # ä¿ç•™æ—§çš„å…¨å±€å‚æ•°
                    new_config["global"]["min_risk_reward"] = config.get(
                        "min_risk_reward", 1.5
                    )
                    new_config["global"]["atr_stop_multiplier"] = config.get(
                        "atr_stop_multiplier", 1.5
                    )
                    new_config["global"]["min_indicator_consensus"] = config.get(
                        "min_indicator_consensus", 4
                    )
                    new_config["global"]["key_level_penalty"] = config.get(
                        "key_level_penalty", 1.0
                    )
                    save_learning_config(new_config)  # ğŸ”§ V7.9.1: ç«‹å³ä¿å­˜å‡çº§åçš„é…ç½®
                    return new_config

                return config
        except Exception as e:
            print(f"âš ï¸ åŠ è½½é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return get_default_config()

    # ğŸ”§ V7.9.1: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼Œè‡ªåŠ¨åˆ›å»ºå¹¶ä¿å­˜
    print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºV7.9.1é»˜è®¤é…ç½®...")
    config = get_default_config()
    save_learning_config(config)
    print(f"âœ“ å·²ç”Ÿæˆé…ç½®æ–‡ä»¶: {LEARNING_CONFIG_FILE}")
    return config


def save_learning_config(config):
    """ä¿å­˜å­¦ä¹ å‚æ•°"""
    try:
        # ã€V8.3.21.5ä¿®å¤ã€‘æ£€æŸ¥å¹¶ä¿®å¤è¿‡é«˜çš„å…±æŒ¯é˜ˆå€¼
        fixed_consensus = False
        for strategy in ['scalping', 'swing']:
            if strategy in config:
                old_consensus = config[strategy].get('min_consensus', 2)
                if old_consensus >= 2:
                    config[strategy]['min_consensus'] = 1
                    # æé«˜ä¿¡å·è´¨é‡è¦æ±‚ä½œä¸ºè¡¥å¿ï¼ˆ75åˆ†ä»¥ä¸Šç›¸å¯¹å®‰å…¨ï¼‰
                    config[strategy]['min_signal_score'] = max(75, config[strategy].get('min_signal_score', 60))
                    fixed_consensus = True
                    print(f"  ğŸ”§ è‡ªåŠ¨ä¿®å¤{strategy} min_consensus: {old_consensus} â†’ 1 (æé«˜signal_scoreâ‰¥75)")
        
        if fixed_consensus:
            print("  ğŸ’¡ åŸå› ï¼šå…±æŒ¯â‰¥2ä¼šé”™è¿‡98%çš„é«˜è´¨é‡æœºä¼šï¼ˆå¦‚BNB 82åˆ†/2å…±æŒ¯ ç›ˆåˆ©20%ï¼‰")
        
        config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(LEARNING_CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump(config, f, ensure_ascii=False, indent=2, default=str)  # ğŸ”§ V7.6.7: æ·»åŠ default=stré˜²æ­¢boolåºåˆ—åŒ–é”™è¯¯
        print(f"âœ“ å­¦ä¹ å‚æ•°å·²æ›´æ–°: {LEARNING_CONFIG_FILE}")
    except Exception as e:
        print(f"âœ— ä¿å­˜å­¦ä¹ å‚æ•°å¤±è´¥: {e}")


def _cold_start_optimization():
    """å†·å¯åŠ¨æ¨¡å¼ï¼šæ— äº¤æ˜“æ ·æœ¬æ—¶æ”¾å®½å‚æ•°ï¼Œå¸®åŠ©ç³»ç»Ÿå¼€å•ç§¯ç´¯æ•°æ®"""
    print("\n" + "=" * 70)
    print("ã€â„ï¸ å†·å¯åŠ¨ä¼˜åŒ–ã€‘")
    print("=" * 70)
    
    config = load_learning_config()
    
    # æ”¾å®½å…¨å±€å‚æ•°ï¼Œè®©ç³»ç»Ÿæ›´å®¹æ˜“å¼€å•
    adjustments = {
        "global": {
            "min_risk_reward": 1.2,  # é™ä½ç›ˆäºæ¯”è¦æ±‚ï¼ˆåŸæœ¬å¯èƒ½æ˜¯1.5+ï¼‰
            "min_indicator_consensus": 3,  # é™ä½æŒ‡æ ‡å…±æŒ¯è¦æ±‚
            "atr_stop_multiplier": 1.8,  # é€‚åº¦æ”¾å®½æ­¢æŸ
            "base_position_ratio": 0.15,  # ä¿æŒè¾ƒå°ä»“ä½ï¼Œæ§åˆ¶é£é™©
            "min_trend_strength": 0.5,  # é™ä½è¶‹åŠ¿å¼ºåº¦è¦æ±‚
            "key_level_penalty": 0.8,  # æ”¾å®½å…³é”®ä½é™åˆ¶
        }
    }
    
    print("\nğŸ“‹ å†·å¯åŠ¨è°ƒæ•´ç­–ç•¥ï¼š")
    print("- é™ä½ç›ˆäºæ¯”è¦æ±‚ â†’ 1.2:1ï¼ˆæ”¾å®½è¿›åœºé—¨æ§›ï¼‰")
    print("- é™ä½æŒ‡æ ‡å…±æŒ¯è¦æ±‚ â†’ 3/5ï¼ˆå‡å°‘ä¿¡å·ç­›é€‰ï¼‰")
    print("- ä¿æŒå°ä»“ä½ â†’ 15%ï¼ˆæ§åˆ¶å•ç¬”é£é™©ï¼‰")
    print("- ç›®æ ‡ï¼šå¿«é€Ÿç§¯ç´¯5-10ç¬”äº¤æ˜“æ ·æœ¬ï¼Œå»ºç«‹AIè®¤çŸ¥åŸºç¡€")
    
    # åº”ç”¨è°ƒæ•´
    config["global"].update(adjustments["global"])
    save_learning_config(config)
    
    print("\nâœ… å†·å¯åŠ¨å‚æ•°å·²ç”Ÿæ•ˆï¼Œç³»ç»Ÿå°†æ›´å®¹æ˜“å¼€å•")
    print("ğŸ’¡ å»ºè®®ï¼šè§‚å¯Ÿ1-2å¤©ï¼Œç§¯ç´¯æ ·æœ¬åAIå°†è¿›å…¥æ¢ç´¢/å­¦ä¹ æ¨¡å¼")


def get_learning_config_for_symbol(symbol, config=None):
    """è·å–ç‰¹å®šå¸ç§çš„å­¦ä¹ å‚æ•°ï¼ˆåˆ†å±‚ä¼˜å…ˆçº§ï¼‰
    
    V7.5æ–°å¢ï¼šæ–°æ‰‹å®‰å…¨æ¨¡å¼ä¼˜å…ˆçº§æœ€é«˜
    """
    if config is None:
        config = load_learning_config()

    # ğŸ†• V7.8.3: ä¼˜å…ˆæ£€æŸ¥äº¤æ˜“ç»éªŒï¼Œä½¿ç”¨AIä¼˜åŒ–+å®‰å…¨ç³»æ•°
    trade_count, experience_level = get_trading_experience_level()
    safe_params = get_safe_params_by_experience(trade_count, config)  # ä¼ é€’config
    
    if safe_params is not None:
        # æ–°æ‰‹/å­¦ä¹ æœŸ/æˆé•¿æœŸï¼Œä½¿ç”¨AIä¼˜åŒ–+å®‰å…¨ç³»æ•°
        final_config = config["global"].copy()
        final_config.update(safe_params)
        final_config["symbol"] = symbol
        final_config["risk_profile"] = "safe_mode"
        final_config["_source"] = f"{safe_params['_mode']} (äº¤æ˜“{trade_count}ç¬”)"
        print(f"ğŸ›¡ï¸ å¯ç”¨{safe_params['_mode']}ï¼šäº¤æ˜“ç»éªŒ{trade_count}ç¬”")
        if '_ai_base' in safe_params:
            print(f"   ğŸ“Š AIåŸºå‡†: {safe_params['_ai_base']}")
        return final_config

    # 1. å¦‚æœæœ‰å¸ç§ç‰¹å®šå‚æ•°ä¸”æ ·æœ¬å……è¶³ï¼Œä½¿ç”¨å¸ç§å‚æ•°
    per_symbol = config.get("per_symbol", {})
    if symbol in per_symbol:
        symbol_config = per_symbol[symbol]
        if symbol_config.get("sample_count", 0) >= 5:
            symbol_config["_source"] = f"{symbol}ç‰¹å®šå‚æ•°"
            return symbol_config

    # 2. ã€V7.9.1ã€‘ä½¿ç”¨é£é™©ç­‰çº§å®‰å…¨ç³»æ•°ï¼ˆAIåŸºå‡†Ã—ç³»æ•°ï¼Œè€Œéç¡¬ç¼–ç ï¼‰
    risk_profile = config.get("risk_profiles", {}).get(symbol, "medium_risk")
    safety_multipliers = config.get("risk_safety_multipliers", {}).get(risk_profile, {})
    fallback_minimums = config.get("risk_fallback_minimums", {}).get(risk_profile, {})

    # 3. ã€V7.9.1ã€‘æ™ºèƒ½åˆå¹¶ï¼šAIå­¦ä¹ å€¼ Ã— å®‰å…¨ç³»æ•°
    final_config = config["global"].copy()
    
    # è·å–AIå­¦ä¹ çš„åŸºå‡†å€¼ï¼ˆglobalæˆ–per_symbolï¼‰
    ai_base_rr = config["global"].get("min_risk_reward", 1.5)
    ai_base_score = config["global"].get("min_signal_score", 55)
    
    # å¦‚æœå¸ç§æœ‰ç‹¬ç«‹å­¦ä¹ å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ï¼ˆä½†æ ·æœ¬è¦å……è¶³ï¼‰
    per_symbol_data = config.get("per_symbol", {}).get(symbol, {})
    if per_symbol_data.get("sample_count", 0) >= 10:  # è‡³å°‘10ç¬”æ‰ä¿¡ä»»
        ai_base_rr = per_symbol_data.get("min_risk_reward", ai_base_rr)
        ai_base_score = per_symbol_data.get("min_signal_score", ai_base_score)
        print(f"   ğŸ“Š ä½¿ç”¨{symbol}ç‹¬ç«‹å­¦ä¹ å‚æ•°ï¼ˆ{per_symbol_data['sample_count']}ç¬”ï¼‰")
    
    # åº”ç”¨å®‰å…¨ç³»æ•°
    rr_multiplier = safety_multipliers.get("min_risk_reward_multiplier", 1.0)
    score_bonus = safety_multipliers.get("min_signal_score_bonus", 0)
    
    calculated_rr = ai_base_rr * rr_multiplier
    calculated_score = ai_base_score + score_bonus
    
    # ç¡®ä¿ä¸ä½äºæœ€ä½åŸºå‡†ï¼ˆé˜²æ­¢AIå­¦ä¹ å‡ºé”™ï¼‰
    final_config["min_risk_reward"] = max(
        calculated_rr,
        fallback_minimums.get("min_risk_reward", 1.5)
    )
    
    final_config["min_signal_score"] = max(
        calculated_score,
        fallback_minimums.get("min_signal_score", 55)
    )
    
    # å¯¹å…±æŒ¯è¦æ±‚ï¼šä½¿ç”¨å®‰å…¨ç³»æ•°çš„è®¾å®šï¼ˆå·²ç»è€ƒè™‘äº†é£é™©ç­‰çº§ï¼‰
    if "min_indicator_consensus" in safety_multipliers:
        final_config["min_indicator_consensus"] = safety_multipliers["min_indicator_consensus"]
    
    # å…¶ä»–å‚æ•°ä½¿ç”¨å®‰å…¨ç³»æ•°çš„è®¾å®š
    for key in ["atr_stop_multiplier", "base_position_ratio"]:
        if key in safety_multipliers:
            final_config[key] = safety_multipliers[key]
    
    final_config["risk_profile"] = risk_profile
    final_config["symbol"] = symbol
    
    # ã€V7.9.1ã€‘æ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹ï¼Œä¾¿äºç†è§£
    if per_symbol_data.get("sample_count", 0) >= 10:
        final_config["_source"] = f"{risk_profile}(AIå­¦Ã—{rr_multiplier})"
    else:
        final_config["_source"] = f"{risk_profile}(å…¨å±€Ã—{rr_multiplier})"
    
    print(f"   ğŸ’¡ {symbol}æœ€ç»ˆè¦æ±‚: R:Râ‰¥{final_config['min_risk_reward']:.1f} åˆ†â‰¥{final_config['min_signal_score']}")

    return final_config


def detect_market_regime(market_data_list):
    """æ£€æµ‹å½“å‰å¸‚åœºç¯å¢ƒ"""
    try:
        if not market_data_list:
            return "unknown", False

        # è®¡ç®—å¸‚åœºæ•´ä½“æ³¢åŠ¨ç‡
        volatilities = []
        for data in market_data_list:
            if data is None:
                continue  # è·³è¿‡è·å–å¤±è´¥çš„å¸ç§
            price_change_pct = abs(data.get("price_change", 0))
            volatilities.append(price_change_pct)

        avg_volatility = sum(volatilities) / len(volatilities) if volatilities else 0

        # åˆ¤æ–­å¸‚åœºç¯å¢ƒ
        if avg_volatility > 5.0:  # æ—¥æ³¢åŠ¨>5%
            return "high_volatility", True  # æš‚åœäº¤æ˜“
        elif avg_volatility > 2.0:  # æ—¥æ³¢åŠ¨>2%
            return "trend", False  # è¶‹åŠ¿å¸‚
        elif avg_volatility < 1.0:  # æ—¥æ³¢åŠ¨<1%
            return "range", False  # éœ‡è¡å¸‚
        else:
            return "trend", False  # é»˜è®¤è¶‹åŠ¿å¸‚

    except Exception as e:
        print(f"âš ï¸ å¸‚åœºç¯å¢ƒæ£€æµ‹å¤±è´¥: {e}")
        return "unknown", False


def calculate_position_size_smart(symbol, signal_quality, total_assets, config, signal_type='swing'):
    """ã€V7.9å¢å¼ºã€‘æ™ºèƒ½ä»“ä½è®¡ç®—ï¼ˆåˆ†Scalping/Swingç‹¬ç«‹è®¡ç®—ï¼‰
    
    Args:
        symbol: äº¤æ˜“å¯¹
        signal_quality: ä¿¡å·è´¨é‡ï¼ˆHIGH/MEDIUM/LOWï¼‰
        total_assets: æ€»èµ„äº§
        config: é…ç½®
        signal_type: ä¿¡å·ç±»å‹ï¼ˆscalping/swingï¼‰
    """
    try:
        # 1. è·å–åˆ†ç±»å‹å‚æ•°
        if signal_type == 'scalping':
            type_params = config.get('global', {}).get('scalping_params', {})
        else:
            type_params = config.get('global', {}).get('swing_params', {})

        # 2. åŸºç¡€ä»“ä½ï¼ˆä½¿ç”¨åˆ†ç±»å‹å‚æ•°ï¼‰
        base_ratio = type_params.get("base_position_ratio", 0.20)
        base_position = total_assets * base_ratio

        # 3. æ ¹æ®ä¿¡å·è´¨é‡è°ƒæ•´
        if signal_quality == "HIGH":
            multiplier = 1.5
        elif signal_quality == "MEDIUM":
            multiplier = 1.0
        else:  # LOW
            multiplier = 0.7

        position = base_position * multiplier

        # 4. æ£€æŸ¥æœ€å¤§ä»“ä½é™åˆ¶ï¼ˆä½¿ç”¨åˆ†ç±»å‹å‚æ•°ï¼‰
        max_ratio = type_params.get("max_position_ratio", 0.30)
        max_position = total_assets * max_ratio
        position = min(position, max_position)

        # 5. æ£€æŸ¥å•ç¬”æœ€å¤§äºæŸé™åˆ¶
        max_loss_ratio = config.get('global', {}).get("max_loss_per_trade", 0.02)
        max_loss_position = total_assets * max_loss_ratio / 0.02  # å‡è®¾2%æ­¢æŸ
        position = min(position, max_loss_position)

        type_name_cn = "è¶…çŸ­çº¿" if signal_type == 'scalping' else "æ³¢æ®µ"
        print(f"   ã€V7.9ä»“ä½ã€‘{type_name_cn}: åŸºç¡€{base_ratio*100:.0f}% â†’ è´¨é‡Ã—{multiplier} = ${position:.2f}")

        return position

    except Exception as e:
        print(f"âš ï¸ æ™ºèƒ½ä»“ä½è®¡ç®—å¤±è´¥: {e}")
        # è¿”å›ä¿å®ˆä»“ä½
        return total_assets * 0.15



def check_signal_type_risk_budget(signal_type, current_positions, planned_position, config):
    """ã€V7.9æ–°å¢ã€‘æ£€æŸ¥åˆ†ç±»å‹é£é™©é¢„ç®—
    
    Args:
        signal_type: ä¿¡å·ç±»å‹ï¼ˆscalping/swingï¼‰
        current_positions: å½“å‰æŒä»“åˆ—è¡¨
        planned_position: è®¡åˆ’å¼€ä»“é‡‘é¢
        config: é…ç½®
    
    Returns:
        (allowed: bool, reason: str, adjusted_position: float)
    """
    try:
        # è·å–åˆ†ç±»å‹å‚æ•°
        if signal_type == 'scalping':
            type_params = config.get('global', {}).get('scalping_params', {})
        else:
            type_params = config.get('global', {}).get('swing_params', {})
        
        max_concurrent = type_params.get('max_concurrent_positions', 2)
        total_risk_budget = type_params.get('total_risk_budget', 0.05)
        
        # ç»Ÿè®¡åŒç±»å‹ç°æœ‰æŒä»“
        same_type_positions = [
            p for p in current_positions 
            if p.get('signal_type') == signal_type or p.get('_temp_signal_type') == signal_type
                ]
        
        # æ£€æŸ¥æ•°é‡é™åˆ¶
        type_name_cn = "è¶…çŸ­çº¿" if signal_type == 'scalping' else "æ³¢æ®µ"
        if len(same_type_positions) >= max_concurrent:
            return False, f"{type_name_cn}æŒä»“å·²è¾¾ä¸Šé™({max_concurrent}ä¸ª)", 0
        
        # æ£€æŸ¥é£é™©é¢„ç®—
        # ä»position_contexts.jsonè¯»å–signal_typeï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from pathlib import Path
            import json
            model_name = os.getenv("MODEL_NAME", "deepseek")
            context_file = Path("trading_data") / model_name / "position_contexts.json"
            if context_file.exists():
                with open(context_file, 'r', encoding='utf-8') as f:
                    contexts = json.load(f)
                    for pos in same_type_positions:
                        coin = pos['symbol'].split('/')[0]
                        if coin in contexts and 'signal_type' in contexts[coin]:
                            pos['_temp_signal_type'] = contexts[coin]['signal_type']
        except:
            pass
        
        # é‡æ–°è®¡ç®—ï¼ˆè€ƒè™‘ä¸´æ—¶æ ‡è®°ï¼‰
        same_type_positions = [
            p for p in current_positions 
            if p.get('_temp_signal_type') == signal_type
                ]
        
        total_same_type_risk = sum([abs(p.get('unrealized_pnl', 0)) for p in same_type_positions])
        
        # ä»TRADES_FILEè¯»å–æœ€è¿‘çš„æ€»èµ„äº§
        try:
            total_assets = 100  # é»˜è®¤å€¼
            if TRADES_FILE.exists():
                import pandas as pd
                df = pd.read_csv(TRADES_FILE)
                if not df.empty and 'ä»“ä½(U)' in df.columns:
                    recent_positions = df['ä»“ä½(U)'].dropna()
                    if len(recent_positions) > 0:
                        # ä¼°ç®—æ€»èµ„äº§ï¼ˆå‡è®¾å¹³å‡ä»“ä½å 20%ï¼‰
                        avg_position = recent_positions.mean()
                        total_assets = avg_position / 0.20
        except:
            pass
        
        max_risk = total_assets * total_risk_budget
        remaining_budget = max_risk - total_same_type_risk
        
        if remaining_budget < planned_position * 0.02:  # å‡è®¾2%é£é™©
            # å°è¯•è°ƒæ•´ä»“ä½
            adjusted = remaining_budget / 0.02
            if adjusted < planned_position * 0.5:  # å¦‚æœè°ƒæ•´å<50%ï¼Œæ‹’ç»
                return False, f"{type_name_cn}é£é™©é¢„ç®—ä¸è¶³({total_same_type_risk:.2f}/{max_risk:.2f}U)", 0
            else:
                return True, f"{type_name_cn}é£é™©é¢„ç®—ç´§å¼ ï¼Œä»“ä½è°ƒæ•´", adjusted
        
        return True, f"{type_name_cn}é£é™©é¢„ç®—å……è¶³", planned_position
    
    except Exception as e:
        print(f"âš ï¸ é£é™©é¢„ç®—æ£€æŸ¥å¤±è´¥: {e}")
        return True, "æ£€æŸ¥å¤±è´¥ï¼Œæ”¾è¡Œ", planned_position


def check_scalping_frequency(coin_name, config):
    """ã€V7.9æ–°å¢ã€‘æ£€æŸ¥Scalpingé¢‘ç‡é™åˆ¶
    
    Args:
        coin_name: å¸ç§åç§°
        config: é…ç½®
    
    Returns:
        (allowed: bool, reason: str)
    """
    try:
        from datetime import datetime, timedelta
        
        scalping_params = config.get('global', {}).get('scalping_params', {})
        cooldown_same = scalping_params.get('cooldown_same_coin_minutes', 30)
        cooldown_any = scalping_params.get('cooldown_any_coin_minutes', 15)
        max_per_hour = scalping_params.get('max_trades_per_hour', 4)
        
        # è¯»å–æœ€è¿‘çš„äº¤æ˜“è®°å½•
        if not TRADES_FILE.exists():
            return True, "æ— å†å²è®°å½•"
        
        import pandas as pd
        df = pd.read_csv(TRADES_FILE)
        if df.empty:
            return True, "æ— äº¤æ˜“è®°å½•"
        
        now = datetime.now()
        
        # è½¬æ¢æ—¶é—´ï¼ˆå¤„ç†å¯èƒ½çš„å¼‚å¸¸ï¼‰
        try:
            df['å¼€ä»“æ—¶é—´_dt'] = pd.to_datetime(df['å¼€ä»“æ—¶é—´'], errors='coerce')
            df = df.dropna(subset=['å¼€ä»“æ—¶é—´_dt'])
        except:
            return True, "æ—¶é—´è§£æå¤±è´¥ï¼Œæ”¾è¡Œ"
        
        # åªçœ‹Scalpingè®¢å•ï¼ˆå¦‚æœæœ‰signal_typeå­—æ®µï¼‰
        if 'ä¿¡å·ç±»å‹' in df.columns:
            scalping_df = df[df['ä¿¡å·ç±»å‹'] == 'scalping'].copy()
        else:
            # æ²¡æœ‰signal_typeï¼ŒæŒ‰é¢„æœŸæŒä»“æ—¶é—´åˆ¤æ–­ï¼ˆ<1å°æ—¶è§†ä¸ºScalpingï¼‰
            if 'é¢„æœŸæŒä»“(åˆ†é’Ÿ)' in df.columns:
                scalping_df = df[df['é¢„æœŸæŒä»“(åˆ†é’Ÿ)'] < 60].copy()
            else:
                scalping_df = df  # æ— æ³•åˆ¤æ–­ï¼Œæ£€æŸ¥å…¨éƒ¨
        
        # æ£€æŸ¥1: åŒå¸ç§å†·å´æœŸ
        same_coin_recent = scalping_df[
            (scalping_df['å¸ç§'] == coin_name) &
            (scalping_df['å¼€ä»“æ—¶é—´_dt'] > now - timedelta(minutes=cooldown_same))
        ]
        if len(same_coin_recent) > 0:
            last_time = same_coin_recent['å¼€ä»“æ—¶é—´_dt'].max()
            wait_minutes = cooldown_same - (now - last_time).total_seconds() / 60
            return False, f"{coin_name}å†·å´ä¸­ï¼ˆè¿˜éœ€{wait_minutes:.0f}åˆ†é’Ÿï¼‰"
        
        # æ£€æŸ¥2: ä»»æ„å¸ç§å†·å´æœŸ
        any_coin_recent = scalping_df[
            scalping_df['å¼€ä»“æ—¶é—´_dt'] > now - timedelta(minutes=cooldown_any)
        ]
        if len(any_coin_recent) > 0:
            last_time = any_coin_recent['å¼€ä»“æ—¶é—´_dt'].max()
            wait_minutes = cooldown_any - (now - last_time).total_seconds() / 60
            return False, f"Scalpingå…¨å±€å†·å´ä¸­ï¼ˆè¿˜éœ€{wait_minutes:.0f}åˆ†é’Ÿï¼‰"
        
        # æ£€æŸ¥3: æ¯å°æ—¶äº¤æ˜“æ•°
        last_hour = scalping_df[
            scalping_df['å¼€ä»“æ—¶é—´_dt'] > now - timedelta(hours=1)
        ]
        if len(last_hour) >= max_per_hour:
            return False, f"Scalpingæ¯å°æ—¶äº¤æ˜“é™åˆ¶({len(last_hour)}/{max_per_hour})"
        
        return True, f"Scalpingé¢‘ç‡æ£€æŸ¥é€šè¿‡ï¼ˆ{len(last_hour)}/{max_per_hour}ç¬”/å°æ—¶ï¼‰"
    
    except Exception as e:
        print(f"âš ï¸ Scalpingé¢‘ç‡æ£€æŸ¥å¤±è´¥: {e}")
        return True, "æ£€æŸ¥å¤±è´¥ï¼Œæ”¾è¡Œ"


def check_cash_reserve(total_assets, available_balance, planned_position_usd, current_positions):
    """
    æ£€æŸ¥ç°é‡‘å‚¨å¤‡æ¯”ä¾‹ï¼ˆé˜²æ­¢æ»¡ä»“çˆ†ä»“ï¼‰
    
    è§„åˆ™ï¼š
    - è‡³å°‘ä¿ç•™20%ç°é‡‘ä½œä¸ºå®‰å…¨å‚¨å¤‡
    - æ»¡ä»“é£é™©è¿‡é«˜ï¼Œå¿…é¡»ä¿ç•™åº”æ€¥èµ„é‡‘
    
    Args:
        total_assets: æ€»èµ„äº§
        available_balance: å¯ç”¨ä½™é¢
        planned_position_usd: è®¡åˆ’å¼€ä»“é‡‘é¢
        current_positions: å½“å‰æŒä»“åˆ—è¡¨
    
    Returns:
        (allowed: bool, reason: str, adjusted_position: float)
    """
    try:
        # è®¡ç®—å·²ä½¿ç”¨ä¿è¯é‡‘
        used_margin = 0
        for pos in current_positions:
            position_value = abs(pos.get("contracts", 0) * pos.get("entry_price", 0))
            leverage = pos.get("leverage", 1)
            if leverage > 0:
                used_margin += position_value / leverage
        
        # è®¡ç®—ç°é‡‘å‚¨å¤‡æ¯”ä¾‹ï¼ˆæœ€ä½20%ï¼‰
        MIN_CASH_RESERVE_RATIO = 0.20  # 20%
        required_reserve = total_assets * MIN_CASH_RESERVE_RATIO
        
        # è®¡åˆ’å¼€ä»“åçš„å‰©ä½™ç°é‡‘
        remaining_cash = available_balance - planned_position_usd
        
        if remaining_cash < required_reserve:
            # è®¡ç®—å…è®¸çš„æœ€å¤§å¼€ä»“é‡‘é¢
            max_allowed_position = available_balance - required_reserve
            
            if max_allowed_position < planned_position_usd * 0.3:  # å¦‚æœè°ƒæ•´å<30%ï¼Œç›´æ¥æ‹’ç»
                return False, f"ç°é‡‘å‚¨å¤‡ä¸è¶³ï¼ˆéœ€ä¿ç•™{MIN_CASH_RESERVE_RATIO*100:.0f}%={required_reserve:.2f}Uï¼Œå‰©ä½™{remaining_cash:.2f}Uï¼‰", 0
            else:
                return True, f"ç°é‡‘å‚¨å¤‡ç´§å¼ ï¼Œä»“ä½è°ƒæ•´è‡³{max_allowed_position:.2f}U", max_allowed_position
        
        # è®¡ç®—ä½¿ç”¨ç‡
        usage_rate = (used_margin + planned_position_usd) / total_assets * 100
        
        return True, f"ç°é‡‘å‚¨å¤‡å……è¶³ï¼ˆä½¿ç”¨ç‡{usage_rate:.1f}%ï¼Œå‚¨å¤‡{remaining_cash:.2f}Uï¼‰", planned_position_usd
    
    except Exception as e:
        print(f"âš ï¸ ç°é‡‘å‚¨å¤‡æ£€æŸ¥å¤±è´¥: {e}")
        return True, "æ£€æŸ¥å¤±è´¥ï¼Œæ”¾è¡Œ", planned_position_usd


def update_position_after_adding(symbol, side, new_avg_price, new_total_amount, 
                                  new_amount, new_price, add_reason, signal_score, 
                                  price_improvement_pct):
    """
    æ›´æ–°CSVè®°å½•ï¼Œè¿½åŠ åŠ ä»“å†å²ï¼ˆV8.5.2æ–°å¢ï¼‰
    
    æ ¼å¼ï¼šåŸå§‹ç†ç”± | [åŠ ä»“N] æ—¶é—´ +æ•°é‡@ä»·æ ¼ ç†ç”±:xxx
    
    Args:
        symbol: äº¤æ˜“å¯¹
        side: æ–¹å‘ (long/short)
        new_avg_price: æ–°çš„å¹³å‡å¼€ä»“ä»·
        new_total_amount: æ–°çš„æ€»æ•°é‡
        new_amount: æœ¬æ¬¡åŠ ä»“æ•°é‡
        new_price: æœ¬æ¬¡åŠ ä»“ä»·æ ¼
        add_reason: åŠ ä»“ç†ç”±ï¼ˆç®€çŸ­ï¼‰
        signal_score: ä¿¡å·è¯„åˆ†
        price_improvement_pct: ä»·æ ¼æ”¹å–„ç™¾åˆ†æ¯”
    """
    import fcntl
    import shutil
    
    coin_name = symbol.split('/')[0]
    side_cn = "å¤š" if side == "long" else "ç©º"
    
    max_retries = 3
    for attempt in range(max_retries):
        lock_file = None
        try:
            # 1. åˆ›å»ºæ–‡ä»¶é”
            lock_path = TRADES_FILE.parent / f"{TRADES_FILE.name}.lock"
            lock_file = open(lock_path, "w")
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
            
            # 2. åˆ›å»ºå¤‡ä»½
            backup_path = TRADES_FILE.parent / f"{TRADES_FILE.name}.backup"
            if TRADES_FILE.exists():
                shutil.copy2(TRADES_FILE, backup_path)
            
            # 3. è¯»å–ç°æœ‰æ•°æ®
            df = pd.read_csv(TRADES_FILE, encoding="utf-8")
            df.columns = df.columns.str.strip().str.replace("\ufeff", "")
            
            # 4. æ‰¾åˆ°è¯¥å¸ç§ã€è¯¥æ–¹å‘ã€æœªå¹³ä»“çš„è®°å½•
            mask = (
                (df["å¸ç§"] == coin_name)
                & (df["æ–¹å‘"] == side_cn)
                & (df["å¹³ä»“æ—¶é—´"].isna())
            )
            matching_rows = df[mask]
            
            if matching_rows.empty:
                print(f"  âš ï¸ æœªæ‰¾åˆ° {coin_name} {side_cn} çš„æœªå¹³ä»“è®°å½•ï¼Œæ— æ³•è®°å½•åŠ ä»“")
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                lock_file.close()
                return
            
            # 5. æ›´æ–°è®°å½•
            last_idx = matching_rows.index[-1]
            original_reason = str(df.at[last_idx, "å¼€ä»“ç†ç”±"])
            
            # è®¡ç®—æ˜¯ç¬¬å‡ æ¬¡åŠ ä»“
            add_count = original_reason.count("[åŠ ä»“") + 1
            
            # æ„å»ºåŠ ä»“è®°å½•
            current_time = datetime.now().strftime("%H:%M")
            add_entry = (
                f" | [åŠ ä»“{add_count}] {current_time} "
                f"+{new_amount:.3f}@{new_price:.2f} "
                f"ç†ç”±:{add_reason}+ä»·æ ¼ä¼˜{abs(price_improvement_pct):.1f}%+ä¿¡å·åˆ†{signal_score}"
            )
            
            # æ›´æ–°å­—æ®µ
            df.at[last_idx, "å¼€ä»“ä»·"] = new_avg_price
            df.at[last_idx, "å¼€ä»“ç†ç”±"] = original_reason + add_entry
            
            # 6. ä¿å­˜
            temp_file = TRADES_FILE.parent / f"{TRADES_FILE.name}.tmp"
            df.to_csv(temp_file, index=False, encoding="utf-8")
            temp_file.replace(TRADES_FILE)
            
            print(f"  ğŸ“ å·²è®°å½•åŠ ä»“{add_count}: +{new_amount:.3f}@{new_price:.2f}, æ–°å¹³å‡ä»·{new_avg_price:.2f}")
            
            # 7. é‡Šæ”¾é”
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
            lock_file.close()
            break
            
        except Exception as e:
            print(f"  âš ï¸ æ›´æ–°åŠ ä»“è®°å½•å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if lock_file:
                try:
                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                    lock_file.close()
                except:
                    pass
            
            if attempt == max_retries - 1:
                print(f"  âŒ åŠ ä»“è®°å½•æ›´æ–°å¤±è´¥")
            else:
                import time
                time.sleep(0.5)
                continue


def add_to_position(symbol, side, new_amount, new_price, leverage, existing_position, 
                    ai_signal, price_improvement_pct, available_balance, current_positions):
    """
    åŠ ä»“åˆ°ç°æœ‰æŒä»“ï¼ˆV8.5.2æ–°å¢ï¼‰
    
    Args:
        symbol: äº¤æ˜“å¯¹
        side: æ–¹å‘ (long/short)
        new_amount: æ–°å¢æ•°é‡
        new_price: æ–°å¢ä»·æ ¼
        leverage: æ æ†
        existing_position: ç°æœ‰æŒä»“ä¿¡æ¯
        ai_signal: AIä¿¡å·
        price_improvement_pct: ä»·æ ¼æ”¹å–„ç™¾åˆ†æ¯”
        available_balance: å¯ç”¨ä½™é¢
        current_positions: å½“å‰æ‰€æœ‰æŒä»“
    
    Returns:
        åŠ ä»“æ˜¯å¦æˆåŠŸ
    """
    try:
        coin_name = symbol.split('/')[0]
        side_cn = "å¤š" if side == "long" else "ç©º"
        
        # 1. è®¡ç®—åŸæŒä»“æˆæœ¬
        old_amount = existing_position.get('size', 0)
        old_price = existing_position.get('entry_price', 0)
        old_cost = old_amount * old_price
        
        # 2. è®¡ç®—æ–°å¢æˆæœ¬
        new_cost = new_amount * new_price
        
        # 3. è®¡ç®—åˆå¹¶åçš„å¹³å‡ä»·
        total_amount = old_amount + new_amount
        avg_price = (old_cost + new_cost) / total_amount
        
        print(f"\nğŸ”¼ æ‰§è¡ŒåŠ ä»“: {coin_name} {side_cn}")
        print(f"  åŸæŒä»“: {old_amount:.3f}ä¸ª @{old_price:.2f}")
        print(f"  æ–°å¢: {new_amount:.3f}ä¸ª @{new_price:.2f}")
        print(f"  åˆå¹¶å: {total_amount:.3f}ä¸ª @{avg_price:.2f}")
        
        # 4. æ‰§è¡Œå¸‚ä»·å•åŠ ä»“
        order_side = 'buy' if side == 'long' else 'sell'
        order = exchange.create_market_order(
            symbol,
            order_side,
            new_amount,
            params={'tag': 'f1ee03b510d5SUDE'}
        )
        print(f"  âœ“ åŠ ä»“è®¢å•å·²æ‰§è¡Œ")
        
        # 5. æ›´æ–°CSVè®°å½•
        add_reason = ai_signal.get('reason', 'é‡‘å­—å¡”åŠ ä»“')[:20]  # ç®€çŸ­ç†ç”±
        signal_score = ai_signal.get('signal_quality', 0)
        
        update_position_after_adding(
            symbol, side, avg_price, total_amount,
            new_amount, new_price, add_reason, signal_score,
            price_improvement_pct
        )
        
        # 6. é‡æ–°è®¡ç®—å¹¶è®¾ç½®æ­¢ç›ˆæ­¢æŸ
        try:
            # æ¸…ç†æ—§çš„æ­¢ç›ˆæ­¢æŸè®¢å•
            clear_symbol_orders(symbol, verbose=False)
            
            # ä»AIä¿¡å·è·å–æ–°çš„æ­¢ç›ˆæ­¢æŸ
            stop_loss = ai_signal.get('stop_loss_price', 0)
            take_profit = ai_signal.get('take_profit_price', 0)
            
            if stop_loss and take_profit:
                # åŸºäºæ–°å¹³å‡ä»·é‡æ–°è®¾ç½®
                sl_ok, tp_ok = set_tpsl_orders_via_papi(
                    symbol=symbol,
                    side=side,
                    amount=total_amount,
                    stop_loss=stop_loss,
                    take_profit=take_profit,
                    verbose=True
                )
                if not (sl_ok or tp_ok):
                    print(f"  âš ï¸ æ­¢ç›ˆæ­¢æŸè®¾ç½®å¤±è´¥")
        except Exception as e:
            print(f"  âš ï¸ é‡è®¾æ­¢ç›ˆæ­¢æŸå¤±è´¥: {e}")
        
        # 7. æ›´æ–° position_contextsï¼ˆè®°å½•åŠ ä»“æ—¶é—´å’Œæ¬¡æ•°ï¼‰
        try:
            model_name = os.getenv("MODEL_NAME", "deepseek")
            context_file = Path("trading_data") / model_name / "position_contexts.json"
            
            if context_file.exists():
                with open(context_file, 'r', encoding='utf-8') as f:
                    contexts = json.load(f)
            else:
                contexts = {}
            
            if coin_name in contexts:
                contexts[coin_name]['last_add_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                contexts[coin_name]['add_count'] = contexts[coin_name].get('add_count', 0) + 1
                contexts[coin_name]['avg_entry_price'] = avg_price
                
                with open(context_file, 'w', encoding='utf-8') as f:
                    json.dump(contexts, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"  âš ï¸ æ›´æ–°position_contextså¤±è´¥: {e}")
        
        # 8. å‘é€Barké€šçŸ¥
        notional_value = total_amount * new_price
        send_bark_notification(
            f"[DeepSeek]{coin_name}åŠ ä»“âœ…",
            f"{side_cn}ä»“ åŠ ä»“{new_amount:.3f}ä¸ª @{new_price:.2f}\n"
            f"æ–°å¹³å‡ä»·: {avg_price:.2f}\n"
            f"æ€»ä»“ä½: {total_amount:.3f}ä¸ª ({notional_value:.2f}U)\n"
            f"ç†ç”±: {add_reason}+ä»·æ ¼ä¼˜{abs(price_improvement_pct):.1f}%+ä¿¡å·åˆ†{signal_score}"
        )
        
        # 9. åˆ·æ–°æŒä»“å¿«ç…§
        try:
            refreshed_positions, _ = get_all_positions()
            save_positions_snapshot(refreshed_positions, 0)
            print("  âœ“ æŒä»“å¿«ç…§å·²æ›´æ–°")
        except:
            pass
        
        return True
        
    except Exception as e:
        print(f"âŒ åŠ ä»“å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # å‘é€å¤±è´¥é€šçŸ¥
        send_bark_notification(
            f"[DeepSeek]{coin_name}åŠ ä»“å¤±è´¥âŒ",
            f"{side_cn}ä»“ åŠ ä»“{new_amount:.3f}ä¸ªå¤±è´¥\n"
            f"é”™è¯¯: {str(e)[:80]}"
        )
        return False


def check_add_position_conditions(symbol, existing_position, ai_signal, available_balance, current_price=0, total_assets=0):
    """
    æ£€æŸ¥æ˜¯å¦æ»¡è¶³åŠ ä»“æ¡ä»¶ï¼ˆV8.5.2æ–°å¢ï¼‰
    
    Args:
        symbol: äº¤æ˜“å¯¹
        existing_position: ç°æœ‰æŒä»“ä¿¡æ¯
        ai_signal: AIä¿¡å·ä¿¡æ¯
        available_balance: å¯ç”¨ä½™é¢
        current_price: å½“å‰å¸‚åœºä»·æ ¼
        total_assets: æ€»èµ„äº§
    
    Returns:
        (can_add: bool, reason: str, price_improvement_pct: float)
    """
    try:
        # 1. æ£€æŸ¥ç°æœ‰æŒä»“çŠ¶æ€ï¼ˆæµ®äºä¸è¶…è¿‡5%ï¼‰
        unrealized_pnl = existing_position.get('unrealized_pnl', 0)
        notional = abs(existing_position.get('notional', 0))
        if notional > 0:
            pnl_pct = unrealized_pnl / notional
            if pnl_pct < -0.05:
                return False, f"ç°æœ‰æŒä»“æµ®äº{pnl_pct*100:.1f}%>5%", 0
        
        # 2. æ£€æŸ¥ä¿¡å·è´¨é‡ï¼ˆéœ€è¦â‰¥åŸä¿¡å·90%ï¼‰
        new_score = ai_signal.get('signal_quality', 0) if ai_signal else 0
        
        # ä»position_contextsè¯»å–åŸå§‹ä¿¡å·è´¨é‡
        try:
            model_name = os.getenv("MODEL_NAME", "deepseek")
            context_file = Path("trading_data") / model_name / "position_contexts.json"
            old_score = 0
            if context_file.exists():
                with open(context_file, 'r', encoding='utf-8') as f:
                    contexts = json.load(f)
                    coin_name = symbol.split('/')[0]
                    if coin_name in contexts:
                        old_score = contexts[coin_name].get('signal_quality', 0)
            
            if old_score > 0 and new_score < old_score * 0.9:
                return False, f"ä¿¡å·è´¨é‡{new_score}<åŸä¿¡å·{old_score}çš„90%", 0
        except Exception as e:
            print(f"  âš ï¸ è¯»å–åŸå§‹ä¿¡å·è´¨é‡å¤±è´¥: {e}")
        
        # 3. æ£€æŸ¥ä»·æ ¼æ˜¯å¦æ›´ä¼˜ï¼ˆé‡‘å­—å¡”åŠ ä»“ï¼‰
        entry_price = existing_position.get('entry_price', 0)
        side = existing_position.get('side', '')
        
        if entry_price == 0 or current_price == 0:
            return False, "ä»·æ ¼æ•°æ®ç¼ºå¤±", 0
        
        # è®¡ç®—ä»·æ ¼æ”¹å–„
        if side == 'short':
            price_improvement_pct = ((current_price - entry_price) / entry_price) * 100
            if price_improvement_pct <= 0.5:  # ç©ºå•éœ€ä»·æ ¼è‡³å°‘é«˜0.5%
                return False, f"ç©ºå•åŠ ä»“éœ€ä»·æ ¼æ›´ä¼˜ï¼ˆå½“å‰{current_price:.2f}ä»…æ¯”å¼€ä»“ä»·{entry_price:.2f}é«˜{price_improvement_pct:.2f}%<0.5%ï¼‰", 0
        else:  # long
            price_improvement_pct = ((entry_price - current_price) / entry_price) * 100
            if price_improvement_pct <= 0.5:  # å¤šå•éœ€ä»·æ ¼è‡³å°‘ä½0.5%
                return False, f"å¤šå•åŠ ä»“éœ€ä»·æ ¼æ›´ä¼˜ï¼ˆå½“å‰{current_price:.2f}ä»…æ¯”å¼€ä»“ä»·{entry_price:.2f}ä½{price_improvement_pct:.2f}%<0.5%ï¼‰", 0
        
        # 4. æ£€æŸ¥åŠ ä»“åæ€»ä¿è¯é‡‘æ˜¯å¦è¶…è¿‡å•å¸ç§å¼€ä»“ä¸Šé™
        # è·å–æ–°ä»“ä½çš„ä¿è¯é‡‘
        new_position_margin = ai_signal.get('position_size_usd', 0) if ai_signal else 0
        new_leverage = ai_signal.get('leverage', 1) if ai_signal else 1
        
        # è®¡ç®—ç°æœ‰æŒä»“çš„ä¿è¯é‡‘ï¼ˆåä¹‰ä»·å€¼ / æ æ†ï¼‰
        existing_leverage = existing_position.get('leverage', 1)
        if existing_leverage <= 0:
            existing_leverage = 1
        existing_margin = notional / existing_leverage
        
        # ç´¯è®¡ä¿è¯é‡‘
        total_margin_after_add = existing_margin + new_position_margin
        
        # è®¡ç®—å•å¸ç§å…è®¸çš„æœ€å¤§ä¿è¯é‡‘ï¼ˆä¸å•æ¬¡å¼€ä»“é™åˆ¶ä¸€è‡´ï¼‰
        MIN_CASH_RESERVE_RATIO = 0.20  # ä¿ç•™20%ç°é‡‘å‚¨å¤‡
        max_single_position = available_balance - (total_assets * MIN_CASH_RESERVE_RATIO) if total_assets > 0 else available_balance * 0.8
        
        print(f"   [åŠ ä»“æ£€æŸ¥] ç°æœ‰ä¿è¯é‡‘: {existing_margin:.2f}U, æ–°å¢ä¿è¯é‡‘: {new_position_margin:.2f}U")
        print(f"   [åŠ ä»“æ£€æŸ¥] ç´¯è®¡ä¿è¯é‡‘: {total_margin_after_add:.2f}U, å•å¸ç§ä¸Šé™: {max_single_position:.2f}U")
        
        # é™åˆ¶ï¼šç´¯è®¡ä¿è¯é‡‘ä¸è¶…è¿‡å•å¸ç§å¼€ä»“ä¸Šé™
        if total_margin_after_add > max_single_position:
            return False, f"åŠ ä»“åæ€»ä¿è¯é‡‘{total_margin_after_add:.2f}U>å•å¸ç§ä¸Šé™{max_single_position:.2f}U", 0
        
        # 5. æ£€æŸ¥åŠ ä»“é¢‘ç‡ï¼ˆä»position_contextsè¯»å–æœ€ååŠ ä»“æ—¶é—´ï¼‰
        try:
            if context_file.exists():
                with open(context_file, 'r', encoding='utf-8') as f:
                    contexts = json.load(f)
                    coin_name = symbol.split('/')[0]
                    if coin_name in contexts:
                        last_add_time_str = contexts[coin_name].get('last_add_time', '')
                        if last_add_time_str:
                            last_add_time = datetime.strptime(last_add_time_str, "%Y-%m-%d %H:%M:%S")
                            time_since_last_add = (datetime.now() - last_add_time).total_seconds() / 60
                            if time_since_last_add < 60:  # 1å°æ—¶å†…ä¸å…è®¸é‡å¤åŠ ä»“
                                return False, f"è·ä¸Šæ¬¡åŠ ä»“ä»…{time_since_last_add:.0f}åˆ†é’Ÿ<60åˆ†é’Ÿ", 0
        except Exception as e:
            print(f"  âš ï¸ æ£€æŸ¥åŠ ä»“é¢‘ç‡å¤±è´¥: {e}")
        
        # æ‰€æœ‰æ¡ä»¶æ»¡è¶³
        return True, f"ä»·æ ¼ä¼˜{abs(price_improvement_pct):.1f}%+ä¿¡å·å¼º{new_score}åˆ†+ä»“ä½å¯æ§", price_improvement_pct
        
    except Exception as e:
        print(f"âš ï¸ åŠ ä»“æ¡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
        return False, f"æ£€æŸ¥å¤±è´¥: {str(e)[:50]}", 0


def check_single_direction_per_coin(symbol, operation, current_positions, ai_signal=None, available_balance=0, current_price=0, total_assets=0):
    """
    æ£€æŸ¥å•å¸ç§å•æ–¹å‘é™åˆ¶ï¼Œæ”¯æŒæ™ºèƒ½åŠ ä»“ï¼ˆV8.5.2æ›´æ–°ï¼‰
    
    è§„åˆ™ï¼š
    - å•ä¸ªå¸ç§åªèƒ½æŒæœ‰ä¸€ä¸ªæ–¹å‘çš„è®¢å•ï¼ˆåšå¤šæˆ–åšç©ºï¼‰
    - ä¸å…è®¸åŒä¸€å¸ç§åŒæ—¶åšå¤šå’Œåšç©ºï¼ˆå¯¹å†²ï¼‰
    - æ»¡è¶³æ¡ä»¶æ—¶å…è®¸åŠ ä»“åˆ°ç°æœ‰è®¢å•
    
    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·
        operation: æ“ä½œç±»å‹ï¼ˆOPEN_LONG/OPEN_SHORTï¼‰
        current_positions: å½“å‰æŒä»“åˆ—è¡¨
        ai_signal: AIä¿¡å·ä¿¡æ¯ï¼ˆç”¨äºåˆ¤æ–­åŠ ä»“æ¡ä»¶ï¼‰
        available_balance: å¯ç”¨ä½™é¢
        current_price: å½“å‰å¸‚åœºä»·æ ¼
        total_assets: æ€»èµ„äº§
    
    Returns:
        (allowed: bool, reason: str, should_add: bool, price_improvement: float)
    """
    try:
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¯¥å¸ç§çš„æŒä»“
        existing_positions = [p for p in current_positions if p.get("symbol") == symbol]
        
        if not existing_positions:
            return True, f"è¯¥å¸ç§æ— æŒä»“ï¼Œå¯ä»¥å¼€ä»“", False, 0
        
        # è·å–ç°æœ‰è®¢å•çš„æ–¹å‘
        existing_position = existing_positions[0]
        existing_side = existing_position.get("side", "").lower()
        
        # ç¡®å®šæ–°è®¢å•æ–¹å‘
        new_side = "long" if operation == "OPEN_LONG" else "short"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸åæ–¹å‘ï¼ˆå¯¹å†²ï¼‰
        if existing_side != new_side:
            return False, (
                f"è¯¥å¸ç§å·²æœ‰{existing_side}ä»“ä½ï¼Œä¸å…è®¸å¼€{new_side}ä»“ï¼ˆç¦æ­¢å¯¹å†²ï¼‰ã€‚"
                f"å»ºè®®ï¼šå…ˆå¹³ä»“ç°æœ‰è®¢å•å†å¼€åå‘å•"
            ), False, 0
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸åŒæ–¹å‘ - åˆ¤æ–­æ˜¯å¦å¯ä»¥åŠ ä»“
        if existing_side == new_side:
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³åŠ ä»“æ¡ä»¶
            can_add, add_reason, price_improvement = check_add_position_conditions(
                symbol, existing_position, ai_signal, available_balance, current_price, total_assets
            )
            
            if can_add:
                # æ»¡è¶³åŠ ä»“æ¡ä»¶
                return True, f"âœ…åŠ ä»“æ¡ä»¶: {add_reason}", True, price_improvement
            else:
                # ä¸æ»¡è¶³åŠ ä»“æ¡ä»¶ï¼Œæ‹’ç»
                position_notional = abs(existing_position.get("notional", 0))
                
                return False, (
                    f"è¯¥å¸ç§å·²æœ‰{existing_side}ä»“ä½ï¼ˆåä¹‰ä»·å€¼{position_notional:.2f}Uï¼‰ï¼Œ"
                        f"ä¸æ»¡è¶³åŠ ä»“æ¡ä»¶ï¼š{add_reason}"
                    ), False, 0
        
        return True, f"æ£€æŸ¥é€šè¿‡", False, 0
    
    except Exception as e:
        print(f"âš ï¸ å•æ–¹å‘æ£€æŸ¥å¤±è´¥: {e}")
        return True, "æ£€æŸ¥å¤±è´¥ï¼Œæ”¾è¡Œ", False, 0


def ai_optimize_parameters(trading_data_summary, learning_mode="full_optimization", sample_count=0):
    """è®©AIåˆ†æäº¤æ˜“æ•°æ®å¹¶æå‡ºå‚æ•°ä¼˜åŒ–å»ºè®®ï¼ˆæ”¯æŒä¸åŒå­¦ä¹ æ¨¡å¼ + å†å²ç»éªŒå¤ç”¨ï¼‰
    
    Args:
        trading_data_summary: äº¤æ˜“æ•°æ®æ‘˜è¦
        learning_mode: å­¦ä¹ æ¨¡å¼ (exploration/initial_learning/full_optimization)
        sample_count: å½“å‰æ ·æœ¬æ•°é‡
    """
    try:
        # ğŸ†• V7.6.3.2: åŠ è½½å†å²éªŒè¯ç»éªŒï¼ˆæ¯æ—¥å¤ç›˜è®°å½•ï¼‰
        validation_history = load_validation_history(max_records=10)
        
        # æ ¹æ®å­¦ä¹ æ¨¡å¼è°ƒæ•´æç¤ºè¯
        mode_instructions = {
            "exploration": f"""
## ğŸ” Current Mode: Exploration Mode (Samples: {sample_count}/5)

**Optimization Strategy**:
- Goal: Accumulate samples, build initial understanding
- Style: Moderately relax parameters, avoid over-strict preventing entries
- Adjustment Range: Gentle (Â±10-15% per change)
- Focus: Lower entry threshold, maintain small positions for risk control
- Forbidden: Don't over-tighten (min_risk_reward â‰¤1.5, min_indicator_consensus â‰¤4)
""",
            "initial_learning": f"""
## ğŸ“š Current Mode: Initial Learning Mode (Samples: {sample_count}/10)

**Optimization Strategy**:
- Goal: Find obvious issues from limited data
- Style: Targeted adjustments, avoid aggressive changes
- Adjustment Range: Moderate (Â±15-20% per change)
- Focus: Identify clear loss patterns (frequent stops, prolonged holds, etc.)
- Caution: Limited samples, avoid overfitting
""",
            "full_optimization": f"""
## ğŸ¯ Current Mode: Deep Optimization Mode (Samples: {sample_count} trades)

**Optimization Strategy**:
- Goal: Comprehensive analysis, fine-tuning
- Style: Data-driven, bold adjustments allowed
- Adjustment Range: Flexible based on severity (Â±20-30%)
- Focus: Deep dive into win rate, R:R, hold time root causes
- Allowed: Can set differentiated parameters per symbol
"""
        }
        
        mode_instruction = mode_instructions.get(learning_mode, mode_instructions["full_optimization"])
        
        # ğŸ†• V7.6.3.2: æ„å»ºå†å²ç»éªŒä¸Šä¸‹æ–‡
        if validation_history:
            experience_context = "## ğŸ“š HISTORICAL VALIDATION LESSONS (Recent Daily Reviews)\n\n"
            experience_context += "**Learn from previous parameter optimization attempts to avoid repeating mistakes:**\n\n"
            
            for i, lesson in enumerate(validation_history, 1):
                status = "âœ… EFFECTIVE" if lesson['was_effective'] else "âŒ INEFFECTIVE"
                applied = "âœ“ APPLIED" if lesson['should_apply'] else "âœ— REJECTED"
                
                experience_context += f"### Lesson {i} ({lesson['date'][:10]}) - {status} ({applied})\n"
                experience_context += f"**Attempted Adjustments**:\n{json.dumps(lesson['attempted_adjustments'], indent=2, ensure_ascii=False)}\n\n"
                
                if lesson['composite_improvement'] is not None:
                    experience_context += f"**Composite Profit Metric Change**: {lesson['composite_improvement']:+.1f}%\n"
                    experience_context += f"  (= Weighted Win Rate Ã— Weighted Profit Ratio Ã— Capture Rate)\n\n"
                
                experience_context += f"**Key Insight**: {lesson['key_insight'][:200]}...\n"
                
                if not lesson['was_effective']:
                    experience_context += f"**Root Cause**: {lesson['root_cause'][:200]}...\n"
                
                experience_context += f"**Final Decision**: {'Applied to production' if lesson['should_apply'] else 'Rejected'}\n\n"
                experience_context += "---\n\n"
        else:
            experience_context = "## ğŸ“š HISTORICAL VALIDATION LESSONS\n\nNo historical data available yet. This is the first optimization.\n\n"
        
        prompt = f"""**[IMPORTANT: Respond ONLY in Chinese (ä¸­æ–‡)]**

You are a professional quantitative trading parameter optimization expert. Analyze the following trading data comprehensively and propose actionable parameter adjustments.

ã€V8.5.2.4.43ã€‘ç§»åŠ¨æ­¢ç›ˆæ­¢æŸå†³ç­–æŒ‡å—ï¼š
- å½“å¸‚åœºæ³¢åŠ¨ç‡é«˜ã€è¶‹åŠ¿æ˜ç¡®æ—¶ï¼Œå»ºè®®å¯ç”¨ç§»åŠ¨æ­¢æŸï¼ˆtrailing_stop_enabled=trueï¼‰
- è¶…çŸ­çº¿äº¤æ˜“ï¼šé€‚åˆåœ¨å¿«é€Ÿçªç ´æ—¶ä½¿ç”¨ç§»åŠ¨æ­¢æŸï¼Œä¿æŠ¤çŸ­æœŸåˆ©æ¶¦
- æ³¢æ®µäº¤æ˜“ï¼šåœ¨å¼ºè¶‹åŠ¿ä¸­ä½¿ç”¨ç§»åŠ¨æ­¢æŸï¼Œè®©åˆ©æ¶¦å……åˆ†å¥”è·‘
- éœ‡è¡å¸‚åœºï¼šå»ºè®®ä½¿ç”¨é™æ€æ­¢æŸï¼ˆtrailing_stop_enabled=falseï¼‰ï¼Œé¿å…é¢‘ç¹è§¦å‘
- æ ¹æ®å†å²å›æµ‹æ•°æ®å’Œå½“å‰å¸‚åœºçŠ¶æ€ï¼Œè‡ªä¸»å†³å®šæ˜¯å¦å¯ç”¨ç§»åŠ¨æ­¢æŸ
- trailing_stop_enabledå‚æ•°å¯ä»¥åœ¨scalping_paramså’Œswing_paramsä¸­ç‹¬ç«‹è®¾ç½®

{experience_context}

{mode_instruction}

## TRADING DATA STATISTICS

{trading_data_summary}

## ADJUSTABLE PARAMETERS

1. **Risk Control**
- min_risk_reward: Minimum risk-reward ratio (current value shown above)
- atr_stop_multiplier: ATR stop-loss multiplier (current value shown above)
- max_loss_per_trade: Max loss per trade % (0.01-0.03)
- max_consecutive_losses: Max consecutive losses (2-5)

2. **Position Management**
- base_position_ratio: Base position ratio (0.10-0.30)
- high_signal_multiplier: High-quality signal multiplier (1.0-2.0)

3. **Entry Timing**
- min_indicator_consensus: Min indicators consensus (3-5)
- key_level_penalty: Key level penalty coefficient (0.5-1.0)
- min_trend_strength: Minimum trend strength (0.5-0.8)

4. **Exit Strategy**
- max_hold_time_hours: Max holding time hours (12-48)
- partial_take_profit: Partial profit taking (true/false)

## COMPREHENSIVE ANALYSIS REQUIREMENTS

### 1. **é—®é¢˜è¯Šæ–­ (Diagnosis)** - 3-4å¥
è¯†åˆ«æ ¸å¿ƒé—®é¢˜ï¼ŒåŒ…æ‹¬ï¼š
- èƒœç‡é—®é¢˜ï¼ˆå¦‚ï¼šä½äº50%ï¼‰
- ç›ˆäºæ¯”é—®é¢˜ï¼ˆå¦‚ï¼šä½äº1.5:1ï¼‰
- æ­¢æŸ/æ­¢ç›ˆè§¦å‘æ¨¡å¼ï¼ˆå¦‚ï¼šé¢‘ç¹æ­¢æŸã€æå‰æ­¢ç›ˆï¼‰
- ä¿¡å·è´¨é‡é—®é¢˜ï¼ˆå¦‚ï¼šé€†åŠ¿ã€å‡çªç ´ã€éœ‡è¡å¸‚ï¼‰

### 2. **æ ¹æœ¬åŸå›  (Root Cause)** - 4-5å¥
æ·±æŒ–å‚æ•°å±‚é¢çš„æ ¹å› ï¼š
- å“ªä¸ªå‚æ•°è®¾ç½®è¿‡æ¾/è¿‡ç´§
- å¯¼è‡´äº†ä»€ä¹ˆç±»å‹çš„é”™è¯¯äº¤æ˜“
- ä¸¾1-2ä¸ªå…·ä½“äº¤æ˜“æ¡ˆä¾‹è¯´æ˜ï¼ˆå¦‚ï¼š"XRPç©ºå•åœ¨éœ‡è¡å¸‚ä¸­è¢«1.7å€ATRæ­¢æŸé¢‘ç¹æ‰«æŸ"ï¼‰
- ä¸å½“å‰å¸‚åœºç¯å¢ƒçš„åŒ¹é…åº¦ï¼ˆå¦‚ï¼šå‚æ•°é€‚åˆè¶‹åŠ¿å¸‚ï¼Œä½†å½“å‰ä¸ºéœ‡è¡å¸‚ï¼‰

### 3. **å‚æ•°è°ƒæ•´å»ºè®® (Adjustments)** - æ˜ç¡®å¯¹æ¯”
å¯¹æ¯ä¸ªéœ€è¦è°ƒæ•´çš„å‚æ•°ï¼Œè¯´æ˜ï¼š
- **å½“å‰å€¼ â†’ å»ºè®®å€¼**ï¼ˆå¦‚ï¼šmin_risk_reward 1.5 â†’ 1.8ï¼‰
- **è°ƒæ•´ç†ç”±**ï¼ˆ1å¥è¯ï¼Œå¦‚ï¼š"é™ä½ç›ˆäºæ¯”é—¨æ§›ä»¥æé«˜å…¥åœºæœºä¼šï¼Œé…åˆæ›´ä¸¥æ ¼çš„ä¿¡å·è¿‡æ»¤"ï¼‰
- **å½±å“èŒƒå›´**ï¼ˆå¦‚ï¼š"å½±å“æ‰€æœ‰å¸ç§çš„å¼€ä»“å†³ç­–"ï¼‰

### 4. **é‡åŒ–é¢„æœŸæ•ˆæœ (Expected Effect)** - 5-6å¥ï¼Œå¿…é¡»åŒ…å«å…·ä½“æ•°å€¼
- **èƒœç‡é¢„æœŸ**ï¼š"ä»å½“å‰X%æå‡è‡³Y%ï¼ˆÂ±Z%ï¼‰"ï¼Œè¯´æ˜åŸå› 
- **ç›ˆäºæ¯”é¢„æœŸ**ï¼š"ä»å½“å‰A:1æ”¹å–„è‡³B:1"ï¼Œè¯´æ˜å¦‚ä½•å®ç°
- **æœºä¼šæ•è·ç‡**ï¼š"é¢„è®¡æå‡è‡³15-25%"ï¼ˆåŸºäºå†å²é”™è¿‡æœºä¼šåˆ†æï¼‰
- **å…·ä½“æ¡ˆä¾‹**ï¼š"å¦‚æ˜¨æ—¥é”™è¿‡çš„BTC 1245å¼ºä¿¡å·ï¼Œè°ƒæ•´åå¯æ•è·"
- **é£é™©æç¤º**ï¼š"å¯èƒ½å¢åŠ Xç±»å‹é£é™©ï¼Œéœ€ç›‘æ§YæŒ‡æ ‡"

### 5. **æ‰§è¡Œå»ºè®® (Action Required)**
- **æ˜¯å¦ç«‹å³è°ƒæ•´**ï¼šYES/NO/WAITï¼ˆè§‚å¯ŸæœŸï¼‰
- **ç†ç”±**ï¼š1-2å¥ï¼ˆå¦‚ï¼š"æ ·æœ¬é‡å……è¶³ä¸”é—®é¢˜æ˜ç¡®ï¼Œå»ºè®®ç«‹å³è°ƒæ•´" OR "æ ·æœ¬é‡ä¸è¶³ï¼Œå»ºè®®å†è§‚å¯Ÿ3å¤©"ï¼‰
- **ç›‘æ§é‡ç‚¹**ï¼šè°ƒæ•´ååº”é‡ç‚¹å…³æ³¨çš„æŒ‡æ ‡ï¼ˆå¦‚ï¼š"å…³æ³¨æ­¢æŸè§¦å‘ç‡æ˜¯å¦ä¸‹é™"ï¼‰

## OUTPUT FORMAT (Strict JSON with V2.0 Enhanced Fields)

```json
{{
  "diagnosis": "æ ¸å¿ƒé—®é¢˜è¯Šæ–­ï¼Œ3-4å¥è¯ï¼ŒåŒ…å«å…·ä½“æŒ‡æ ‡æ•°å€¼",
  "root_cause": "å‚æ•°å±‚é¢çš„æ ¹æœ¬åŸå› åˆ†æï¼Œ4-5å¥è¯ï¼Œå¿…é¡»ä¸¾1-2ä¸ªå…·ä½“äº¤æ˜“æ¡ˆä¾‹",
  "adjustments": {{
    "global": {{
      "min_risk_reward": 1.8,
      "atr_stop_multiplier": 1.5,
      "_rationale": {{
        "min_risk_reward": "å½“å‰1.5â†’å»ºè®®1.8ï¼ŒåŸå› ï¼šé™ä½é—¨æ§›ä»¥æé«˜æœºä¼šæ•è·ç‡ï¼Œé…åˆæ›´ä¸¥æ ¼çš„ä¿¡å·è¿‡æ»¤",
        "atr_stop_multiplier": "å½“å‰1.7â†’å»ºè®®1.5ï¼ŒåŸå› ï¼šéœ‡è¡å¸‚ä¸­1.7å€æ­¢æŸè¿‡å®½ï¼Œå¯¼è‡´å›æ’¤è¿‡å¤§"
      }}
    }},
    "per_symbol": {{
      "XRP/USDT:USDT": {{
        "min_indicator_consensus": 4,
        "_rationale": "XRPæ³¢åŠ¨ç‡é«˜ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„ä¿¡å·ç¡®è®¤ï¼ˆ3â†’4ï¼‰"
      }}
    }}
  }},
  "expected_effect": "é‡åŒ–é¢„æœŸæ•ˆæœï¼Œ5-6å¥è¯ï¼Œå¿…é¡»åŒ…å«ï¼š1)èƒœç‡ä»X%æå‡è‡³Y%ï¼Œ2)ç›ˆäºæ¯”ä»Aæ”¹å–„è‡³Bï¼Œ3)æœºä¼šæ•è·ç‡æå‡è‡³C%ï¼Œ4)å…·ä½“æ¡ˆä¾‹ï¼ˆå¦‚æ˜¨æ—¥é”™è¿‡çš„æŸä¿¡å·è°ƒæ•´åå¯æ•è·ï¼‰ï¼Œ5)é£é™©æç¤º",
  "expected_win_rate": "50-55%",
  "expected_profit_ratio": "1.5:1",
  "expected_capture_rate": "20%",
  "confidence": 0.75,
  "action_required": "YES",
  "action_reason": "æ ·æœ¬é‡å……è¶³ï¼ˆ20ç¬”ï¼‰ä¸”é—®é¢˜æ˜ç¡®ï¼Œå»ºè®®ç«‹å³è°ƒæ•´",
  "monitor_focus": "å…³æ³¨æ­¢æŸè§¦å‘ç‡ï¼ˆç›®æ ‡é™è‡³30%ä»¥ä¸‹ï¼‰å’Œæœºä¼šæ•è·ç‡"
}}
```

## CRITICAL RULES

1. **ğŸ“š Learn from History (ç»éªŒå¤ç”¨)**ï¼š
   - Review "HISTORICAL VALIDATION LESSONS" above carefully
   - If a similar adjustment FAILED recently (within 3 lessons): Explain why this time is different OR choose a different direction
   - If a similar adjustment SUCCEEDED: Build upon that success
   - Focus on **Composite Profit Metric** (åŠ æƒèƒœç‡ Ã— åŠ æƒç›ˆäºæ¯” Ã— æ•è·ç‡) when evaluating past lessons
   - Avoid repeating mistakes, learn from successful patterns

2. **é‡åŒ–ä¼˜å…ˆ**ï¼šæ‰€æœ‰é¢„æœŸæ•ˆæœå¿…é¡»æœ‰å…·ä½“æ•°å€¼ï¼Œé¿å…"é¢„è®¡æå‡"ã€"æœ‰æœ›æ”¹å–„"ç­‰æ¨¡ç³Šè¡¨è¿°

3. **æ¡ˆä¾‹æ”¯æ’‘**ï¼šæ ¹æœ¬åŸå› åˆ†æå¿…é¡»å¼•ç”¨å…·ä½“äº¤æ˜“æ¡ˆä¾‹ï¼ˆä»trading_data_summaryä¸­æå–ï¼‰

4. **å‚æ•°æº¯æº**ï¼šæ¯ä¸ªè°ƒæ•´å»ºè®®å¿…é¡»è¯´æ˜"å½“å‰å€¼â†’å»ºè®®å€¼"ï¼Œä¸èƒ½åªç»™æ–°å€¼

5. **ä¿å®ˆé¢„æµ‹**ï¼šé¢„æœŸæ•ˆæœç»™å‡ºåŒºé—´ï¼ˆå¦‚50-55%ï¼‰ï¼Œä¸è¦è¿‡åº¦ä¹è§‚

6. **æ‰§è¡Œæ˜ç¡®**ï¼šå¿…é¡»ç»™å‡ºYES/NO/WAITçš„æ˜ç¡®å»ºè®®ï¼Œä¸èƒ½å«ç³Š

7. **ä¸­æ–‡è¾“å‡º**ï¼šdiagnosisã€root_causeã€expected_effectç­‰å­—æ®µå†…å®¹å¿…é¡»ä¸ºä¸­æ–‡

8. **é€‚åº¦è°ƒæ•´**ï¼šå•æ¬¡å‚æ•°å˜åŒ–å¹…åº¦ä¸è¶…è¿‡30%ï¼Œé¿å…è¿‡åº¦éœ‡è¡
"""

        # è°ƒç”¨AIåˆ†æ
        response = deepseek_client.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {
                    "role": "system",
                    "content": "You are a professional quantitative trading parameter optimization expert, skilled in analyzing trading data and proposing optimization suggestions. **Always respond in Chinese (ä¸­æ–‡).**",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,  # è¾ƒä½æ¸©åº¦ç¡®ä¿è¾“å‡ºç¨³å®š
        )

        ai_response = response.choices[0].message.content.strip()
        print(f"\nã€AIåˆ†æç»“æœã€‘")
        print(ai_response)

        # è§£æJSON
        import re

        json_match = re.search(r"```json\s*(.*?)\s*```", ai_response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰markdownä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æ
            json_str = ai_response

        optimization = json.loads(json_str)

        return optimization

    except Exception as e:
        print(f"âš ï¸ AIå‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return None


def load_validation_history(max_records=10):
    """
    V7.6.3.2: åŠ è½½å†å²å‚æ•°éªŒè¯è®°å½•ï¼Œä½œä¸ºç»éªŒå¤ç”¨
    
    æ¯æ¬¡ã€æ¯æ—¥å¤ç›˜ã€‘éƒ½ä¼šäº§ç”Ÿä¸€æ¡éªŒè¯è®°å½•ï¼Œè¿™é‡Œè¯»å–æœ€è¿‘çš„Næ¡
    å¸®åŠ©AIé¿å…é‡å¤é”™è¯¯ï¼Œå­¦ä¹ æˆåŠŸç»éªŒ
    
    Args:
        max_records: æœ€å¤šè¯»å–å¤šå°‘æ¡å†å²è®°å½•ï¼ˆé»˜è®¤10æ¡ï¼‰
    
    Returns:
        [
            {
                'date': '2025-10-25 12:00:00',
                'attempted_adjustments': {...},
                'was_effective': True/False,
                'should_apply': True/False,
                'composite_improvement': +15.2%,
                'key_insight': 'AIçš„ç»éªŒæ€»ç»“',
                'root_cause': 'æœ‰æ•ˆ/æ— æ•ˆçš„åŸå› åˆ†æ'
            },
            ...
        ]
    """
    try:
        model_dir = os.getenv("MODEL_NAME", "deepseek")
        history_file = f"trading_data/{model_dir}/backtest_validation_history.jsonl"
        
        if not os.path.exists(history_file):
            return []
        
        lessons = []
        
        with open(history_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    record = json.loads(line)
                    
                    # æå–å…³é”®ç»éªŒ
                    ai_review = record.get('ai_review', {})
                    
                    # è®¡ç®—ç»¼åˆåˆ©æ¶¦æŒ‡æ ‡çš„æå‡ï¼ˆå¦‚æœæœ‰å›æµ‹æ•°æ®ï¼‰
                    backtest_orig = record.get('backtest_original', {})
                    backtest_opt = record.get('backtest_optimized', {})
                    
                    composite_improvement = None
                    if backtest_orig and backtest_opt:
                        orig_metric = backtest_orig.get('composite_profit_metric', 0)
                        opt_metric = backtest_opt.get('composite_profit_metric', 0)
                        if orig_metric > 0:
                            composite_improvement = ((opt_metric - orig_metric) / orig_metric) * 100
                    
                    lesson = {
                        'date': record.get('timestamp', 'Unknown'),
                        'attempted_adjustments': record.get('optimization', {}).get('adjustments', {}),
                        'was_effective': ai_review.get('is_effective', False),
                        'should_apply': ai_review.get('should_apply', False),
                        'composite_improvement': composite_improvement,
                        'key_insight': ai_review.get('improvement_summary', ''),
                        'root_cause': ai_review.get('root_cause_analysis', ''),
                        'applied_config': record.get('applied_config', {})
                    }
                    lessons.append(lesson)
                    
                except json.JSONDecodeError:
                    continue
        
        # è¿”å›æœ€è¿‘çš„max_recordsæ¡
        return lessons[-max_records:]
    
    except Exception as e:
        print(f"âš ï¸ åŠ è½½å†å²éªŒè¯è®°å½•å¤±è´¥: {e}")
        return []


def backtest_parameters(config_variant, days=7, verbose=False):
    """
    ã€V7.9å¢å¼ºã€‘å‚æ•°å›æµ‹å¼•æ“ï¼ˆè¿‘æœŸæ•°æ®åŠ æƒ + ç»¼åˆåˆ©æ¶¦æŒ‡æ ‡ï¼‰
    åŸºäºå†å²market_snapshotsæ•°æ®ï¼Œæ¨¡æ‹Ÿä¸åŒå‚æ•°é…ç½®ä¸‹çš„äº¤æ˜“ç»“æœ
    
    Args:
        config_variant: å‚æ•°é…ç½®å˜ä½“ï¼ˆå­—å…¸ï¼‰
        days: å›æµ‹å¤©æ•°ï¼ˆé»˜è®¤7å¤©é‡ç‚¹å›æµ‹ï¼Œæœ€é•¿14å¤©å…¨é¢å›æµ‹ï¼‰
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿—
    
    Returns:
        {
            'total_trades': æ€»äº¤æ˜“æ¬¡æ•°,
            'win_rate': èƒœç‡,
            'profit_ratio': ç›ˆäºæ¯”,
            'total_profit': æ€»ç›ˆåˆ©,
            'captured_opportunities': æ•è·çš„æœºä¼šæ•°,
            'missed_opportunities': é”™å¤±çš„æœºä¼šæ•°,
            'capture_rate': æ•è·ç‡,
            'trades': äº¤æ˜“è¯¦æƒ…åˆ—è¡¨,
            'weighted_win_rate': åŠ æƒèƒœç‡ï¼ˆè¿‘æœŸæƒé‡æ›´é«˜ï¼‰,
            'weighted_profit_ratio': åŠ æƒç›ˆäºæ¯”,
            'ç»¼åˆåˆ©æ¶¦æŒ‡æ ‡': åŠ æƒèƒœç‡ Ã— åŠ æƒç›ˆäºæ¯” Ã— æ•è·ç‡ï¼ˆæ ¸å¿ƒå†³ç­–ä¾æ®ï¼‰
        }
    """
    try:
        from datetime import datetime, timedelta
        import glob
        
        print(f"\n{'='*60}")
        print(f"ã€ğŸ“Š å‚æ•°å›æµ‹å¼•æ“ã€‘å›æµ‹æœ€è¿‘{days}å¤©æ•°æ®ï¼ˆè¿‘æœŸæƒé‡é€’å‡ï¼‰")
        print(f"{'='*60}")
        
        # è¯»å–å†å²å¿«ç…§æ•°æ®ï¼ˆè¿‘æœŸä¼˜å…ˆï¼‰
        model_dir = os.getenv("MODEL_NAME", "deepseek")
        snapshot_dir = f"trading_data/{model_dir}/market_snapshots"
        
        end_date = datetime.now()
        
        # ğŸ†• V7.6.3.1: æŒ‰æ—¥æœŸåˆ†ç»„å­˜å‚¨ï¼Œä¾¿äºåŠ æƒ
        daily_snapshots = {}
        total_records = 0
        
        for i in range(days):
            target_date = (end_date - timedelta(days=i)).strftime('%Y%m%d')
            snapshot_file = f"{snapshot_dir}/{target_date}.csv"
            
            try:
                df = pd.read_csv(snapshot_file)
                daily_snapshots[i] = df  # i=0æ˜¯ä»Šå¤©ï¼Œi=1æ˜¯æ˜¨å¤©...
                total_records += len(df)
                if verbose:
                    print(f"âœ“ è¯»å– {target_date}: {len(df)}æ¡è®°å½• (æƒé‡: {1.0 - i*0.1:.1f})")
            except FileNotFoundError:
                if verbose:
                    print(f"âœ— æœªæ‰¾åˆ° {target_date} æ•°æ®")
                continue
        
        if not daily_snapshots:
            print("âš ï¸ æœªæ‰¾åˆ°å†å²å¿«ç…§æ•°æ®")
            return None
        
        print(f"âœ“ å…±åŠ è½½ {total_records} æ¡å†å²è®°å½•ï¼ˆ{len(daily_snapshots)}å¤©ï¼‰")
        print(f"  æƒé‡ç­–ç•¥: ä»Šå¤©1.0 â†’ {days-1}å¤©å‰{1.0 - (days-1)*0.1:.1f}")
        print(f"  ğŸ’¾ å†…å­˜ä¼˜åŒ–: åˆ†æ‰¹å¤„ç† + åŠæ—¶é‡Šæ”¾")
        
        # ã€V7.8ä¿®å¤ã€‘ç¡®ä¿ config_variant åŒ…å« min_signal_score
        # ã€V8.5.2.3å‡çº§ã€‘åŠ è½½learning_configç”¨äºåŠ¨æ€è®¡ç®—signal_score
        learning_config = None
        if 'min_signal_score' not in config_variant:
            try:
                learning_config = load_learning_config()
                config_variant['min_signal_score'] = learning_config.get('global', {}).get('min_signal_score', 55)
            except:
                config_variant['min_signal_score'] = 55  # é»˜è®¤55åˆ†
        else:
            # å³ä½¿å·²æœ‰min_signal_scoreï¼Œä¹Ÿè¦åŠ è½½learning_configç”¨äºåŠ¨æ€è¯„åˆ†
            try:
                learning_config = load_learning_config()
            except:
                pass
        
        # æ¨¡æ‹Ÿäº¤æ˜“å†³ç­–ï¼ˆæŒ‰å¤©å¤„ç†ï¼Œä¾¿äºåŠ æƒï¼‰
        simulated_trades = []
        captured_opps = 0
        missed_opps = 0
        
        # è·å–å‚æ•°é…ç½®
        min_rr = config_variant.get('min_risk_reward', 1.5)
        min_consensus = config_variant.get('min_indicator_consensus', 3)
        atr_multiplier = config_variant.get('atr_stop_multiplier', 1.7)
        
        print(f"\nå›æµ‹å‚æ•°é…ç½®:")
        print(f"  min_risk_reward: {min_rr}")
        print(f"  min_indicator_consensus: {min_consensus}")
        print(f"  atr_stop_multiplier: {atr_multiplier}")
        
        # ã€V8.3.21ã€‘å¯¼å…¥gcç”¨äºå†…å­˜ç®¡ç†
        import gc
        
        # ğŸ†• V7.6.3.1: æŒ‰å¤©å›æµ‹ï¼Œæ¯å¤©åˆ†é…æƒé‡
        for day_offset, history_df in daily_snapshots.items():
            # è®¡ç®—å½“å¤©æƒé‡ï¼šä»Šå¤©1.0ï¼Œæ˜¨å¤©0.9ï¼Œå‰å¤©0.8...
            day_weight = max(0.3, 1.0 - day_offset * 0.1)  # æœ€ä½0.3æƒé‡
            
            # æŒ‰å¸ç§å’Œæ—¶é—´åˆ†ç»„
            for coin in history_df['coin'].unique():
                coin_data = history_df[history_df['coin'] == coin].sort_values('time')
                
                for idx, row in coin_data.iterrows():
                    # æ¨¡æ‹Ÿä¿¡å·è´¨é‡æ£€æŸ¥
                    indicator_consensus = row.get('indicator_consensus', 3)
                    
                    # ã€V8.5.2.3ã€‘åŠ¨æ€è®¡ç®—signal_scoreï¼ˆä¸å†ä¾èµ–CSVä¸­çš„å€¼ï¼‰
                    # å…ˆæ¨æ–­ä¿¡å·ç±»å‹ï¼ˆåŸºäºè¶‹åŠ¿å¼ºåº¦å’Œåˆ†æ•°ï¼‰
                    strong_trend = row.get('trend_4h') or row.get('trend_1h')
                    inferred_signal_type_for_score = 'swing' if strong_trend else 'scalping'
                    
                    # è°ƒç”¨recalculate_signal_score_from_snapshotåŠ¨æ€è®¡ç®—
                    signal_score = recalculate_signal_score_from_snapshot(row, inferred_signal_type_for_score, learning_config)
                    
                    # ğŸ†• V7.6.3.8: è¶…å®½æ¾æ ‡å‡† - åªè¦ä»·æ ¼æ³¢åŠ¨è¶…è¿‡1%å°±ç®—æ½œåœ¨æœºä¼š
                    # ç›®çš„ï¼šè®©AIçœ‹åˆ°æ‰€æœ‰å®é™…çš„å¸‚åœºæ³¢åŠ¨ï¼Œæ›´å‡†ç¡®åˆ¤æ–­å‚æ•°æ˜¯å¦è¿‡ä¸¥
                    
                    # è®¡ç®—æœªæ¥ä»·æ ¼æ³¢åŠ¨ï¼ˆå‘å‰çœ‹10æ ¹Kçº¿ï¼‰
                    future_data = coin_data[coin_data['time'] > row['time']].head(10)
                    has_price_movement = False
                    
                    if len(future_data) > 0:
                        current_price = row['price']
                        max_price = future_data['high'].max()
                        min_price = future_data['low'].min()
                        
                        # è®¡ç®—æœ€å¤§ä»·æ ¼æ³¢åŠ¨ç™¾åˆ†æ¯”
                        upward_move = (max_price - current_price) / current_price * 100
                        downward_move = (current_price - min_price) / current_price * 100
                        max_movement = max(upward_move, downward_move)
                        
                        # åªè¦ä»·æ ¼æ³¢åŠ¨è¶…è¿‡1%ï¼Œå°±ç®—ä¸€ä¸ªæ½œåœ¨æœºä¼š
                        has_price_movement = max_movement >= 1.0
                    
                    # åŒæ—¶æ£€æŸ¥åŸºæœ¬æœ‰æ•ˆæ€§ï¼ˆé¿å…æ•°æ®å¼‚å¸¸ï¼‰
                    is_valid_data = (
                        row.get('atr', 0) > 0 and           # ATRæœ‰æ•ˆ
                        row.get('price', 0) > 0 and         # ä»·æ ¼æœ‰æ•ˆ
                        indicator_consensus >= 1             # è‡³å°‘1ä¸ªæŒ‡æ ‡ï¼ˆé¿å…å®Œå…¨æ— æ•ˆæ•°æ®ï¼‰
                    )
                    
                    # æœ€ç»ˆåˆ¤æ–­ï¼šä»·æ ¼æœ‰æ³¢åŠ¨ + æ•°æ®æœ‰æ•ˆ
                    is_potential_opportunity = has_price_movement and is_valid_data
                    
                    if is_potential_opportunity:
                        # æ ¹æ®å›æµ‹å‚æ•°åˆ¤æ–­æ˜¯å¦ä¼šå¼€ä»“
                        # ğŸ”§ V7.8ä¿®å¤ï¼šä½¿ç”¨é…ç½®çš„ min_signal_scoreï¼Œç¡®ä¿ä¸æœºä¼šè¯„ä¼°æ ‡å‡†ä¸€è‡´
                        min_signal_score = config_variant.get('min_signal_score', 50)  # é»˜è®¤50ï¼Œå…¼å®¹æ—§ç‰ˆ
                        
                        # ğŸ”§ V7.8.1å…³é”®ä¿®å¤ï¼šå¿…é¡»æ£€æŸ¥risk_rewardï¼Œå¦åˆ™å›æµ‹ç»“æœä¸å®é™…è„±èŠ‚
                        snapshot_risk_reward = row.get('risk_reward', 0)
                        
                        would_open = (
                            indicator_consensus >= min_consensus and
                            signal_score >= min_signal_score and  # ä½¿ç”¨é…ç½®å‚æ•°ï¼Œä¸å†ç¡¬ç¼–ç 
                            snapshot_risk_reward >= min_rr and  # ã€å…³é”®ã€‘ç¡®ä¿å¿«ç…§ä¸­çš„ç›ˆäºæ¯”æ»¡è¶³è¦æ±‚
                            (
                                row.get('trend_4h', '') in ['å¤šå¤´', 'ç©ºå¤´'] or  # 4Hè¶‹åŠ¿
                                row.get('trend_1h', '') in ['å¤šå¤´', 'ç©ºå¤´'] or  # å…è®¸1Hè¶‹åŠ¿
                                row.get('trend_15m', '') in ['å¤šå¤´', 'ç©ºå¤´']    # å…è®¸15mè¶‹åŠ¿
                            )
                        )
                        
                        if would_open:
                            # æ¨¡æ‹Ÿäº¤æ˜“ç»“æœ
                            entry_price = row['price']
                            atr = row.get('atr', entry_price * 0.01)
                            
                            # æ­¢æŸæ­¢ç›ˆ
                            if row.get('trend_4h', '') == 'å¤šå¤´':
                                stop_loss = entry_price - atr * atr_multiplier
                                take_profit = entry_price + atr * min_rr * atr_multiplier
                                direction = 'LONG'
                            else:
                                stop_loss = entry_price + atr * atr_multiplier
                                take_profit = entry_price - atr * min_rr * atr_multiplier
                                direction = 'SHORT'
                            
                            # ã€V7.9ã€‘æ¨æ–­ä¿¡å·ç±»å‹ï¼ˆç”¨äºä¸»åŠ¨å¹³ä»“æ¨¡æ‹Ÿï¼‰
                            strong_trend = row.get('trend_4h') or row.get('trend_1h')
                            inferred_signal_type = 'swing' if (signal_score >= 75 or strong_trend) else 'scalping'
                            expected_holding_bars = 2 if inferred_signal_type == 'scalping' else 8  # 15åˆ†é’ŸKçº¿æ•°é‡
                            
                            # æ¨¡æ‹Ÿå¸‚åœºèµ°åŠ¿ï¼ˆã€V7.9ã€‘å¢åŠ ä¸»åŠ¨å¹³ä»“æ¨¡æ‹Ÿï¼‰
                            future_data = coin_data[coin_data['time'] > row['time']].head(12)  # å¤šè·å–2æ ¹Kçº¿ç”¨äºåˆ¤æ–­
                            
                            if len(future_data) > 0:
                                hit_tp = False
                                hit_sl = False
                                scratch_exit = False  # ä¸»åŠ¨å¹³ä»“æ ‡å¿—
                                exit_bar = 0  # é€€å‡ºçš„Kçº¿ä½ç½®
                                
                                for bar_idx, future_row in future_data.iterrows():
                                    holding_bars = (bar_idx - row.name) if isinstance(bar_idx, int) else len(future_data[:future_row.name])
                                    future_high = future_row['high']
                                    future_low = future_row['low']
                                    
                                    # ã€V7.9ã€‘ä¸»åŠ¨å¹³ä»“æ£€æŸ¥ï¼ˆåœ¨TP/SLæ£€æŸ¥ä¹‹å‰ï¼‰
                                    if not scratch_exit:
                                        if inferred_signal_type == 'scalping':
                                            # Scalping: æ•æ„Ÿæ£€æŸ¥
                                            # 1. è¶…æ—¶ï¼ˆ>2å°æ—¶=8æ ¹15åˆ†é’ŸKçº¿ï¼‰
                                            if holding_bars >= 8:
                                                scratch_exit = True
                                                exit_bar = holding_bars
                                                break
                                            
                                            # 2. è¶‹åŠ¿åè½¬ï¼ˆå¦‚æœæœ‰è¶‹åŠ¿æ•°æ®ï¼‰
                                            future_trend = future_row.get('trend_15m', '')
                                            if future_trend:
                                                if direction == 'LONG' and 'ç©ºå¤´' in future_trend:
                                                    scratch_exit = True
                                                    exit_bar = holding_bars
                                                    break
                                                elif direction == 'SHORT' and 'å¤šå¤´' in future_trend:
                                                    scratch_exit = True
                                                    exit_bar = holding_bars
                                                    break
                                        
                                        else:  # swing
                                            # Swing: åªæ£€æŸ¥å¤šå‘¨æœŸå…±æŒ¯åè½¬
                                            if holding_bars >= 8:  # 2å°æ—¶åæ‰æ£€æŸ¥
                                                future_trend_15m = future_row.get('trend_15m', '')
                                                future_trend_1h = future_row.get('trend_1h', '')
                                                
                                                # éœ€è¦15m+1hå…±æŒ¯åè½¬æ‰è§¦å‘
                                                if direction == 'LONG':
                                                    if 'ç©ºå¤´' in future_trend_15m and 'ç©ºå¤´' in future_trend_1h:
                                                        scratch_exit = True
                                                        exit_bar = holding_bars
                                                        break
                                                elif direction == 'SHORT':
                                                    if 'å¤šå¤´' in future_trend_15m and 'å¤šå¤´' in future_trend_1h:
                                                        scratch_exit = True
                                                        exit_bar = holding_bars
                                                        break
                                            
                                            # Swingè¶…æ—¶ï¼ˆ24å°æ—¶=96æ ¹Kçº¿ï¼Œä½†æˆ‘ä»¬åªå–12æ ¹ï¼Œæ‰€ä»¥ä¸ä¼šè§¦å‘ï¼‰
                                            if holding_bars >= 12:
                                                scratch_exit = True
                                                exit_bar = holding_bars
                                                break
                                    
                                    # æ£€æŸ¥TP/SL
                                    if direction == 'LONG':
                                        if future_high >= take_profit:
                                            hit_tp = True
                                            exit_bar = holding_bars
                                            break
                                        elif future_low <= stop_loss:
                                            hit_sl = True
                                            exit_bar = holding_bars
                                            break
                                    else:
                                        if future_low <= take_profit:
                                            hit_tp = True
                                            exit_bar = holding_bars
                                            break
                                        elif future_high >= stop_loss:
                                            hit_sl = True
                                            exit_bar = holding_bars
                                            break
                                
                                # ã€V7.9ã€‘è®°å½•äº¤æ˜“ç»“æœï¼ˆå¢åŠ ä¿¡å·ç±»å‹å’Œä¸»åŠ¨å¹³ä»“ï¼‰
                                if scratch_exit:
                                    # ä¸»åŠ¨å¹³ä»“ï¼šç”¨å½“å‰ä»·æ ¼è®¡ç®—ç›ˆäº
                                    exit_price = future_data.iloc[min(exit_bar, len(future_data)-1)]['close']
                                    profit_pct = ((exit_price - entry_price) / entry_price) * 100
                                    if direction == 'SHORT':
                                        profit_pct = -profit_pct
                                    
                                    simulated_trades.append({
                                        'coin': coin,
                                        'direction': direction,
                                        'entry_price': entry_price,
                                        'exit_price': exit_price,
                                        'profit_pct': profit_pct,
                                        'result': 'WIN' if profit_pct > 0 else 'LOSS',
                                        'exit_reason': 'SCRATCH',  # ä¸»åŠ¨å¹³ä»“
                                        'signal_type': inferred_signal_type,  # V7.9
                                        'holding_bars': exit_bar,  # V7.9
                                        'weight': day_weight
                                    })
                                elif hit_tp:
                                    profit = abs(take_profit - entry_price) / entry_price
                                    simulated_trades.append({
                                        'coin': coin,
                                        'direction': direction,
                                        'entry_price': entry_price,
                                        'exit_price': take_profit,
                                        'profit_pct': profit * 100,
                                        'result': 'WIN',
                                        'exit_reason': 'TP',
                                        'signal_type': inferred_signal_type,  # V7.9
                                        'holding_bars': exit_bar,  # V7.9
                                        'weight': day_weight
                                    })
                                elif hit_sl:
                                    loss = abs(entry_price - stop_loss) / entry_price
                                    simulated_trades.append({
                                        'coin': coin,
                                        'direction': direction,
                                        'entry_price': entry_price,
                                        'exit_price': stop_loss,
                                        'profit_pct': -loss * 100,
                                        'result': 'LOSS',
                                        'exit_reason': 'SL',
                                        'signal_type': inferred_signal_type,  # V7.9
                                        'holding_bars': exit_bar,  # V7.9
                                        'weight': day_weight
                                    })
                                else:
                                    # æœªè§¦å‘æ­¢æŸæ­¢ç›ˆï¼ŒæŒ‰æœ€åä»·æ ¼è®¡ç®—
                                    last_price = future_data.iloc[-1]['close']
                                    profit_pct = ((last_price - entry_price) / entry_price) * 100
                                    if direction == 'SHORT':
                                        profit_pct = -profit_pct
                                    
                                    simulated_trades.append({
                                        'coin': coin,
                                        'direction': direction,
                                        'entry_price': entry_price,
                                        'exit_price': last_price,
                                        'profit_pct': profit_pct,
                                        'result': 'WIN' if profit_pct > 0 else 'LOSS',
                                        'exit_reason': 'HOLD',
                                        'signal_type': inferred_signal_type,  # V7.9
                                        'holding_bars': len(future_data),  # V7.9
                                        'weight': day_weight
                                    })
                            
                            captured_opps += 1
                        else:
                            missed_opps += 1
            
            # ã€V8.3.21ã€‘å¤„ç†å®Œæ¯å¤©çš„æ•°æ®åé‡Šæ”¾å†…å­˜
            del history_df
            gc.collect()
        
        # ã€V8.3.21ã€‘å›æµ‹å®Œæˆï¼Œé‡Šæ”¾daily_snapshots
        del daily_snapshots
        gc.collect()
        
        # ã€V7.9ã€‘è®¡ç®—å›æµ‹ç»Ÿè®¡ï¼ˆå¢åŠ åˆ†ç±»å‹ç»Ÿè®¡ï¼‰
        if simulated_trades:
            wins = [t for t in simulated_trades if t['result'] == 'WIN']
            losses = [t for t in simulated_trades if t['result'] == 'LOSS']
            
            # ã€V7.9ã€‘åˆ†ç±»å‹ç»Ÿè®¡
            scalping_trades = [t for t in simulated_trades if t.get('signal_type') == 'scalping']
            swing_trades = [t for t in simulated_trades if t.get('signal_type') == 'swing']
            
            scalping_wins = [t for t in scalping_trades if t['result'] == 'WIN']
            swing_wins = [t for t in swing_trades if t['result'] == 'WIN']
            
            scalping_win_rate = len(scalping_wins) / len(scalping_trades) if scalping_trades else 0
            swing_win_rate = len(swing_wins) / len(swing_trades) if swing_trades else 0
            
            # å¹³å‡æŒä»“æ—¶é—´ï¼ˆ15åˆ†é’ŸKçº¿æ•°ï¼‰
            avg_holding_scalping = np.mean([t.get('holding_bars', 0) for t in scalping_trades]) if scalping_trades else 0
            avg_holding_swing = np.mean([t.get('holding_bars', 0) for t in swing_trades]) if swing_trades else 0
            
            # æ™®é€šèƒœç‡
            win_rate = len(wins) / len(simulated_trades)
            
            # ğŸ†• åŠ æƒèƒœç‡ï¼ˆè¿‘æœŸæ•°æ®æƒé‡æ›´é«˜ï¼‰
            total_weight = sum([t['weight'] for t in simulated_trades])
            weighted_wins = sum([t['weight'] for t in wins])
            weighted_win_rate = weighted_wins / total_weight if total_weight > 0 else 0
            
            # ğŸ†• åŠ æƒç›ˆäºæ¯”
            weighted_avg_win = sum([t['profit_pct'] * t['weight'] for t in wins]) / weighted_wins if weighted_wins > 0 else 0
            weighted_losses_sum = sum([t['weight'] for t in losses])
            weighted_avg_loss = abs(sum([t['profit_pct'] * t['weight'] for t in losses]) / weighted_losses_sum) if weighted_losses_sum > 0 else 0
            weighted_profit_ratio = weighted_avg_win / weighted_avg_loss if weighted_avg_loss > 0 else 0
            
            # æ™®é€šæŒ‡æ ‡
            avg_win = np.mean([t['profit_pct'] for t in wins]) if wins else 0
            avg_loss = abs(np.mean([t['profit_pct'] for t in losses])) if losses else 0
            profit_ratio = avg_win / avg_loss if avg_loss > 0 else 0
            total_profit = sum([t['profit_pct'] for t in simulated_trades])
            
            capture_rate = captured_opps / (captured_opps + missed_opps) if (captured_opps + missed_opps) > 0 else 0
            
            # ğŸ†• V7.6.3.2: ç»¼åˆåˆ©æ¶¦æŒ‡æ ‡ï¼ˆæ ¸å¿ƒå†³ç­–ä¾æ®ï¼‰
            # å…¬å¼ï¼šåŠ æƒèƒœç‡ Ã— åŠ æƒç›ˆäºæ¯” Ã— æ•è·ç‡
            # è¿™ä¸ªæŒ‡æ ‡å¹³è¡¡äº†ä¸‰ä¸ªç»´åº¦ï¼š
            # - èƒœç‡ï¼šäº¤æ˜“è´¨é‡
            # - ç›ˆäºæ¯”ï¼šç›ˆåˆ©æ•ˆç‡
            # - æ•è·ç‡ï¼šæœºä¼šæŠŠæ¡
            composite_profit_metric = weighted_win_rate * weighted_profit_ratio * capture_rate
            
            # ğŸ†• V7.6.5: ç›ˆåˆ©åˆ¤æ–­ - æœŸæœ›æ”¶ç›Šå’Œç›ˆäºå¹³è¡¡ç‚¹
            # æœŸæœ›æ”¶ç›Š = èƒœç‡ Ã— å¹³å‡ç›ˆåˆ© - (1 - èƒœç‡) Ã— å¹³å‡äºæŸ
            expected_return = weighted_win_rate * weighted_avg_win - (1 - weighted_win_rate) * weighted_avg_loss
            
            # ç›ˆäºå¹³è¡¡ç‚¹ï¼šåœ¨å½“å‰èƒœç‡ä¸‹ï¼Œéœ€è¦å¤šå°‘ç›ˆäºæ¯”æ‰èƒ½ç›ˆåˆ©
            # å…¬å¼ï¼šbreakeven_ratio = (1 - win_rate) / win_rate
            breakeven_profit_ratio = (1 - weighted_win_rate) / weighted_win_rate if weighted_win_rate > 0 else 999
            
            # åˆ¤æ–­æ˜¯å¦ç›ˆåˆ©ï¼ˆä¸¤ä¸ªæ¡ä»¶éƒ½è¦æ»¡è¶³ï¼‰
            is_profitable = (total_profit > 0) and (expected_return > 0)
            
            result = {
                'total_trades': len(simulated_trades),
                'win_rate': win_rate,
                'weighted_win_rate': weighted_win_rate,  # ğŸ†• åŠ æƒèƒœç‡
                'profit_ratio': profit_ratio,
                'weighted_profit_ratio': weighted_profit_ratio,  # ğŸ†• åŠ æƒç›ˆäºæ¯”
                'total_profit': total_profit,
                'captured_opportunities': captured_opps,
                'missed_opportunities': missed_opps,
                'capture_rate': capture_rate,
                'composite_profit_metric': composite_profit_metric,  # ğŸ†• ç»¼åˆåˆ©æ¶¦æŒ‡æ ‡
                'trades': simulated_trades,
                'avg_win': avg_win,
                'avg_loss': avg_loss,
                # ğŸ†• V7.6.5: ç›ˆåˆ©åˆ¤æ–­å­—æ®µ
                'expected_return': expected_return,  # ç†è®ºæœŸæœ›æ”¶ç›Šï¼ˆæ¯ç¬”äº¤æ˜“ï¼‰
                'breakeven_profit_ratio': breakeven_profit_ratio,  # ç›ˆäºå¹³è¡¡ç‚¹
                'is_profitable': is_profitable,  # æ˜¯å¦ç›ˆåˆ©
                
                # ã€V7.9ã€‘åˆ†ç±»å‹ç»Ÿè®¡
                'scalping_trades': len(scalping_trades),
                'swing_trades': len(swing_trades),
                'scalping_win_rate': scalping_win_rate,
                'swing_win_rate': swing_win_rate,
                'avg_holding_scalping_bars': avg_holding_scalping,
                'avg_holding_swing_bars': avg_holding_swing,
            }
            
            print(f"\nã€ğŸ“Š å›æµ‹ç»“æœã€‘")
            print(f"  æ€»äº¤æ˜“: {len(simulated_trades)}ç¬”")
            print(f"  èƒœç‡: {win_rate*100:.1f}% ({len(wins)}èƒœ/{len(losses)}è´Ÿ)")
            print(f"  ğŸ†• åŠ æƒèƒœç‡: {weighted_win_rate*100:.1f}% (è¿‘æœŸæƒé‡æ›´é«˜)")
            print(f"  ç›ˆäºæ¯”: {profit_ratio:.2f}:1")
            print(f"  ğŸ†• åŠ æƒç›ˆäºæ¯”: {weighted_profit_ratio:.2f}:1")
            print(f"  æ€»ç›ˆåˆ©: {total_profit:.2f}%")
            print(f"  æœºä¼šæ•è·: {captured_opps}ä¸ª / é”™å¤±: {missed_opps}ä¸ª")
            print(f"  æ•è·ç‡: {capture_rate*100:.1f}%")
            print(f"\n  ğŸ¯ ã€ç»¼åˆåˆ©æ¶¦æŒ‡æ ‡ã€‘: {composite_profit_metric:.4f}")
            print(f"     = åŠ æƒèƒœç‡({weighted_win_rate:.2f}) Ã— åŠ æƒç›ˆäºæ¯”({weighted_profit_ratio:.2f}) Ã— æ•è·ç‡({capture_rate:.2f})")
            print(f"     â†’ æ ¸å¿ƒå†³ç­–ä¾æ®ï¼šåœ¨èƒœç‡ã€ç›ˆäºæ¯”ã€æ•è·ç‡ä¹‹é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡")
            
            return result
        else:
            # ğŸ†• V7.6.3.4: å³ä½¿æ— äº¤æ˜“ï¼Œä¹Ÿè¿”å›æœ‰ä»·å€¼çš„åé¦ˆä¿¡æ¯
            print("âš ï¸ æœªæ¨¡æ‹Ÿåˆ°ä»»ä½•äº¤æ˜“")
            print(f"   ğŸ“Š æ€»å¿«ç…§æ•°: {total_records}")  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ total_records è€Œé all_snapshots
            print(f"   ğŸ¯ æ½œåœ¨æœºä¼š: {captured_opps + missed_opps}ä¸ª")
            print(f"   âŒ å…¨éƒ¨è¢«å‚æ•°è¿‡æ»¤ï¼ˆå‚æ•°å¯èƒ½è¿‡äºä¸¥æ ¼ï¼‰")
            
            # è¿”å›è¯¦ç»†çš„å¤±è´¥åŸå› ï¼Œè€Œä¸æ˜¯None
            return {
                'total_trades': 0,
                'win_rate': 0,
                'weighted_win_rate': 0,
                'profit_ratio': 0,
                'weighted_profit_ratio': 0,
                'total_profit': 0,
                'captured_opportunities': 0,
                'missed_opportunities': missed_opps,
                'capture_rate': 0,  # 0% æ•è·ç‡
                'composite_profit_metric': 0,
                'trades': [],
                'failure_reason': 'NO_TRADES',  # ğŸ†• å¤±è´¥åŸå› 
                'total_snapshots': total_records,  # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ total_records
                'potential_opportunities': captured_opps + missed_opps,  # ğŸ†• æ½œåœ¨æœºä¼šæ•°
                'filter_strictness': 'TOO_STRICT' if (captured_opps + missed_opps) > 0 else 'NO_OPPORTUNITIES'  # ğŸ†• ä¸¥æ ¼ç¨‹åº¦åˆ¤æ–­
                    }
            
    except Exception as e:
        print(f"âš ï¸ å›æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def ai_review_backtest_result(original_stats, backtest_original, backtest_optimized, optimization):
    """
    V7.6.3.2: AIå¤ç›˜å›æµ‹ç»“æœï¼ˆæ ¸å¿ƒä¾æ®ï¼šç»¼åˆåˆ©æ¶¦æŒ‡æ ‡ï¼‰
    å°†å›æµ‹å¯¹æ¯”ç»“æœåé¦ˆç»™AIï¼Œè®©AIåˆ¤æ–­å‚æ•°è°ƒæ•´æ˜¯å¦çœŸçš„æœ‰æ•ˆ
    
    å†³ç­–åŸåˆ™ï¼š
    - æ ¸å¿ƒåˆ¤æ–­ä¾æ®ï¼šç»¼åˆåˆ©æ¶¦æŒ‡æ ‡ (åŠ æƒèƒœç‡ Ã— åŠ æƒç›ˆäºæ¯” Ã— æ•è·ç‡)
    - ç›®æ ‡ï¼šåœ¨èƒœç‡ã€ç›ˆäºæ¯”ã€æ•è·ç‡ä¹‹é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡ï¼Œæœ€å¤§åŒ–æ•´ä½“åˆ©æ¶¦
    
    Args:
        original_stats: åŸå§‹äº¤æ˜“ç»Ÿè®¡
        backtest_original: åŸå‚æ•°å›æµ‹ç»“æœ
        backtest_optimized: ä¼˜åŒ–å‚æ•°å›æµ‹ç»“æœ
        optimization: åŸå§‹ä¼˜åŒ–å»ºè®®
    
    Returns:
        {
            'is_effective': True/False,
            'improvement_summary': æ”¹å–„æ€»ç»“,
            'final_recommendation': æœ€ç»ˆå»ºè®®,
            'confidence': ç½®ä¿¡åº¦,
            'should_apply': æ˜¯å¦åº”è¯¥åº”ç”¨ï¼ˆåŸºäºç»¼åˆåˆ©æ¶¦æŒ‡æ ‡ï¼‰
        }
    """
    try:
        print(f"\n{'='*60}")
        print(f"ã€ğŸ¤– AIå¤ç›˜å›æµ‹ç»“æœã€‘")
        print(f"{'='*60}")
        
        # ğŸ†• æå–åŠ æƒæŒ‡æ ‡å’Œç»¼åˆåˆ©æ¶¦æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
        original_weighted_wr = backtest_original.get('weighted_win_rate', backtest_original.get('win_rate', 0)) if backtest_original else 0
        original_weighted_pr = backtest_original.get('weighted_profit_ratio', backtest_original.get('profit_ratio', 0)) if backtest_original else 0
        original_composite = backtest_original.get('composite_profit_metric', 0) if backtest_original else 0
        
        optimized_weighted_wr = backtest_optimized.get('weighted_win_rate', backtest_optimized.get('win_rate', 0)) if backtest_optimized else 0
        optimized_weighted_pr = backtest_optimized.get('weighted_profit_ratio', backtest_optimized.get('profit_ratio', 0)) if backtest_optimized else 0
        optimized_composite = backtest_optimized.get('composite_profit_metric', 0) if backtest_optimized else 0
        
        # è®¡ç®—ç»¼åˆåˆ©æ¶¦æŒ‡æ ‡çš„æå‡å¹…åº¦
        composite_improvement = 0
        if original_composite > 0:
            composite_improvement = ((optimized_composite - original_composite) / original_composite) * 100
        
        prompt = f"""**[CRITICAL INSTRUCTION: ALL RESPONSES MUST BE IN CHINESE (ä¸­æ–‡)]**

You are a quantitative trading parameter optimization validation expert. Your task is to OBJECTIVELY evaluate the effectiveness of a previously proposed parameter adjustment using EMPIRICAL BACKTEST DATA.

**CORE EVALUATION METRIC**: 
ğŸ¯ **Composite Profit Metric** = Weighted Win Rate Ã— Weighted Profit Ratio Ã— Capture Rate

This metric balances three dimensions:
- Win Rate (äº¤æ˜“è´¨é‡): How often we win
- Profit Ratio (ç›ˆåˆ©æ•ˆç‡): How much we win vs. lose  
- Capture Rate (æœºä¼šæŠŠæ¡): How many opportunities we seize

**Your primary goal is to maximize this composite metric, not individual components alone.**

## CONTEXT: Original Optimization Proposal

**Diagnosed Issue**: {optimization.get('diagnosis', 'N/A')}
**Root Cause Analysis**: {optimization.get('root_cause', 'N/A')}
**Expected Improvement**: {optimization.get('expected_effect', 'N/A')}

**Proposed Parameter Adjustments**:
{json.dumps(optimization.get('adjustments', dict()), indent=2, ensure_ascii=False)}

## EMPIRICAL EVIDENCE: Backtest Performance Comparison

### Baseline: Live Trading Performance (Actual)
- Win Rate: {original_stats.get('win_rate', 0)*100:.1f}%
- Profit Ratio (R:R): {original_stats.get('profit_ratio', 0):.2f}:1
- Total P&L: {original_stats.get('total_profit', 0):.2f}U

### Control Group: Original Parameters (7-Day Historical Backtest)
{f"- Win Rate: {backtest_original['win_rate']*100:.1f}%" if backtest_original else "- Backtest Failed"}
    {f"- Weighted Win Rate (Recent-Biased): {original_weighted_wr*100:.1f}%" if backtest_original else ""}
{f"- Profit Ratio: {backtest_original['profit_ratio']:.2f}:1" if backtest_original else ""}
    {f"- Weighted Profit Ratio: {original_weighted_pr:.2f}:1" if backtest_original else ""}
{f"- Opportunity Capture Rate: {backtest_original['capture_rate']*100:.1f}%" if backtest_original else ""}
    {f"- ğŸ¯ **Composite Profit Metric**: {original_composite:.4f}" if backtest_original else ""}
{f"     (= {original_weighted_wr:.2f} Ã— {original_weighted_pr:.2f} Ã— {backtest_original['capture_rate']:.2f})" if backtest_original else ""}
    {f"- Total P&L: {backtest_original['total_profit']:.2f}%" if backtest_original else ""}

### Treatment Group: Optimized Parameters (7-Day Historical Backtest)
{f"- Win Rate: {backtest_optimized['win_rate']*100:.1f}%" if backtest_optimized else "- Backtest Failed"}
    {f"- Weighted Win Rate (Recent-Biased): {optimized_weighted_wr*100:.1f}%" if backtest_optimized else ""}
{f"- Profit Ratio: {backtest_optimized['profit_ratio']:.2f}:1" if backtest_optimized else ""}
    {f"- Weighted Profit Ratio: {optimized_weighted_pr:.2f}:1" if backtest_optimized else ""}
{f"- Opportunity Capture Rate: {backtest_optimized['capture_rate']*100:.1f}%" if backtest_optimized else ""}
    {f"- ğŸ¯ **Composite Profit Metric**: {optimized_composite:.4f}" if backtest_optimized else ""}
{f"     (= {optimized_weighted_wr:.2f} Ã— {optimized_weighted_pr:.2f} Ã— {backtest_optimized['capture_rate']:.2f})" if backtest_optimized else ""}
    {f"- Total P&L: {backtest_optimized['total_profit']:.2f}%" if backtest_optimized else ""}

### ğŸ¯ **CORE DECISION INDICATOR**
{f"**Composite Profit Metric Change**: {composite_improvement:+.1f}%" if backtest_original and backtest_optimized else "- Unable to calculate"}
    {f"  - Original: {original_composite:.4f}" if backtest_original else ""}
{f"  - Optimized: {optimized_composite:.4f}" if backtest_optimized else ""}
    {f"  - {'âœ… IMPROVED' if composite_improvement > 0 else 'âŒ DEGRADED'}" if backtest_original and backtest_optimized else ""}

**NOTE**: 
- Weighted metrics emphasize recent data (Day 0: 1.0x â†’ Day 6: 0.4x weight) to reflect current market conditions
- Composite Profit Metric is the PRIMARY decision criterion (æ ¸å¿ƒå†³ç­–ä¾æ®)

## ANALYTICAL REQUIREMENTS

### 1. Effectiveness Validation (3-4 sentences in Chinese)
   - Does the backtest performance align with the expected improvement?
   - Which KPIs improved? Which degraded?
   - Is the magnitude of improvement statistically significant (â‰¥10% improvement threshold)?

### 2. Root Cause Analysis (3-4 sentences in Chinese)
   - If results underperform expectations: Was the parameter direction incorrect, or the magnitude insufficient?
   - Identify discrepancies between backtest environment vs. live trading conditions
   - Assess whether 7-day sample size provides sufficient statistical power

### 3. Final Recommendation (2-3 sentences in Chinese)
   - Binary decision: Should these parameter adjustments be deployed to production?
   - If YES: Provide specific implementation plan
   - If NO: Suggest alternative parameter tuning directions

## OUTPUT FORMAT (Strict JSON, All Text Fields in Chinese)

```json
{{
  "is_effective": true/false,
  "improvement_summary": "[ä¸­æ–‡] Quantitative comparison summary (3-4 sentences, must include specific numeric deltas)",
  "root_cause_analysis": "[ä¸­æ–‡] If underperforming, root cause analysis (3-4 sentences with trade examples)",
      "final_recommendation": "[ä¸­æ–‡] Final binary decision with implementation plan (2-3 sentences)",
  "revised_adjustments": {{
    "global": {{
      "min_risk_reward": 1.6,
      "_comment": "If revision needed, provide refined parameters; if not, return empty object"
          }}
  }},
  "confidence": 0.85,
  "should_apply": true/false,
  "next_steps": "[ä¸­æ–‡] Actionable next steps"
}}
```

## CRITICAL DECISION FRAMEWORK

1. **ğŸ¯ Primary Decision Criterion (æ ¸å¿ƒåˆ¤æ–­ä¾æ®)**:
   - **Composite Profit Metric** (ç»¼åˆåˆ©æ¶¦æŒ‡æ ‡) is the ULTIMATE goal
   - Formula: Weighted Win Rate Ã— Weighted Profit Ratio Ã— Capture Rate
   - This metric balances win rate, profit efficiency, and opportunity capture
   - A parameter change is valuable ONLY if it improves this composite metric

2. **Deployment Decision Logic** (`should_apply`):
   - âœ… `should_apply = true` IF: **Composite Profit Metric improves â‰¥10%**
   - âš ï¸ `should_apply = true` (with caution) IF:
       * Composite Profit Metric improves 5-10% AND no single dimension degrades >15%
  - âŒ `should_apply = false` OTHERWISE
   
3. **Balanced Trade-offs**:
   - If win rate â†‘ but capture rate â†“â†“ â†’ Check if composite metric improves overall
   - If capture rate â†‘ but win rate â†“ â†’ Check if the trade-off is worthwhile
   - Avoid tunnel vision on individual metrics; always evaluate the composite

4. **Data-Driven Priority**: Backtest empirical evidence overrides theoretical predictions

5. **Conservative Threshold**: 
   - 7-day backtest = limited sample size
   - Require â‰¥10% composite improvement for confident deployment
   - Flag high variance or insufficient data

6. **Objective Self-Critique**: Acknowledge prediction errors transparently

7. **Recent Data Priority**: Weighted metrics (near-term biased) override simple metrics when conflicting

8. **Language Requirement**: ALL text fields MUST be in Chinese (ä¸­æ–‡)
"""

        response = deepseek_client.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {
                    "role": "system",
                    "content": "You are an objective parameter optimization reviewer. Always respond in Chinese (ä¸­æ–‡)."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )
        
        ai_response = response.choices[0].message.content.strip()
        print(f"\nã€AIå¤ç›˜åˆ†æã€‘")
        print(ai_response)
        
        # è§£æJSON
        import re
        json_match = re.search(r"```json\s*(.*?)\s*```", ai_response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_str = ai_response
        
        review_result = json.loads(json_str)
        
        return review_result
        
    except Exception as e:
        print(f"âš ï¸ AIå¤ç›˜å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


# ============================================================================
# V7.7.0: å¤šé˜¶æ®µç›ˆåˆ©ä¼˜å…ˆä¼˜åŒ–ç³»ç»Ÿ
# ============================================================================
# æ–°å¢4ä¸ªé˜¶æ®µå‡½æ•°ï¼Œç¡®ä¿ä¼˜å…ˆæ‰¾åˆ°ç›ˆåˆ©å‚æ•°ç»„åˆ
# é˜¶æ®µ1: profit_discovery_phase_v770() - ç›ˆåˆ©æ¢ç´¢ï¼ˆæœ€å¤š8è½®ï¼‰
# é˜¶æ®µ2: profit_expansion_phase_v770() - ç›ˆåˆ©æ‰©å¤§ï¼ˆæœ€å¤š3è½®ï¼‰
# é˜¶æ®µ3: fine_tuning_phase_v770() - å‚æ•°ä¼˜åŒ–ï¼ˆ1è½®ï¼‰
# é˜¶æ®µ4: validation_phase_v770() - æœ€ç»ˆéªŒè¯ï¼ˆ1è½®ï¼‰
# ============================================================================

# æ³¨æ„ï¼šç”±äº V7.7.0 ä»£ç é‡è¾ƒå¤§ï¼ˆçº¦1500è¡Œï¼‰ï¼Œå·²ä¿å­˜åˆ°ç‹¬ç«‹æ–‡ä»¶
# è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤æ‰‹åŠ¨åˆå¹¶ï¼š
#   python3 /tmp/merge_v770_to_q wen.py
# æˆ–ä½¿ç”¨æä¾›çš„éƒ¨ç½²è„šæœ¬

# ============================================================================
# é˜¶æ®µ1ï¼šç›ˆåˆ©æ¢ç´¢ (Profit Discovery Phase)
# ============================================================================

def profit_discovery_phase_v770(data_summary, current_config, historical_range, days=7, max_rounds=8):
    """
    V7.7.0 é˜¶æ®µ1ï¼šç›ˆåˆ©æ¢ç´¢
    
    ç›®æ ‡ï¼šé€šè¿‡å¤šè½®æ¢ç´¢ç­–ç•¥ï¼Œæ‰¾åˆ°è‡³å°‘1ä¸ªç›ˆåˆ©å‚æ•°ç»„åˆ
    
    ç­–ç•¥ï¼š
    - Round 1: é»˜è®¤7ç‚¹æˆ˜ç•¥é‡‡æ ·ï¼ˆä½¿ç”¨å†å²æœ€ä¼˜èŒƒå›´ï¼‰
    - Round 2: AIæ¨èæ–°åŒºåŸŸï¼ˆå¦‚æœRound 1å…¨äºæŸï¼‰
    - Round 3: æå®½æ¾åŒºåŸŸï¼ˆR:R 0.8-1.5, å…±è¯† 1-2ï¼‰
    - Round 4: æä¸¥æ ¼åŒºåŸŸï¼ˆR:R 3.0-5.0, å…±è¯† 3-4ï¼‰
    - Round 5: ä¸­é—´åŒºåŸŸï¼ˆR:R 1.8-2.5, å…±è¯† 2-3ï¼‰
    - Round 6: AIæ·±åº¦åˆ†æ + åˆ›æ–°æ¨è
    - Round 7: æç«¯ATRæµ‹è¯•ï¼ˆATR 1.0-2.5ï¼‰
    - Round 8: AIç´§æ€¥æ¨èï¼ˆæœ€åæœºä¼šï¼‰
    
    Args:
        data_summary: äº¤æ˜“æ•°æ®æ‘˜è¦
        current_config: å½“å‰é…ç½®
        historical_range: å†å²æœ€ä¼˜é‡‡æ ·èŒƒå›´
        days: å›æµ‹å¤©æ•°ï¼ˆã€V7.9ã€‘é»˜è®¤7å¤©ï¼Œæ ·æœ¬é‡å¤§æ—¶è‡ªåŠ¨æ‰©å±•åˆ°14å¤©ï¼‰
        max_rounds: æœ€å¤§æ¢ç´¢è½®æ¬¡
    
    Returns:
        {
            'found_profitable': bool,
            'best_profitable': dict or None,
            'all_profitable': list,
            'all_results': list,
            'rounds': int,
            'search_path': list,
            'final_status': 'PROFITABLE' / 'NO_PROFITABLE'
        }
    """
    print(f"\n{'='*70}")
    print(f"ã€é˜¶æ®µ1ï¼šç›ˆåˆ©æ¢ç´¢ã€‘æœ€å¤š{max_rounds}è½®ï¼Œç›´åˆ°æ‰¾åˆ°ç›ˆåˆ©ç»„åˆ")
    print(f"{'='*70}")
    print(f"  ç­–ç•¥ï¼šä»é»˜è®¤èŒƒå›´å¼€å§‹ï¼Œé€æ­¥æ‰©å¤§æœç´¢ï¼Œç¡®ä¿æ‰¾åˆ°ç›ˆåˆ©")
    print(f"  ç»ˆæ­¢ï¼šæ‰¾åˆ°ç›ˆåˆ© OR å®Œæˆ{max_rounds}è½®")
    print()
    
    all_results = []
    all_profitable = []
    search_path = []
    
    for round_num in range(1, max_rounds + 1):
        print(f"  ğŸ” æ¢ç´¢ Round {round_num}/{max_rounds}")
        
        # æ ¹æ®è½®æ¬¡ç¡®å®šæœç´¢ç­–ç•¥
        if round_num == 1:
            # Round 1: é»˜è®¤7ç‚¹æˆ˜ç•¥é‡‡æ ·
            print(f"     ç­–ç•¥ï¼šé»˜è®¤7ç‚¹æˆ˜ç•¥é‡‡æ ·")
            
            # ä½¿ç”¨å†å²æœ€ä¼˜èŒƒå›´ï¼ˆå¦‚æœæœ‰ï¼‰
            if historical_range:
                rr_min, rr_max = historical_range.get('rr_range', [1.4, 2.5])
                consensus_min, consensus_max = historical_range.get('consensus_range', [2, 3])
                atr_min, atr_max = historical_range.get('atr_range', [1.4, 1.9])
                print(f"     èŒƒå›´ï¼šR:R [{rr_min:.1f}-{rr_max:.1f}], å…±è¯† [{consensus_min}-{consensus_max}], ATR [{atr_min:.1f}-{atr_max:.1f}]")
            else:
                rr_min, rr_max = 1.4, 2.5
                consensus_min, consensus_max = 2, 3
                atr_min, atr_max = 1.4, 1.9
                print(f"     èŒƒå›´ï¼šé»˜è®¤èŒƒå›´ï¼ˆæ— å†å²æ•°æ®ï¼‰")
            
            # ç”Ÿæˆ7ä¸ªæˆ˜ç•¥é‡‡æ ·ç‚¹
            test_points = [
                {'min_risk_reward': rr_min, 'min_indicator_consensus': consensus_min, 'atr_stop_multiplier': atr_min, 'name': 'æå®½æ¾'},
                {'min_risk_reward': (rr_min + rr_max * 2) / 3, 'min_indicator_consensus': consensus_min, 'atr_stop_multiplier': (atr_min + atr_max) / 2, 'name': 'åå®½æ¾'},
                {'min_risk_reward': (rr_min + rr_max) / 2, 'min_indicator_consensus': consensus_min, 'atr_stop_multiplier': (atr_min + atr_max) / 2, 'name': 'æ ‡å‡†'},
                {'min_risk_reward': (rr_min * 2 + rr_max) / 3, 'min_indicator_consensus': consensus_min, 'atr_stop_multiplier': (atr_min + atr_max * 2) / 3, 'name': 'åä¸¥æ ¼'},
                {'min_risk_reward': rr_max, 'min_indicator_consensus': consensus_max, 'atr_stop_multiplier': atr_max, 'name': 'ä¸¥æ ¼'},
                {'min_risk_reward': rr_max * 1.2, 'min_indicator_consensus': consensus_max, 'atr_stop_multiplier': atr_max, 'name': 'è¶…ä¸¥æ ¼'},
                {'min_risk_reward': rr_max * 1.4, 'min_indicator_consensus': consensus_max, 'atr_stop_multiplier': atr_max, 'name': 'æä¸¥æ ¼'},
            ]
        
        elif round_num == 2:
            # Round 2: AIæ¨èæ–°åŒºåŸŸ
            print(f"     ç­–ç•¥ï¼šAIåˆ†æRound 1ç»“æœï¼Œæ¨èæ–°åŒºåŸŸ")
            
            # æ„å»ºAIæç¤º
            round1_summary = "\n".join([
                f"    â€¢ {r['name']}: æ€»ç›ˆåˆ©={r.get('total_profit', 0):.2f}%, èƒœç‡={r.get('win_rate', 0)*100:.1f}%, "
                f"ç›ˆäºæ¯”={r.get('profit_ratio', 0):.2f}:1"
                for r in all_results if 'name' in r
                    ])
            
            ai_prompt = f"""
## AIä»»åŠ¡ï¼šåˆ†æRound 1ç»“æœï¼Œæ¨èæ–°çš„ç›ˆåˆ©æœç´¢åŒºåŸŸ

### Round 1 ç»“æœï¼ˆå…¨éƒ¨äºæŸï¼‰
{round1_summary}

### åˆ†æè¦æ±‚ï¼š
1. **è¯Šæ–­**ï¼šä¸ºä»€ä¹ˆæ‰€æœ‰é…ç½®éƒ½äºæŸï¼Ÿ
   - èƒœç‡å¤ªä½ï¼Ÿï¼ˆ<40%ï¼‰
   - ç›ˆäºæ¯”å¤ªä½ï¼Ÿï¼ˆ<1.5ï¼‰
   - å‚æ•°èŒƒå›´æœ‰é—®é¢˜ï¼Ÿ

2. **å‡è®¾**ï¼šç›ˆåˆ©å¯èƒ½å­˜åœ¨äºå“ªä¸ªåŒºåŸŸï¼Ÿ
   - æ›´å®½æ¾ï¼Ÿï¼ˆR:R 0.8-1.5, å…±è¯† 1-2ï¼‰
   - æ›´ä¸¥æ ¼ï¼Ÿï¼ˆR:R 3.0-5.0, å…±è¯† 3-4ï¼‰
   - è°ƒæ•´ATRï¼Ÿï¼ˆ1.0-2.5ï¼‰

3. **æ¨è**ï¼š4ä¸ªæ–°æµ‹è¯•ç‚¹ï¼Œè¦†ç›–æœ€å¯èƒ½ç›ˆåˆ©çš„åŒºåŸŸ

### è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "diagnosis": "äºæŸåŸå› è¯Šæ–­ï¼ˆä¸­æ–‡ï¼‰",
  "hypothesis": "ç›ˆåˆ©å¯èƒ½åŒºåŸŸï¼ˆä¸­æ–‡ï¼‰",
  "strategy": "EXTREME_LOOSE" / "EXTREME_STRICT" / "ADJUST_ATR" / "MIDDLE_GROUND",
  "recommended_tests": [
    {{
      "min_risk_reward": X,
      "min_indicator_consensus": Y,
      "atr_stop_multiplier": Z,
      "name": "æµ‹è¯•ç‚¹åç§°",
      "reason": "ä¸ºä»€ä¹ˆæµ‹è¯•è¿™ä¸ªç‚¹ï¼ˆä¸­æ–‡ï¼‰"
    }},
    ... (4 points)
  ],
  "confidence": "HIGH" / "MEDIUM" / "LOW"
}}
"""
            
            # è°ƒç”¨AIï¼ˆç›´æ¥ä½¿ç”¨å…¨å±€deepseek_clientï¼‰
            try:
                response = deepseek_client.chat.completions.create(
                    model="deepseek-reasoner",
                    messages=[{"role": "user", "content": ai_prompt}],
                    temperature=0.7,
                    max_tokens=8000  # ğŸ”§ å¢åŠ åˆ°8000ï¼Œé¿å…å¤æ‚å†³ç­–æ—¶JSONè¢«æˆªæ–­
                )
                
                ai_content = response.choices[0].message.content.strip()
                finish_reason = response.choices[0].finish_reason
                
                # ğŸ”§ V7.7.0.12: æ£€æµ‹æ˜¯å¦è¢«æˆªæ–­
                if finish_reason == 'length':
                    print(f"     âš ï¸ AIå›å¤è¢«æˆªæ–­ï¼ˆè¶…è¿‡max_tokensé™åˆ¶ï¼‰")
                    print(f"     [è°ƒè¯•] æˆªæ–­çš„å†…å®¹: {ai_content[-200:]}...")
                    raise ValueError("AIå›å¤è¢«æˆªæ–­ï¼Œæ— æ³•æå–å®Œæ•´JSON")
                
                if not ai_content:
                    print(f"     âš ï¸ AIè¿”å›ç©ºå†…å®¹")
                    raise ValueError("AIè¿”å›ç©ºå†…å®¹")
                
                ai_suggestion = extract_json_from_ai_response(ai_content)  # ğŸ”§ V7.7.0.11: ä½¿ç”¨é²æ£’JSONæå–
                print(f"     âœ… AIè¯Šæ–­ï¼š{ai_suggestion['diagnosis'][:100]}...")
                print(f"     âœ… AIç­–ç•¥ï¼š{ai_suggestion['strategy']}")
                test_points = ai_suggestion['recommended_tests']
            
            except Exception as e:
                print(f"     âš ï¸ AIè°ƒç”¨å¤±è´¥: {e}")
                print(f"     ä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼šæµ‹è¯•ä¸­é—´åŒºåŸŸ")
                test_points = [
                    {'min_risk_reward': 1.8, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 1.6, 'name': 'ä¸­é—´åå®½æ¾'},
                    {'min_risk_reward': 2.2, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.7, 'name': 'ä¸­é—´æ ‡å‡†'},
                    {'min_risk_reward': 2.6, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.8, 'name': 'ä¸­é—´åä¸¥æ ¼'},
                    {'min_risk_reward': 3.0, 'min_indicator_consensus': 4, 'atr_stop_multiplier': 1.9, 'name': 'ä¸­é—´ä¸¥æ ¼'},
                ]
        
        elif round_num == 3:
            # Round 3: æå®½æ¾åŒºåŸŸ
            print(f"     ç­–ç•¥ï¼šæµ‹è¯•æå®½æ¾åŒºåŸŸï¼ˆé«˜é¢‘äº¤æ˜“ï¼‰")
            test_points = [
                {'min_risk_reward': 0.8, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 1.2, 'name': 'è¶…çº§å®½æ¾'},
                {'min_risk_reward': 1.0, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 1.4, 'name': 'æåº¦å®½æ¾'},
                {'min_risk_reward': 1.2, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 1.6, 'name': 'å¾ˆå®½æ¾'},
                {'min_risk_reward': 1.4, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 1.5, 'name': 'è¾ƒå®½æ¾'},
            ]
        
        elif round_num == 4:
            # Round 4: æä¸¥æ ¼åŒºåŸŸ
            print(f"     ç­–ç•¥ï¼šæµ‹è¯•æä¸¥æ ¼åŒºåŸŸï¼ˆç²¾é€‰é«˜è´¨é‡ï¼‰")
            test_points = [
                {'min_risk_reward': 3.0, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.3, 'name': 'è¾ƒä¸¥æ ¼'},
                {'min_risk_reward': 3.5, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.4, 'name': 'å¾ˆä¸¥æ ¼'},
                {'min_risk_reward': 4.0, 'min_indicator_consensus': 4, 'atr_stop_multiplier': 1.5, 'name': 'æåº¦ä¸¥æ ¼'},
                {'min_risk_reward': 5.0, 'min_indicator_consensus': 4, 'atr_stop_multiplier': 1.6, 'name': 'è¶…çº§ä¸¥æ ¼'},
            ]
        
        elif round_num == 5:
            # Round 5: ä¸­é—´åŒºåŸŸï¼ˆå¹³è¡¡å‹ï¼‰
            print(f"     ç­–ç•¥ï¼šæµ‹è¯•ä¸­é—´å¹³è¡¡åŒºåŸŸ")
            test_points = [
                {'min_risk_reward': 1.8, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 1.5, 'name': 'å¹³è¡¡åå®½æ¾'},
                {'min_risk_reward': 2.0, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 1.6, 'name': 'å¹³è¡¡æ ‡å‡†1'},
                {'min_risk_reward': 2.2, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.7, 'name': 'å¹³è¡¡æ ‡å‡†2'},
                {'min_risk_reward': 2.5, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.8, 'name': 'å¹³è¡¡åä¸¥æ ¼'},
            ]
        
        elif round_num == 6:
            # Round 6: AIæ·±åº¦åˆ†æï¼ˆä½¿ç”¨æ‰€æœ‰å†å²æ•°æ®ï¼‰
            print(f"     ç­–ç•¥ï¼šAIæ·±åº¦åˆ†ææ‰€æœ‰å†å²ï¼Œåˆ›æ–°æ¨è")
            
            # æ„å»ºå®Œæ•´å†å²æ‘˜è¦
            all_summary = "\n".join([
                f"    Round {i+1}: {len([r for r in all_results if r.get('round') == i+1])}ä¸ªç‚¹, "
                    f"ç›ˆåˆ©: {len([r for r in all_results if r.get('round') == i+1 and r.get('is_profitable')])}ä¸ª"
                for i in range(round_num - 1)
                    ])
            
            ai_deep_prompt = f"""
## æ·±åº¦åˆ†æï¼šç»è¿‡{round_num-1}è½®æ¢ç´¢ä»æœªæ‰¾åˆ°ç›ˆåˆ©

### å†å²æ¢ç´¢æ‘˜è¦
{all_summary}

### ä½ çš„ä»»åŠ¡
ä½œä¸ºé«˜çº§é‡åŒ–åˆ†æå¸ˆï¼Œä½ éœ€è¦çªç ´å¸¸è§„ï¼Œåˆ›æ–°æ€§åœ°æ¨è4ä¸ª**ææœ‰å¯èƒ½ç›ˆåˆ©**çš„å‚æ•°ç»„åˆã€‚

**å…³é”®æ´å¯Ÿï¼š**
- å¦‚æœå®½æ¾å’Œä¸¥æ ¼éƒ½äºæŸ â†’ å¯èƒ½æ˜¯å¸‚åœºç»“æ„é—®é¢˜ï¼Œè€ƒè™‘ç‰¹æ®ŠATRæˆ–æç«¯å…±è¯†
- å¦‚æœæŸä¸ªæ–¹å‘æ¥è¿‘ç›ˆåˆ© â†’ åœ¨è¯¥æ–¹å‘é™„è¿‘å¾®è°ƒ
- è€ƒè™‘éçº¿æ€§ç»„åˆï¼ˆå¦‚ï¼šæå®½æ¾R:R + æä¸¥æ ¼å…±è¯†ï¼‰

**åˆ›æ–°æ–¹å‘ï¼š**
1. æç«¯ATRç»„åˆï¼ˆ1.0-2.5ï¼‰
2. éå¯¹ç§°ç»„åˆï¼ˆå¦‚ï¼šä½R:R + é«˜å…±è¯†ï¼‰
3. åç›´è§‰ç»„åˆï¼ˆå¦‚ï¼šé«˜R:R + ä½å…±è¯† + ç´§æ­¢æŸï¼‰
4. å†å²æ•°æ®æš—ç¤ºçš„åŒºåŸŸ

### è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "deep_analysis": "æ·±åº¦åˆ†æç»“è®ºï¼ˆä¸­æ–‡ï¼‰",
  "innovation_hypothesis": "åˆ›æ–°å‡è®¾ï¼ˆä¸­æ–‡ï¼‰",
  "recommended_tests": [
    {{
      "min_risk_reward": X,
      "min_indicator_consensus": Y,
      "atr_stop_multiplier": Z,
      "name": "åˆ›æ–°ç‚¹åç§°",
      "innovation_reason": "ä¸ºä»€ä¹ˆè¿™ä¸ªç»„åˆå¯èƒ½çªç ´ï¼ˆä¸­æ–‡ï¼‰"
    }},
    ... (4 innovative points)
  ]
}}
"""
            
            try:
                response = deepseek_client.chat.completions.create(
                    model="deepseek-reasoner",
                    messages=[{"role": "user", "content": ai_deep_prompt}],
                    temperature=0.8,  # æ›´é«˜æ¸©åº¦é¼“åŠ±åˆ›æ–°
                    max_tokens=8000  # ğŸ”§ å¢åŠ åˆ°8000ï¼Œé¿å…å¤æ‚å†³ç­–æ—¶JSONè¢«æˆªæ–­
                )
                
                ai_content = response.choices[0].message.content.strip()
                json_match = re.search(r'\{[\s\S]*\}', ai_content)
                
                if json_match:
                    ai_deep = json.loads(json_match.group(0))
                    print(f"     AIæ·±åº¦åˆ†æï¼š{ai_deep['deep_analysis'][:80]}...")
                    test_points = ai_deep['recommended_tests']
                else:
                    raise ValueError("AIå“åº”æ ¼å¼é”™è¯¯")
            
            except Exception as e:
                print(f"     âš ï¸ AIæ·±åº¦åˆ†æå¤±è´¥: {e}")
                test_points = [
                    {'min_risk_reward': 1.5, 'min_indicator_consensus': 4, 'atr_stop_multiplier': 1.2, 'name': 'ä½Ré«˜å…±è¯†'},
                    {'min_risk_reward': 3.5, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 2.0, 'name': 'é«˜Rä½å…±è¯†'},
                    {'min_risk_reward': 2.5, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.0, 'name': 'æç´§æ­¢æŸ'},
                    {'min_risk_reward': 2.0, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 2.5, 'name': 'ææ¾æ­¢æŸ'},
                ]
        
        elif round_num == 7:
            # Round 7: æç«¯ATRæµ‹è¯•
            print(f"     ç­–ç•¥ï¼šæµ‹è¯•æç«¯ATRè®¾ç½®")
            test_points = [
                {'min_risk_reward': 2.0, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.0, 'name': 'è¶…ç´§æ­¢æŸ'},
                {'min_risk_reward': 2.0, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.2, 'name': 'å¾ˆç´§æ­¢æŸ'},
                {'min_risk_reward': 2.0, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 2.2, 'name': 'å¾ˆæ¾æ­¢æŸ'},
                {'min_risk_reward': 2.0, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 2.5, 'name': 'è¶…æ¾æ­¢æŸ'},
            ]
        
        else:  # Round 8: æœ€åæœºä¼š
            # Round 8: AIç´§æ€¥æ¨è
            print(f"     ç­–ç•¥ï¼šâš ï¸ æœ€åæœºä¼š - AIç´§æ€¥æ¨è")
            print(f"     çŠ¶æ€ï¼šå·²æ¢ç´¢{round_num-1}è½®ä»æœªæ‰¾åˆ°ç›ˆåˆ©")
            
            emergency_prompt = f"""
## ğŸš¨ ç´§æ€¥ä»»åŠ¡ï¼šæœ€åæœºä¼šæ‰¾åˆ°ç›ˆåˆ©

### å½“å‰æƒ…å†µ
- å·²æ¢ç´¢{round_num-1}è½®ï¼Œæµ‹è¯•{len(all_results)}ä¸ªå‚æ•°ç»„åˆ
- **ä»æœªæ‰¾åˆ°ç›ˆåˆ©ç»„åˆ**
- è¿™æ˜¯ç¬¬{round_num}è½®ï¼ˆæœ€åæœºä¼šï¼‰

### ä½ çš„ç´§æ€¥ä»»åŠ¡
æ¨è4ä¸ª**ç»å¯¹æœ€æœ‰å¯èƒ½ç›ˆåˆ©**çš„å‚æ•°ç»„åˆã€‚
ä¸è¦ä¿å®ˆï¼Œè¦å¤§èƒ†åˆ›æ–°ï¼

### å‚è€ƒå†å²æœ€æ¥è¿‘ç›ˆåˆ©çš„ç‚¹
ï¼ˆå¦‚æœæœ‰ï¼‰

### è¾“å‡ºï¼ˆJSONï¼‰ï¼š
{{
  "emergency_analysis": "ä¸ºä»€ä¹ˆä¸€ç›´æ‰¾ä¸åˆ°ç›ˆåˆ©ï¼ˆä¸­æ–‡ï¼‰",
  "last_hope_strategy": "æœ€åå¸Œæœ›ç­–ç•¥ï¼ˆä¸­æ–‡ï¼‰",
  "final_recommendations": [
    {{
      "min_risk_reward": X,
      "min_indicator_consensus": Y,
      "atr_stop_multiplier": Z,
      "name": "æœ€åå¸Œæœ›X",
      "why_this_works": "ä¸ºä»€ä¹ˆè¿™ä¸ªå¯èƒ½è¡Œï¼ˆä¸­æ–‡ï¼‰"
    }},
    ... (4 points)
  ]
}}
"""
            
            try:
                response = deepseek_client.chat.completions.create(
                    model="deepseek-reasoner",
                    messages=[{"role": "user", "content": emergency_prompt}],
                    temperature=0.9,  # æœ€é«˜æ¸©åº¦ï¼Œæœ€å¤§åˆ›æ–°
                    max_tokens=8000  # ğŸ”§ å¢åŠ åˆ°8000ï¼Œé¿å…å¤æ‚å†³ç­–æ—¶JSONè¢«æˆªæ–­
                )
                
                ai_content = response.choices[0].message.content.strip()
                json_match = re.search(r'\{[\s\S]*\}', ai_content)
                
                if json_match:
                    ai_emergency = json.loads(json_match.group(0))
                    print(f"     ğŸš¨ AIç´§æ€¥åˆ†æï¼š{ai_emergency['emergency_analysis']}")
                    test_points = ai_emergency['final_recommendations']
                else:
                    raise ValueError("AIå“åº”æ ¼å¼é”™è¯¯")
            
            except Exception as e:
                print(f"     âš ï¸ AIç´§æ€¥æ¨èå¤±è´¥: {e}")
                # ä½¿ç”¨æœ€æç«¯çš„ç»„åˆä½œä¸ºæœ€åå°è¯•
                test_points = [
                    {'min_risk_reward': 0.8, 'min_indicator_consensus': 4, 'atr_stop_multiplier': 1.0, 'name': 'æç«¯ç»„åˆ1'},
                    {'min_risk_reward': 5.0, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 2.5, 'name': 'æç«¯ç»„åˆ2'},
                    {'min_risk_reward': 2.5, 'min_indicator_consensus': 2, 'atr_stop_multiplier': 1.8, 'name': 'å¹³è¡¡åå¤‡1'},
                    {'min_risk_reward': 3.0, 'min_indicator_consensus': 3, 'atr_stop_multiplier': 1.5, 'name': 'å¹³è¡¡åå¤‡2'},
                ]
        
        # å›æµ‹æ‰€æœ‰æµ‹è¯•ç‚¹
        print(f"     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” å›æµ‹{len(test_points)}ä¸ªç‚¹...")
        round_profitable = []
        
        for point in test_points:
            config = {k: v for k, v in point.items() if k != 'name'}
            # ã€V7.9ã€‘å›æµ‹ï¼ˆæ—©æœŸ7å¤©ï¼ŒåæœŸæ‰©å±•åˆ°14å¤©ï¼‰
            backtest_days = 7 if round_num <= 3 else min(14, days * 2)
            result = backtest_parameters(config, days=backtest_days, verbose=False)
            
            if result:
                result['name'] = point['name']
                result['round'] = round_num
                result['config'] = config
                all_results.append(result)
                
                # æ£€æŸ¥æ˜¯å¦ç›ˆåˆ©
                is_profitable = result.get('is_profitable', False)
                total_profit = result.get('total_profit', 0)
                
                if is_profitable and total_profit > 0:
                    round_profitable.append(result)
                    all_profitable.append(result)
                    print(f"        âœ… {point['name']}: ç›ˆåˆ© +{total_profit:.2f}% (æœŸæœ›æ”¶ç›Š +{result.get('expected_return', 0)*100:.2f}%)")
                else:
  