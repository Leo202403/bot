#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
V8.3.21 æ—¶åŒºä¿®å¤å·¥å…·

é—®é¢˜ï¼šæœåŠ¡å™¨ä¹‹å‰ä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰ï¼Œå¯¼è‡´ä¿å­˜çš„æ—¶é—´æˆ³æ¯”å®é™…æ—¶é—´å¤šäº†8å°æ—¶
è§£å†³ï¼šå°†æ‰€æœ‰æ—¶é—´æˆ³å‡å»8å°æ—¶ï¼Œç¡®ä¿æ²¡æœ‰"æœªæ¥"çš„è®°å½•

æ¶‰åŠçš„æ•°æ®æ–‡ä»¶ï¼š
1. trades_history.csv - äº¤æ˜“å†å²
2. ai_decisions.json - AIå†³ç­–å†å²
3. pnl_history.csv - ç›ˆäºå†å²
4. market_snapshots/*.csv - å¸‚åœºå¿«ç…§
"""

import pandas as pd
import json
from pathlib import Path
from datetime import datetime, timedelta
import shutil
from typing import List, Dict

# é…ç½®
MODELS = ['qwen', 'deepseek']
BACKUP_SUFFIX = '.bak_before_timezone_fix'

def backup_file(file_path: Path):
    """
    å¤‡ä»½æ–‡ä»¶
    """
    if file_path.exists():
        backup_path = file_path.parent / f"{file_path.name}{BACKUP_SUFFIX}"
        shutil.copy2(file_path, backup_path)
        print(f"  âœ“ å·²å¤‡ä»½: {backup_path.name}")
        return True
    return False


def fix_csv_timestamps(file_path: Path, time_columns: List[str], dry_run: bool = False):
    """
    ä¿®å¤CSVæ–‡ä»¶ä¸­çš„æ—¶é—´æˆ³ï¼ˆå‡å»8å°æ—¶ï¼‰
    
    Args:
        file_path: CSVæ–‡ä»¶è·¯å¾„
        time_columns: åŒ…å«æ—¶é—´æˆ³çš„åˆ—ååˆ—è¡¨
        dry_run: æ˜¯å¦åªæ£€æŸ¥ä¸ä¿®æ”¹
    """
    if not file_path.exists():
        print(f"  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    print(f"\n{'[æ£€æŸ¥]' if dry_run else '[ä¿®å¤]'} {file_path.name}")
    
    try:
        # è¯»å–CSV
        df = pd.read_csv(file_path)
        
        if df.empty:
            print(f"  âœ“ æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡")
            return
        
        print(f"  ğŸ“Š å…±{len(df)}æ¡è®°å½•")
        
        # æ£€æŸ¥æ—¶é—´åˆ—
        found_columns = [col for col in time_columns if col in df.columns]
        
        if not found_columns:
            print(f"  âš ï¸  æœªæ‰¾åˆ°æ—¶é—´åˆ—: {time_columns}")
            return
        
        # ä¿®å¤æ¯ä¸ªæ—¶é—´åˆ—
        modified = False
        future_count = 0
        
        for col in found_columns:
            print(f"\n  å¤„ç†åˆ—: {col}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœªæ¥æ—¶é—´
            now = datetime.now()
            
            # å°è¯•è§£ææ—¶é—´
            for idx, value in df[col].items():
                if pd.isna(value):
                    continue
                
                try:
                    # å°è¯•å¤šç§æ—¶é—´æ ¼å¼
                    dt = None
                    for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d']:
                        try:
                            dt = datetime.strptime(str(value), fmt)
                            break
                        except:
                            continue
                    
                    if dt and dt > now:
                        future_count += 1
                        if future_count <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªç¤ºä¾‹
                            print(f"    âš ï¸  å‘ç°æœªæ¥æ—¶é—´: {dt} (å½“å‰: {now})")
                
                except Exception as e:
                    continue
            
            if future_count > 0:
                print(f"    ğŸš¨ å‘ç°{future_count}æ¡æœªæ¥è®°å½•ï¼")
                
                if not dry_run:
                    # ä¿®å¤ï¼šå‡å»8å°æ—¶
                    df[col] = pd.to_datetime(df[col], errors='coerce')
                    df[col] = df[col] - timedelta(hours=8)
                    modified = True
                    print(f"    âœ“ å·²ä¿®å¤ï¼šæ‰€æœ‰æ—¶é—´å‡å»8å°æ—¶")
            else:
                print(f"    âœ“ æ— æœªæ¥æ—¶é—´ï¼Œæ•°æ®æ­£å¸¸")
        
        # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
        if modified and not dry_run:
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_file(file_path)
            
            # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
            df.to_csv(file_path, index=False, encoding='utf-8')
            print(f"\n  âœ… æ–‡ä»¶å·²ä¿®å¤å¹¶ä¿å­˜")
        elif dry_run and future_count > 0:
            print(f"\n  ğŸ’¡ [å¹²è¿è¡Œæ¨¡å¼] å®é™…è¿è¡Œæ—¶å°†ä¿®å¤{future_count}æ¡è®°å½•")
        else:
            print(f"\n  âœ“ æ— éœ€ä¿®å¤")
    
    except Exception as e:
        print(f"  âŒ å¤„ç†å¤±è´¥: {e}")


def fix_json_timestamps(file_path: Path, dry_run: bool = False):
    """
    ä¿®å¤JSONæ–‡ä»¶ä¸­çš„æ—¶é—´æˆ³ï¼ˆå‡å»8å°æ—¶ï¼‰
    
    Args:
        file_path: JSONæ–‡ä»¶è·¯å¾„
        dry_run: æ˜¯å¦åªæ£€æŸ¥ä¸ä¿®æ”¹
    """
    if not file_path.exists():
        print(f"  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    print(f"\n{'[æ£€æŸ¥]' if dry_run else '[ä¿®å¤]'} {file_path.name}")
    
    try:
        # è¯»å–JSON
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not data:
            print(f"  âœ“ æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡")
            return
        
        print(f"  ğŸ“Š å…±{len(data)}æ¡è®°å½•")
        
        # æ£€æŸ¥æ—¶é—´å­—æ®µ
        modified = False
        future_count = 0
        now = datetime.now()
        
        for item in data:
            if 'timestamp' in item:
                try:
                    dt = datetime.fromisoformat(item['timestamp'])
                    
                    if dt > now:
                        future_count += 1
                        if future_count <= 3:
                            print(f"    âš ï¸  å‘ç°æœªæ¥æ—¶é—´: {dt} (å½“å‰: {now})")
                        
                        if not dry_run:
                            # ä¿®å¤ï¼šå‡å»8å°æ—¶
                            fixed_dt = dt - timedelta(hours=8)
                            item['timestamp'] = fixed_dt.isoformat()
                            modified = True
                
                except Exception as e:
                    continue
        
        if future_count > 0:
            print(f"    ğŸš¨ å‘ç°{future_count}æ¡æœªæ¥è®°å½•ï¼")
            
            if modified and not dry_run:
                # å¤‡ä»½åŸæ–‡ä»¶
                backup_file(file_path)
                
                # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                print(f"\n  âœ… æ–‡ä»¶å·²ä¿®å¤å¹¶ä¿å­˜")
            elif dry_run:
                print(f"\n  ğŸ’¡ [å¹²è¿è¡Œæ¨¡å¼] å®é™…è¿è¡Œæ—¶å°†ä¿®å¤{future_count}æ¡è®°å½•")
        else:
            print(f"    âœ“ æ— æœªæ¥æ—¶é—´ï¼Œæ•°æ®æ­£å¸¸")
            print(f"\n  âœ“ æ— éœ€ä¿®å¤")
    
    except Exception as e:
        print(f"  âŒ å¤„ç†å¤±è´¥: {e}")


def fix_market_snapshots(snapshot_dir: Path, dry_run: bool = False):
    """
    ä¿®å¤market_snapshotsç›®å½•ä¸‹çš„æ‰€æœ‰CSVæ–‡ä»¶
    
    Args:
        snapshot_dir: market_snapshotsç›®å½•è·¯å¾„
        dry_run: æ˜¯å¦åªæ£€æŸ¥ä¸ä¿®æ”¹
    """
    if not snapshot_dir.exists():
        print(f"  âš ï¸  ç›®å½•ä¸å­˜åœ¨: {snapshot_dir}")
        return
    
    print(f"\n{'='*60}")
    print(f"{'[æ£€æŸ¥]' if dry_run else '[ä¿®å¤]'} å¸‚åœºå¿«ç…§ç›®å½•: {snapshot_dir}")
    print(f"{'='*60}")
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = list(snapshot_dir.glob("*.csv"))
    
    if not csv_files:
        print(f"  âš ï¸  ç›®å½•ä¸‹æ²¡æœ‰CSVæ–‡ä»¶")
        return
    
    print(f"  ğŸ“ æ‰¾åˆ°{len(csv_files)}ä¸ªå¿«ç…§æ–‡ä»¶")
    
    # åªä¿®å¤æœ€è¿‘30å¤©çš„æ•°æ®ï¼ˆé¿å…å¤„ç†å¤ªå¤šå†å²æ•°æ®ï¼‰
    recent_files = sorted(csv_files, reverse=True)[:30]
    
    for csv_file in recent_files:
        # market_snapshotsä¸­çš„timeåˆ—é€šå¸¸æ˜¯HH:MMæ ¼å¼ï¼Œä¸æ˜¯å®Œæ•´æ—¶é—´æˆ³
        # ä½†æ–‡ä»¶ååŒ…å«æ—¥æœŸï¼ˆYYYYMMDD.csvï¼‰
        # ä¸»è¦æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ˜¯å¦åœ¨æœªæ¥
        
        stat = csv_file.stat()
        file_mtime = datetime.fromtimestamp(stat.st_mtime)
        now = datetime.now()
        
        if file_mtime > now:
            print(f"\n  âš ï¸  {csv_file.name}: æ–‡ä»¶ä¿®æ”¹æ—¶é—´åœ¨æœªæ¥ ({file_mtime})")
            
            if not dry_run:
                # æ— æ³•ç›´æ¥ä¿®æ”¹æ–‡ä»¶æ—¶é—´æˆ³ï¼Œä½†å¯ä»¥ä¿®æ­£CSVå†…å®¹
                # å¸‚åœºå¿«ç…§çš„æ—¶é—´ä¸»è¦åœ¨æ–‡ä»¶åä¸­ï¼ŒCSVå†…åªæœ‰HH:MM
                print(f"    ğŸ’¡ å¸‚åœºå¿«ç…§æ–‡ä»¶çš„æ—¶é—´æˆ³æ— éœ€ä¿®å¤ï¼ˆæ—¶é—´åœ¨æ–‡ä»¶åä¸­ï¼‰")
        else:
            if csv_file == recent_files[0]:  # åªå¯¹ç¬¬ä¸€ä¸ªæ–‡ä»¶æ˜¾ç¤ºè¯¦æƒ…
                print(f"\n  âœ“ {csv_file.name}: æ—¶é—´æ­£å¸¸ ({file_mtime})")


def main():
    """
    ä¸»å‡½æ•°
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='V8.3.21 æ—¶åŒºä¿®å¤å·¥å…·')
    parser.add_argument('--dry-run', action='store_true', help='åªæ£€æŸ¥ä¸ä¿®æ”¹ï¼ˆæ¨èå…ˆè¿è¡Œï¼‰')
    parser.add_argument('--model', choices=['qwen', 'deepseek', 'all'], default='all', help='æŒ‡å®šä¿®å¤å“ªä¸ªæ¨¡å‹çš„æ•°æ®')
    args = parser.parse_args()
    
    print("=" * 80)
    print("V8.3.21 æ—¶åŒºä¿®å¤å·¥å…·")
    print("=" * 80)
    print(f"æ¨¡å¼: {'æ£€æŸ¥æ¨¡å¼ï¼ˆä¸ä¼šä¿®æ”¹æ–‡ä»¶ï¼‰' if args.dry_run else 'ä¿®å¤æ¨¡å¼ï¼ˆä¼šä¿®æ”¹æ–‡ä»¶ï¼‰'}")
    print(f"èŒƒå›´: {args.model}")
    print()
    
    if not args.dry_run:
        confirm = input("âš ï¸  ç¡®è®¤è¦ä¿®å¤æ•°æ®å—ï¼Ÿå°†ä¼šå¤‡ä»½åŸæ–‡ä»¶ã€‚(yes/no): ")
        if confirm.lower() != 'yes':
            print("âŒ å·²å–æ¶ˆ")
            return
    
    # ç¡®å®šè¦å¤„ç†çš„æ¨¡å‹
    models_to_fix = MODELS if args.model == 'all' else [args.model]
    
    for model in models_to_fix:
        print(f"\n{'='*80}")
        print(f"å¤„ç†æ¨¡å‹: {model.upper()}")
        print(f"{'='*80}")
        
        data_dir = Path("trading_data") / model
        
        if not data_dir.exists():
            print(f"  âš ï¸  æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
            continue
        
        # 1. ä¿®å¤äº¤æ˜“å†å²
        print(f"\n{'â”€'*60}")
        print("1. äº¤æ˜“å†å² (trades_history.csv)")
        print(f"{'â”€'*60}")
        fix_csv_timestamps(
            data_dir / "trades_history.csv",
            time_columns=['å¼€ä»“æ—¶é—´', 'å¹³ä»“æ—¶é—´', 'åˆ›å»ºæ—¶é—´', 'create_time'],
            dry_run=args.dry_run
        )
        
        # 2. ä¿®å¤ç›ˆäºå†å²
        print(f"\n{'â”€'*60}")
        print("2. ç›ˆäºå†å² (pnl_history.csv)")
        print(f"{'â”€'*60}")
        fix_csv_timestamps(
            data_dir / "pnl_history.csv",
            time_columns=['time', 'timestamp', 'æ—¶é—´'],
            dry_run=args.dry_run
        )
        
        # 3. ä¿®å¤AIå†³ç­–å†å²
        print(f"\n{'â”€'*60}")
        print("3. AIå†³ç­–å†å² (ai_decisions.json)")
        print(f"{'â”€'*60}")
        fix_json_timestamps(
            data_dir / "ai_decisions.json",
            dry_run=args.dry_run
        )
        
        # 4. ä¿®å¤å¸‚åœºå¿«ç…§
        print(f"\n{'â”€'*60}")
        print("4. å¸‚åœºå¿«ç…§ (market_snapshots/*.csv)")
        print(f"{'â”€'*60}")
        fix_market_snapshots(
            data_dir / "market_snapshots",
            dry_run=args.dry_run
        )
    
    print(f"\n{'='*80}")
    if args.dry_run:
        print("âœ… æ£€æŸ¥å®Œæˆï¼")
        print("ğŸ’¡ å¦‚ç¡®è®¤éœ€è¦ä¿®å¤ï¼Œè¯·è¿è¡Œ: python3 fix_timezone_data.py")
    else:
        print("âœ… ä¿®å¤å®Œæˆï¼")
        print("ğŸ’¡ å¤‡ä»½æ–‡ä»¶å·²ä¿å­˜ï¼ˆåç¼€.bak_before_timezone_fixï¼‰")
        print("ğŸ’¡ å¦‚æœ‰é—®é¢˜ï¼Œå¯ä»å¤‡ä»½æ¢å¤")
    print(f"{'='*80}")


if __name__ == '__main__':
    main()

