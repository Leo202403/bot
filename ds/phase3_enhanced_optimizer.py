#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã€V8.5.2.4.42ã€‘Phase 3å¢å¼ºä¼˜åŒ–å™¨

æ ¸å¿ƒåŠŸèƒ½:
1. å åŠ Phase 2çš„learned_featuresï¼ˆsignal_scoreæƒé‡ã€top5å‚æ•°ç»„åˆï¼‰
2. ä½¿ç”¨ä¼˜åŒ–åçš„signal_scoreæƒé‡é‡æ–°è®¡ç®—æ‰€æœ‰æœºä¼š
3. å¤šèµ·ç‚¹æœç´¢ï¼ˆAIå»ºè®® + Phase2æœ€ä¼˜ + Top5ç»„åˆï¼‰
4. ç»„åˆç­›é€‰æµ‹è¯•ï¼ˆconsensus Ã— signal_scoreçŸ©é˜µï¼‰
5. AIååŠ©åˆ†æå’Œæ¨èæœ€ä¼˜å‚æ•°
6. ã€V8.5.2.4.42æ–°å¢ã€‘åˆ†ç¦»ä¼˜åŒ–è¶…çŸ­çº¿å’Œæ³¢æ®µå‚æ•°
7. ã€V8.5.2.4.42æ–°å¢ã€‘æµ‹è¯•ç§»åŠ¨æ­¢ç›ˆæ­¢æŸæ•ˆæœ
"""

import json
from pathlib import Path
from typing import Dict, List
import sys


def sample_opportunities_for_phase3(opportunities: List[Dict], max_size: int = 800) -> List[Dict]:
    """
    ã€V8.5.2.4.89.4ã€‘ä¸ºPhase 3é‡‡æ ·æœºä¼šï¼ˆä¿ç•™ä»£è¡¨æ€§ï¼Œæ§åˆ¶å†…å­˜ï¼‰
    
    ç­–ç•¥ï¼š
    1. å…ˆæŒ‰è¶…çŸ­çº¿/æ³¢æ®µåˆ†ç±»
    2. æ¯ç±»åˆ†åˆ«é‡‡æ ·ï¼ˆä¿è¯ä¸¤ç±»éƒ½æœ‰ä»£è¡¨ï¼‰
    3. åœ¨æ¯ç±»å†…æŒ‰è´¨é‡åˆ†å±‚é‡‡æ ·
    
    Args:
        opportunities: æ‰€æœ‰æœºä¼šåˆ—è¡¨
        max_size: æœ€å¤§ä¿ç•™æ•°é‡ï¼ˆé»˜è®¤800ï¼Œçº¦å ç”¨170MBï¼‰
    
    Returns:
        é‡‡æ ·åçš„æœºä¼šåˆ—è¡¨
    """
    
    # ã€V8.5.2.4.89.4ã€‘å…ˆæŒ‰ç±»å‹åˆ†ç±»ï¼ˆå…³é”®ä¿®å¤ï¼‰
    scalping_opps = [o for o in opportunities if o.get('signal_type') == 'scalping']
    swing_opps = [o for o in opportunities if o.get('signal_type') == 'swing']
    
    print(f"  ğŸ“Š æœºä¼šåˆ†å¸ƒ: è¶…çŸ­çº¿{len(scalping_opps)}ä¸ª | æ³¢æ®µ{len(swing_opps)}ä¸ª")
    
    # å¦‚æœæ€»æ•°<=max_sizeï¼Œä¸éœ€è¦é‡‡æ ·
    if len(opportunities) <= max_size:
        print(f"  âœ“ æœºä¼šæ•°({len(opportunities)})æœªè¶…é™ï¼Œæ— éœ€é‡‡æ ·")
        return opportunities
    
    # ã€V8.5.2.4.89.4ã€‘æŒ‰ç±»å‹æ¯”ä¾‹åˆ†é…é…é¢
    scalping_ratio = len(scalping_opps) / len(opportunities) if opportunities else 0
    scalping_quota = int(max_size * scalping_ratio)
    swing_quota = max_size - scalping_quota
    
    # ç¡®ä¿è‡³å°‘å„æœ‰ä¸€äº›æ ·æœ¬ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
    # ã€ä¿®å¤ã€‘scalpingæœºä¼šå°‘ï¼Œè‡³å°‘ä¿ç•™200ä¸ªé¿å…è¿‡åº¦è¿‡æ»¤
    if len(scalping_opps) > 0 and scalping_quota < 200:
        scalping_quota = min(200, len(scalping_opps))
        swing_quota = max_size - scalping_quota
    if len(swing_opps) > 0 and swing_quota < 100:
        swing_quota = min(100, len(swing_opps))
        scalping_quota = max_size - swing_quota
    
    sampled = []
    
    # é‡‡æ ·è¶…çŸ­çº¿
    if scalping_opps:
        sampled_scalping = _sample_by_quality(scalping_opps, scalping_quota)
        sampled.extend(sampled_scalping)
        print(f"  âš¡ è¶…çŸ­çº¿é‡‡æ ·: {len(sampled_scalping)}/{len(scalping_opps)}ä¸ª")
    
    # é‡‡æ ·æ³¢æ®µ
    if swing_opps:
        sampled_swing = _sample_by_quality(swing_opps, swing_quota)
        sampled.extend(sampled_swing)
        print(f"  ğŸŒŠ æ³¢æ®µé‡‡æ ·: {len(sampled_swing)}/{len(swing_opps)}ä¸ª")
    
    print(f"  âœ‚ï¸  é‡‡æ ·å: {len(sampled)}ä¸ªæœºä¼šï¼ˆèŠ‚çœ{len(opportunities)-len(sampled)}ä¸ªï¼Œçº¦{(1-len(sampled)/len(opportunities))*100:.0f}%å†…å­˜ï¼‰")
    return sampled


def _sample_by_quality(opportunities: List[Dict], quota: int) -> List[Dict]:
    """
    ã€V8.5.2.4.89.63ã€‘æŒ‰è´¨é‡åˆ†å±‚é‡‡æ ·ï¼ˆåŠ¨æ€é˜ˆå€¼ï¼Œé¿å…è¶…çŸ­çº¿/æ³¢æ®µé‡‡æ ·å¤±è¡¡ï¼‰
    """
    import random
    
    if len(opportunities) <= quota:
        return opportunities
    
    # ã€ä¿®å¤ã€‘åŠ¨æ€è®¡ç®—è´¨é‡é˜ˆå€¼ï¼ˆåŸºäºå½“å‰æ•°æ®åˆ†å¸ƒï¼Œè€Œéå›ºå®š90/80ï¼‰
    scores = [o.get('signal_score', 0) for o in opportunities]
    scores_sorted = sorted(scores, reverse=True)
    
    # ä½¿ç”¨åˆ†ä½æ•°åŠ¨æ€è®¾ç½®é˜ˆå€¼
    p75_idx = int(len(scores_sorted) * 0.25)  # Top 25%
    p50_idx = int(len(scores_sorted) * 0.50)  # Top 50%
    
    high_threshold = scores_sorted[p75_idx] if p75_idx < len(scores_sorted) else 80
    medium_threshold = scores_sorted[p50_idx] if p50_idx < len(scores_sorted) else 60
    
    # æŒ‰è´¨é‡åˆ†å±‚
    high_quality = [o for o in opportunities if o.get('signal_score', 0) >= high_threshold]
    medium_quality = [o for o in opportunities if medium_threshold <= o.get('signal_score', 0) < high_threshold]
    low_quality = [o for o in opportunities if o.get('signal_score', 0) < medium_threshold]
    
    # ä¿ç•™æ‰€æœ‰é«˜è´¨é‡
    sampled = high_quality.copy()
    remaining_quota = quota - len(high_quality)
    
    if remaining_quota > 0:
        # ä»ä¸­ä½è´¨é‡ä¸­æŒ‰æ¯”ä¾‹é‡‡æ ·
        medium_sample_size = int(remaining_quota * 0.6)  # 60%ä¸­è´¨é‡
        low_sample_size = remaining_quota - medium_sample_size  # 40%ä½è´¨é‡
        
        if len(medium_quality) > medium_sample_size:
            sampled.extend(random.sample(medium_quality, medium_sample_size))
        else:
            sampled.extend(medium_quality)
            low_sample_size += medium_sample_size - len(medium_quality)
        
        if len(low_quality) > low_sample_size:
            sampled.extend(random.sample(low_quality, low_sample_size))
        else:
            sampled.extend(low_quality)
    
    return sampled


def phase3_enhanced_optimization(
    all_opportunities: List[Dict],
    phase1_baseline: Dict,
    phase2_baseline: Dict,
    kline_snapshots,
    model_name: str = "deepseek"
) -> Dict:
    """
    ã€V8.5.2.4.88ã€‘Phase 3å¢å¼ºä¼˜åŒ–ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰
    
    Args:
        all_opportunities: æ‰€æœ‰è¯†åˆ«çš„æœºä¼š
        phase1_baseline: Phase 1çš„ç»Ÿè®¡åŸºçº¿
        phase2_baseline: Phase 2çš„ä¼˜åŒ–ç»“æœï¼ˆåŒ…å«learned_featuresï¼‰
        kline_snapshots: å¸‚åœºå¿«ç…§æ•°æ®
        model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºAIè°ƒç”¨ï¼‰
    
    Returns:
        phase3_result: Phase 3ä¼˜åŒ–ç»“æœ
    """
    print(f"\n{'='*70}")
    print("âš–ï¸  ã€Phase 3ã€‘é£é™©æ§åˆ¶ä¸åˆ©æ¶¦æœ€å¤§åŒ–")
    print(f"{'='*70}")
    print("  ç­–ç•¥ï¼šå åŠ Phase 2æˆæœ + å¤šèµ·ç‚¹æœç´¢ + AIè¾…åŠ©å†³ç­–")
    print("  ç‰¹è‰²ï¼šä½¿ç”¨ä¼˜åŒ–æƒé‡ + consensusç­›é€‰ + ä¿¡å·åˆ†çŸ©é˜µ")
    print("  ã€V8.5.2.4.88ã€‘å†…å­˜ä¼˜åŒ–ï¼šæ™ºèƒ½é‡‡æ · + åˆ†æ‰¹æµ‹è¯•")
    print(f"{'='*70}")
    
    # ã€V8.5.2.4.88ã€‘å†…å­˜ä¼˜åŒ–ï¼šé‡‡æ ·æœºä¼š
    print("\n  ğŸ’¾ ã€å†…å­˜ä¼˜åŒ–ã€‘æœºä¼šé‡‡æ ·")
    print(f"     åŸå§‹æœºä¼šæ•°: {len(all_opportunities)}")
    all_opportunities = sample_opportunities_for_phase3(all_opportunities, max_size=800)
    print(f"     é‡‡æ ·åæœºä¼šæ•°: {len(all_opportunities)}")
    
    # ã€æ­¥éª¤1ã€‘æå–Phase 2å­¦åˆ°çš„ç‰¹å¾
    learned_features = phase2_baseline.get('learned_features', {})
    best_scalping_weights = learned_features.get('best_scalping_weights', {})
    best_swing_weights = learned_features.get('best_swing_weights', {})
    top5_param_combos = learned_features.get('top5_param_combos', [])
    
    print("\n  ğŸ“š ã€Phase 2å­¦ä¹ æˆæœåŠ è½½ã€‘")
    print(f"     âš¡ è¶…çŸ­çº¿æœ€ä¼˜æƒé‡: {best_scalping_weights.get('name', 'N/A')}")
    print(f"     ğŸŒŠ æ³¢æ®µæœ€ä¼˜æƒé‡: {best_swing_weights.get('name', 'N/A')}")
    print(f"     ğŸ¯ Top5å‚æ•°ç»„åˆ: {len(top5_param_combos)}ä¸ª")
    
    # ã€æ­¥éª¤2ã€‘ä½¿ç”¨ä¼˜åŒ–æƒé‡é‡æ–°è®¡ç®—signal_score
    print("\n  ğŸ”„ ã€é‡æ–°è®¡ç®—signal_scoreã€‘")
    print("     ä½¿ç”¨Phase 2ä¼˜åŒ–çš„æƒé‡é…ç½®...")
    
    # å¯¼å…¥é‡æ–°è®¡ç®—å‡½æ•°
    sys.path.insert(0, str(Path(__file__).parent))
    from deepseek_å¤šå¸ç§æ™ºèƒ½ç‰ˆ import recalculate_signal_score_from_snapshot
    
    recalc_count = 0
    for opp in all_opportunities:
        signal_type = opp.get('signal_type', 'swing')
        
        # é€‰æ‹©å¯¹åº”çš„æƒé‡é…ç½®
        if signal_type == 'scalping' and best_scalping_weights:
            weight_config = best_scalping_weights.get('weights', {})
        elif signal_type == 'swing' and best_swing_weights:
            weight_config = best_swing_weights.get('weights', {})
        else:
            weight_config = None
        
        # é‡æ–°è®¡ç®—signal_score
        if weight_config:
            # æ„å»ºlearning_configæ ¼å¼
            learning_config = {
                'scalping_weights': best_scalping_weights.get('weights', {}) if signal_type == 'scalping' else {},
                'swing_weights': best_swing_weights.get('weights', {}) if signal_type == 'swing' else {}
            }
            
            new_signal_score = recalculate_signal_score_from_snapshot(
                opp, signal_type, learning_config
            )
            
            # ä¿å­˜æ—§å€¼ï¼ˆè°ƒè¯•ç”¨ï¼‰
            opp['_old_signal_score'] = opp.get('signal_score', 0)
            opp['signal_score'] = new_signal_score
            recalc_count += 1
    
    print(f"     âœ“ é‡æ–°è®¡ç®—: {recalc_count}/{len(all_opportunities)}ä¸ªæœºä¼š")
    
    # ã€æ­¥éª¤3ã€‘ä¸¤é˜¶æ®µå¤šèµ·ç‚¹æœç´¢ï¼ˆæ–¹æ¡ˆCï¼‰
    print("\n  ğŸ¯ ã€ä¸¤é˜¶æ®µå¤šèµ·ç‚¹æœç´¢ã€‘")
    print("     ç­–ç•¥ï¼šå…ˆç²—ç­›æ‰¾Top2èµ·ç‚¹ â†’ å†ç²¾é€‰æœ€ä¼˜å‚æ•°")
    print("     ã€V8.5.2.4.89æ–¹æ¡ˆCã€‘åˆ†å±‚æµ‹è¯•ï¼Œå†…å­˜å³°å€¼æ›´ä½ï¼Œç²¾åº¦æŸå¤±<5%")
    
    # å‡†å¤‡å€™é€‰èµ·ç‚¹ï¼ˆ4ä¸ªï¼‰
    candidate_starting_points = []
    
    # ã€V8.5.2.4.89.24ã€‘ä¿®å¤ï¼šPhase 2ç°åœ¨æ˜¯åˆ†ç¦»ç»“æ„
    # èµ·ç‚¹1: Phase 2è¶…çŸ­çº¿æœ€ä¼˜å‚æ•°
    if phase2_baseline.get('scalping', {}).get('params'):
        candidate_starting_points.append({
            'name': 'Phase2è¶…çŸ­çº¿',
            'params': phase2_baseline['scalping']['params'].copy(),
            'source': 'phase2_scalping'
        })
    
    # èµ·ç‚¹2: Phase 2æ³¢æ®µæœ€ä¼˜å‚æ•°
    if phase2_baseline.get('swing', {}).get('params'):
        candidate_starting_points.append({
            'name': 'Phase2æ³¢æ®µ',
            'params': phase2_baseline['swing']['params'].copy(),
            'source': 'phase2_swing'
        })
    
    # èµ·ç‚¹3-5: Top3ç»„åˆ
    for i, combo in enumerate(top5_param_combos[:3], 1):
        if combo.get('params'):
            candidate_starting_points.append({
                'name': f"Top{i}ç»„åˆ",
                'params': combo['params'].copy(),
                'source': f'top5_{i}'
            })
    
    print(f"     å€™é€‰èµ·ç‚¹: {len(candidate_starting_points)}ä¸ª")
    for sp in candidate_starting_points:
        print(f"       - {sp['name']}")
    
    from backtest_optimizer_v8321 import optimize_params_v8321_lightweight
    import gc
    
    # ========== ç¬¬ä¸€é˜¶æ®µï¼šç²—ç­›ï¼ˆå¿«é€Ÿæ‰¾Top2èµ·ç‚¹ï¼‰==========
    print(f"\n     âš¡ ã€ç¬¬ä¸€é˜¶æ®µï¼šç²—ç­›ã€‘å¿«é€Ÿæµ‹è¯•4ç»„Ã—{len(candidate_starting_points)}èµ·ç‚¹")
    
    coarse_results = []
    
    for i, starting_point in enumerate(candidate_starting_points, 1):
        print(f"        [{i}/{len(candidate_starting_points)}] {starting_point['name']}...")
        
        try:
            # ç²—ç­›ï¼šåªæµ‹è¯•4ç»„å‚æ•°
            search_result = optimize_params_v8321_lightweight(
                opportunities=all_opportunities,
                current_params=starting_point['params'],
                signal_type='swing',
                max_combinations=4  # ã€æ–¹æ¡ˆCã€‘ç²—ç­›åªç”¨4ç»„
            )
            
            if search_result:
                search_result['starting_point'] = starting_point['name']
                search_result['starting_point_params'] = starting_point['params'].copy()
                coarse_results.append(search_result)
                print(f"           âœ“ åˆ©æ¶¦: {search_result.get('total_profit', 0):.1f}%")
            
            gc.collect()
            
        except Exception as e:
            print(f"           âš ï¸  å¤±è´¥: {e}")
    
    # é€‰æ‹©Top2èµ·ç‚¹
    if len(coarse_results) >= 2:
        coarse_results_sorted = sorted(coarse_results, key=lambda x: x.get('total_profit', 0), reverse=True)
        top2_starting_points = coarse_results_sorted[:2]
        print("\n     ğŸ† ç²—ç­›Top2èµ·ç‚¹:")
        for rank, sp in enumerate(top2_starting_points, 1):
            print(f"        {rank}. {sp['starting_point']} (åˆ©æ¶¦: {sp.get('total_profit', 0):.1f}%)")
    elif len(coarse_results) == 1:
        top2_starting_points = coarse_results
        print("\n     âš ï¸  åªæœ‰1ä¸ªæœ‰æ•ˆèµ·ç‚¹ï¼Œå°†åªå¯¹å…¶è¿›è¡Œç²¾é€‰")
    else:
        top2_starting_points = []
        print("\n     âŒ ç²—ç­›æœªæ‰¾åˆ°æœ‰æ•ˆèµ·ç‚¹")
    
    # ========== ç¬¬äºŒé˜¶æ®µï¼šç²¾é€‰ï¼ˆåœ¨Top2èµ·ç‚¹ä¸Šç²¾ç»†æµ‹è¯•ï¼‰==========
    print(f"\n     ğŸ”¬ ã€ç¬¬äºŒé˜¶æ®µï¼šç²¾é€‰ã€‘ç²¾ç»†æµ‹è¯•8ç»„Ã—{len(top2_starting_points)}èµ·ç‚¹")
    
    fine_results = []
    
    for i, starting_point_result in enumerate(top2_starting_points, 1):
        starting_point_name = starting_point_result['starting_point']
        starting_point_params = starting_point_result['starting_point_params']
        
        print(f"        [{i}/{len(top2_starting_points)}] {starting_point_name}...")
        
        try:
            # ç²¾é€‰ï¼šæµ‹è¯•8ç»„å‚æ•°
            search_result = optimize_params_v8321_lightweight(
                opportunities=all_opportunities,
                current_params=starting_point_params,
                signal_type='swing',
                max_combinations=8  # ã€æ–¹æ¡ˆCã€‘ç²¾é€‰ç”¨8ç»„
            )
            
            if search_result:
                search_result['starting_point'] = starting_point_name
                fine_results.append(search_result)
                print(f"           âœ“ åˆ©æ¶¦: {search_result.get('total_profit', 0):.1f}%")
            
            gc.collect()
            
        except Exception as e:
            print(f"           âš ï¸  å¤±è´¥: {e}")
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    all_search_results = coarse_results + fine_results
    
    # é€‰æ‹©æœ€ä½³ç»“æœ
    if fine_results:
        best_search_result = max(fine_results, key=lambda x: x.get('total_profit', 0))
        print(f"\n     ğŸ† æœ€ç»ˆæœ€ä½³èµ·ç‚¹: {best_search_result.get('starting_point')}")
        print(f"        æ€»åˆ©æ¶¦: {best_search_result.get('total_profit', 0):.1f}%")
        print(f"        æ•è·ç‡: {best_search_result.get('capture_rate', 0)*100:.1f}%")
    elif coarse_results:
        best_search_result = max(coarse_results, key=lambda x: x.get('total_profit', 0))
        print(f"\n     âš ï¸  ç²¾é€‰å¤±è´¥ï¼Œä½¿ç”¨ç²—ç­›æœ€ä½³ç»“æœ: {best_search_result.get('starting_point')}")
    else:
        best_search_result = None
        print("\n     âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆç»“æœï¼Œä½¿ç”¨Phase 2å‚æ•°")
    
    print("\n     ğŸ’¾ å†…å­˜ä¼˜åŒ–: åˆ†ä¸¤æ‰¹æ‰§è¡Œï¼Œå³°å€¼é™ä½50%")
    
    # ã€æ­¥éª¤4ã€‘ç»„åˆç­›é€‰çŸ©é˜µæµ‹è¯•
    print("\n  ğŸ“Š ã€ç»„åˆç­›é€‰çŸ©é˜µã€‘")
    print("     æµ‹è¯•ä¸åŒçš„consensus Ã— signal_scoreç»„åˆ")
    
    filter_combinations = [
        {'min_consensus': 1, 'min_signal_score': 75, 'name': 'æå®½æ¾ï¼ˆæœ€å¤§å¬å›ï¼‰'},
        {'min_consensus': 1, 'min_signal_score': 80, 'name': 'å®½æ¾'},
        {'min_consensus': 2, 'min_signal_score': 80, 'name': 'å¹³è¡¡-åå®½'},
        {'min_consensus': 2, 'min_signal_score': 85, 'name': 'å¹³è¡¡'},
        {'min_consensus': 2, 'min_signal_score': 90, 'name': 'å¹³è¡¡-åä¸¥'},
        {'min_consensus': 3, 'min_signal_score': 85, 'name': 'ä¸¥æ ¼-é«˜å…±æŒ¯'},
        {'min_consensus': 3, 'min_signal_score': 90, 'name': 'ä¸¥æ ¼'},
        {'min_consensus': 1, 'min_signal_score': 90, 'name': 'ä¿¡å·åˆ†ä¼˜å…ˆ'},
        {'min_consensus': 3, 'min_signal_score': 80, 'name': 'å…±æŒ¯ä¼˜å…ˆ'},
    ]
    
    # å¯¼å…¥actual_profitè®¡ç®—
    from calculate_actual_profit import calculate_single_actual_profit
    
    matrix_results = []
    
    for combo in filter_combinations:
        # è¿‡æ»¤æœºä¼š
        # ã€V8.5.2.4.47ä¿®å¤ã€‘å­—æ®µåç»Ÿä¸€ä¸ºconsensusï¼ˆPhase 1è®¾ç½®çš„å­—æ®µåï¼‰
        filtered_opps = [
            opp for opp in all_opportunities
            if (opp.get('consensus', 0) >= combo['min_consensus'] and
                opp.get('signal_score', 0) >= combo['min_signal_score'])
        ]
        
        if not filtered_opps:
            continue
        
        # è®¡ç®—actual_profitï¼ˆä½¿ç”¨best_search_resultçš„å‚æ•°ï¼Œå¦‚æœæœ‰ï¼‰
        params = best_search_result.get('params', phase2_baseline.get('params', {})) if best_search_result else phase2_baseline.get('params', {})
        
        for opp in filtered_opps:
            signal_type = opp.get('signal_type', 'swing')
            
            # ã€V8.5.2.4.60ã€‘ä»learned_featuresæå–æœ€ä¼˜TP/SL
            optimal_tp_sl = learned_features.get('optimal_tp_sl', {})
            
            # æ ¹æ®signal_typeä½¿ç”¨æœ€ä¼˜TP/SLï¼ˆä¼˜å…ˆï¼‰æˆ–é»˜è®¤å€¼ï¼ˆé™çº§ï¼‰
            if signal_type == 'scalping':
                scalping_optimal = optimal_tp_sl.get('scalping', {})
                default_tp = scalping_optimal.get('atr_tp_multiplier', 2.0)
                default_sl = scalping_optimal.get('atr_stop_multiplier', 1.5)
                default_holding = 12
            else:
                swing_optimal = optimal_tp_sl.get('swing', {})
                default_tp = swing_optimal.get('atr_tp_multiplier', 6.0)
                default_sl = swing_optimal.get('atr_stop_multiplier', 2.5)
                default_holding = 72
            
            strategy_params = {
                **params,
                'atr_tp_multiplier': params.get('atr_tp_multiplier', default_tp),
                'atr_stop_multiplier': params.get('atr_stop_multiplier', default_sl),
                'max_holding_hours': params.get('max_holding_hours', default_holding)
            }
            
            actual_profit = calculate_single_actual_profit(
                opp,
                strategy_params=strategy_params,
                use_dynamic_atr=False
            )
            opp['_matrix_actual_profit'] = actual_profit
        
        # ç»Ÿè®¡ç»“æœ
        capture_rate = len(filtered_opps) / len(all_opportunities) if all_opportunities else 0
        avg_profit = sum(o.get('_matrix_actual_profit', 0) for o in filtered_opps) / len(filtered_opps) if filtered_opps else 0
        total_profit = sum(o.get('_matrix_actual_profit', 0) for o in filtered_opps)
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        score = total_profit * 0.7 + capture_rate * 100 * 0.3
        
        matrix_results.append({
            'name': combo['name'],
            'min_consensus': combo['min_consensus'],
            'min_signal_score': combo['min_signal_score'],
            'captured_count': len(filtered_opps),
            'capture_rate': capture_rate,
            'avg_profit': avg_profit,
            'total_profit': total_profit,
            'score': score
        })
    
    # æ’åºå¹¶æ˜¾ç¤ºTop 3
    matrix_results_sorted = sorted(matrix_results, key=lambda x: x['score'], reverse=True)
    
    print("\n     ç»„åˆç­›é€‰Top 3:")
    for i, result in enumerate(matrix_results_sorted[:3], 1):
        print(f"       #{i} [{result['name']}]")
        print(f"          consensus>={result['min_consensus']}, signal_score>={result['min_signal_score']}")
        print(f"          æ•è·: {result['captured_count']}ä¸ª ({result['capture_rate']*100:.1f}%)")
        print(f"          å¹³å‡åˆ©æ¶¦: {result['avg_profit']:.2f}%, æ€»åˆ©æ¶¦: {result['total_profit']:.1f}%")
        print(f"          ç»¼åˆå¾—åˆ†: {result['score']:.1f}")
    
    best_matrix_combo = matrix_results_sorted[0] if matrix_results_sorted else None
    
    # ã€æ­¥éª¤5ã€‘AIè¾…åŠ©å†³ç­–
    print("\n  ğŸ¤– ã€AIè¾…åŠ©å†³ç­–ã€‘")
    print("     è¯·æ±‚AIåˆ†ææ•°æ®å¹¶æ¨èæœ€ä¼˜å‚æ•°...")
    
    ai_recommendation = request_ai_analysis(
        all_opportunities=all_opportunities,
        phase1_baseline=phase1_baseline,
        phase2_baseline=phase2_baseline,
        search_results=all_search_results,
        matrix_results=matrix_results_sorted[:5],
        model_name=model_name
    )
    
    # ã€æ­¥éª¤6ã€‘åˆ†ç¦»ä¼˜åŒ–è¶…çŸ­çº¿å’Œæ³¢æ®µ
    print("\n  ğŸ“Š ã€åˆ†ç¦»ä¼˜åŒ–ã€‘")
    print("     åˆ†åˆ«ä¸ºè¶…çŸ­çº¿å’Œæ³¢æ®µå¯»æ‰¾æœ€å¤§åˆ©æ¶¦å‚æ•°...")
    
    # åˆ†ç¦»æœºä¼š
    scalping_opps = [o for o in all_opportunities if o.get('signal_type') == 'scalping']
    swing_opps = [o for o in all_opportunities if o.get('signal_type') == 'swing']
    
    print(f"     è¶…çŸ­çº¿æœºä¼š: {len(scalping_opps)}ä¸ª")
    print(f"     æ³¢æ®µæœºä¼š: {len(swing_opps)}ä¸ª")
    
    # ã€V8.5.2.4.89æ–¹æ¡ˆC+ã€‘åˆ†ç¦»ä¼˜åŒ–ï¼šåªä½¿ç”¨Phase 3æ‰¾åˆ°çš„æœ€ä½³èµ·ç‚¹
    # åŸå› ï¼šä¸¤é˜¶æ®µæœç´¢å·²ç»æ‰¾åˆ°æœ€ä¼˜èµ·ç‚¹ï¼Œåˆ†ç¦»ä¼˜åŒ–åº”è¯¥åœ¨æœ€ä½³èµ·ç‚¹ä¸Šç²¾è°ƒï¼Œè€Œä¸æ˜¯é‡æ–°æœç´¢4ä¸ªèµ·ç‚¹
    best_starting_point_params = best_search_result.get('params') if best_search_result else (candidate_starting_points[0]['params'] if candidate_starting_points else phase2_baseline.get('params'))
    best_starting_point_list = [{'name': 'Phase3æœ€ä½³', 'params': best_starting_point_params, 'source': 'phase3_best'}]
    
    print("\n     ğŸ’¡ ã€å†…å­˜ä¼˜åŒ–ã€‘åˆ†ç¦»ä¼˜åŒ–åªä½¿ç”¨Phase 3æ‰¾åˆ°çš„æœ€ä½³èµ·ç‚¹ï¼ˆ4â†’1èµ·ç‚¹ï¼ŒèŠ‚çœ75%å†…å­˜ï¼‰")
    
    # ä¼˜åŒ–è¶…çŸ­çº¿å‚æ•°
    scalping_result = optimize_for_signal_type(
        opportunities=scalping_opps,
        signal_type='scalping',
        learned_features=learned_features,
        starting_points=best_starting_point_list,  # ã€V8.5.2.4.89ã€‘åªç”¨1ä¸ªæœ€ä½³èµ·ç‚¹
        kline_snapshots=kline_snapshots
    )
    
    # ã€V8.5.2.4.47ã€‘è¶…çŸ­çº¿ä¼˜åŒ–å®Œæˆï¼Œç«‹å³é‡Šæ”¾å†…å­˜
    import gc
    del scalping_opps  # åˆ é™¤å·²ç”¨å®Œçš„è¶…çŸ­çº¿æœºä¼šåˆ—è¡¨
    gc.collect()
    print("     ğŸ’¾ è¶…çŸ­çº¿ä¼˜åŒ–å®Œæˆï¼Œå·²é‡Šæ”¾å†…å­˜")
    
    # ä¼˜åŒ–æ³¢æ®µå‚æ•°
    swing_result = optimize_for_signal_type(
        opportunities=swing_opps,
        signal_type='swing',
        learned_features=learned_features,
        starting_points=best_starting_point_list,  # ã€V8.5.2.4.89ã€‘åªç”¨1ä¸ªæœ€ä½³èµ·ç‚¹
        kline_snapshots=kline_snapshots
    )
    
    print("\n  âœ… Phase 3ä¼˜åŒ–å®Œæˆ")
    print(f"     è¶…çŸ­çº¿: æ•è·ç‡{scalping_result['capture_rate']*100:.1f}%, å¹³å‡åˆ©æ¶¦{scalping_result['avg_profit']:.2f}%")
    print(f"     æ³¢æ®µ: æ•è·ç‡{swing_result['capture_rate']*100:.1f}%, å¹³å‡åˆ©æ¶¦{swing_result['avg_profit']:.2f}%")
    
    # ã€V8.5.2.4.42ã€‘è¿”å›åˆ†ç¦»çš„Phase 3ç»“æœ
    return {
        'scalping': {
            'params': scalping_result['best_params'],
            'capture_rate': scalping_result['capture_rate'],
            'avg_profit': scalping_result['avg_profit'],
            'total_profit': scalping_result['total_profit'],
            'captured_count': scalping_result['captured_count']
        },
        'swing': {
            'params': swing_result['best_params'],
            'capture_rate': swing_result['capture_rate'],
            'avg_profit': swing_result['avg_profit'],
            'total_profit': swing_result['total_profit'],
            'captured_count': swing_result['captured_count']
        },
        'decision_source': 'Multi-start search with trailing stop',
        'learned_features': learned_features,
        'multi_start_search': {
            'starting_points': len(candidate_starting_points),
            'all_results': all_search_results,
            'best_result': best_search_result
        },
        'filter_matrix': {
            'tested_combinations': len(matrix_results),
            'all_results': matrix_results_sorted,
            'best_combo': best_matrix_combo
        },
        'ai_recommendation': ai_recommendation,
        'recalculated_opportunities': len(all_opportunities)
    }


def request_ai_analysis(
    all_opportunities: List[Dict],
    phase1_baseline: Dict,
    phase2_baseline: Dict,
    search_results: List[Dict],
    matrix_results: List[Dict],
    model_name: str
) -> Dict:
    """
    ã€V8.5.2.4.41ã€‘è¯·æ±‚AIåˆ†ææ•°æ®å¹¶æ¨èæœ€ä¼˜å‚æ•°
    
    ç»Ÿä¸€AIè°ƒç”¨æ¥å£ï¼Œæ”¯æŒdeepseekå’Œqwen
    ä½¿ç”¨è‹±æ–‡ä¸AIæ²Ÿé€šä»¥è·å¾—æ›´å¥½çš„æ¨ç†èƒ½åŠ›
    
    Args:
        all_opportunities: æ‰€æœ‰æœºä¼š
        phase1_baseline: Phase 1åŸºçº¿
        phase2_baseline: Phase 2åŸºçº¿
        search_results: å¤šèµ·ç‚¹æœç´¢ç»“æœ
        matrix_results: çŸ©é˜µç­›é€‰ç»“æœ
        model_name: æ¨¡å‹åç§° ("deepseek" æˆ– "qwen")
    
    Returns:
        ai_recommendation: AIæ¨èç»“æœ
    """
    try:
        # æ„å»ºAIæç¤ºè¯ï¼ˆè‹±æ–‡ï¼‰
        prompt = build_ai_analysis_prompt(
            all_opportunities, phase1_baseline, phase2_baseline,
            search_results, matrix_results
        )
        
        # ç»Ÿä¸€AIè°ƒç”¨é€»è¾‘
        ai_response = call_ai_unified(prompt, model_name)
        
        # è§£æAIå“åº”
        recommendation = parse_ai_recommendation(ai_response)
        
        print("     âœ“ AI Analysis Completed")
        print(f"     Recommended Strategy: {recommendation.get('strategy', 'N/A')}")
        print(f"     Reason: {recommendation.get('reason', 'N/A')[:80]}...")
        
        return recommendation
        
    except Exception as e:
        # ã€V8.5.2.4.89.2ã€‘æ›´å‹å¥½çš„é”™è¯¯æç¤º
        if "API key not found" in str(e):
            print("     â„¹ï¸  AIè¾…åŠ©å†³ç­–å·²è·³è¿‡ï¼ˆæœªé…ç½®APIå¯†é’¥ï¼‰")
            print("     ğŸ’¡ å·²ä½¿ç”¨Phase 2+3æ•°æ®é©±åŠ¨çš„æœ€ä¼˜å‚æ•°ï¼Œæ•ˆæœç­‰åŒæˆ–æ›´å¥½")
        else:
            print(f"     âš ï¸  AI Call Failed: {e}")
        return {}


def call_ai_unified(prompt: str, model_name: str) -> str:
    """
    ã€V8.5.2.4.41ã€‘ç»Ÿä¸€AIè°ƒç”¨æ¥å£
    
    æ”¯æŒdeepseekå’Œqwenï¼Œä½¿ç”¨ç›¸åŒçš„APIè°ƒç”¨é€»è¾‘
    
    Args:
        prompt: è‹±æ–‡æç¤ºè¯
        model_name: æ¨¡å‹åç§°
    
    Returns:
        ai_response: AIå“åº”æ–‡æœ¬
    """
    import os
    import requests
    
    # æ ¹æ®æ¨¡å‹é€‰æ‹©APIé…ç½®
    if model_name == "deepseek":
        api_key = os.getenv("DEEPSEEK_API_KEY")
        api_url = "https://api.deepseek.com/v1/chat/completions"
        model_id = "deepseek-reasoner"
        max_tokens = 8000  # DeepSeekæ”¯æŒæ›´é«˜é™åˆ¶
    else:  # qwen
        api_key = os.getenv("DASHSCOPE_API_KEY")
        api_url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
        model_id = "qwen-plus"
        max_tokens = 2000  # Qwen-pluså®˜æ–¹é™åˆ¶ä¸º2000
    
    if not api_key:
        raise ValueError(f"API key not found for {model_name}")
    
    # æ„å»ºè¯·æ±‚
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": model_id,
        "messages": [
            {
                "role": "system",
                "content": "You are an expert trading system optimizer. Analyze data and provide recommendations in JSON format. Always respond in English."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": max_tokens
    }
    
    # å‘é€è¯·æ±‚ï¼ˆPhase3æ•°æ®é‡å¤§ï¼Œéœ€è¦æ›´é•¿è¶…æ—¶ï¼‰
    response = requests.post(api_url, headers=headers, json=payload, timeout=60)
    response.raise_for_status()
    
    # è§£æå“åº”
    result = response.json()
    ai_response = result["choices"][0]["message"]["content"]
    
    return ai_response


def build_ai_analysis_prompt(
    all_opportunities: List[Dict],
    phase1_baseline: Dict,
    phase2_baseline: Dict,
    search_results: List[Dict],
    matrix_results: List[Dict]
) -> str:
    """
    Build AI analysis prompt in English
    
    English prompts provide better reasoning capabilities for AI models
    """
    
    # Statistics
    total_opps = len(all_opportunities)
    scalping_count = sum(1 for o in all_opportunities if o.get('signal_type') == 'scalping')
    swing_count = total_opps - scalping_count
    
    # Consensus distribution
    consensus_dist: Dict[int, int] = {}
    for opp in all_opportunities:
        c = opp.get('consensus', 0)  # ã€V8.5.2.4.47ä¿®å¤ã€‘å­—æ®µåç»Ÿä¸€
        consensus_dist[c] = consensus_dist.get(c, 0) + 1
    
    # Signal score distribution
    signal_score_ranges = {'0-70': 0, '70-80': 0, '80-90': 0, '90-100': 0}
    for opp in all_opportunities:
        score = opp.get('signal_score', 0)
        if score < 70:
            signal_score_ranges['0-70'] += 1
        elif score < 80:
            signal_score_ranges['70-80'] += 1
        elif score < 90:
            signal_score_ranges['80-90'] += 1
        else:
            signal_score_ranges['90-100'] += 1
    
    # ã€V8.5.2.4.83ã€‘ä»learned_featuresæå–å¯†åº¦ä¿¡æ¯
    learned_features = phase2_baseline.get('learned_features', {})
    
    prompt = f"""As a trading system optimization expert, please analyze the following data and recommend optimal parameter configuration.

ã€Phase 1 Objective Statisticsã€‘
- Total Opportunities: {total_opps}
- Scalping: {scalping_count} (density: {learned_features.get('scalping_avg_density', 'N/A')}, profit: {learned_features.get('scalping_avg_profit', 'N/A')}%, holding: {learned_features.get('scalping_real_holding_hours', 'N/A')}h)
- Swing: {swing_count} (density: {learned_features.get('swing_avg_density', 'N/A')}, profit: {learned_features.get('swing_avg_profit', 'N/A')}%, holding: {learned_features.get('swing_real_holding_hours', 'N/A')}h)
- Density Threshold: {learned_features.get('high_density_threshold', 'N/A')} (>thresholdâ†’Scalping, â‰¤thresholdâ†’Swing)

ã€Phase 2 Learning Resultsã€‘
- Capture Rate: {phase2_baseline.get('capture_rate', 0)*100:.1f}%, Avg Profit: {phase2_baseline.get('avg_profit', 0):.2f}%

ã€Data Distributionã€‘
Consensus Distribution: {consensus_dist}
Signal Score Distribution: {signal_score_ranges}

ã€Multi-Start Search Resultsã€‘(Top 3)
"""
    
    for i, result in enumerate(search_results[:3], 1):
        prompt += f"""
{i}. Starting Point: {result.get('starting_point', 'N/A')}
   Total Profit: {result.get('total_profit', 0):.1f}%
   Capture Rate: {result.get('capture_rate', 0)*100:.1f}%
   Params: consensus>={result.get('params', {}).get('min_indicator_consensus', 'N/A')}, 
           signal_score>={result.get('params', {}).get('min_signal_score', 'N/A')}
"""
    
    prompt += """
ã€Filter Matrix Resultsã€‘(Top 3)
"""
    
    for i, result in enumerate(matrix_results[:3], 1):
        prompt += f"""
{i}. {result.get('name', 'N/A')}
   consensus>={result['min_consensus']}, signal_score>={result['min_signal_score']}
   Capture Rate: {result['capture_rate']*100:.1f}%
   Avg Profit: {result['avg_profit']:.2f}%
   Total Profit: {result['total_profit']:.1f}%
   Composite Score: {result['score']:.1f}
"""
    
    prompt += """
ã€Questionsã€‘
1. Comprehensive Evaluation: Which configuration is optimal and why?
2. Parameter Recommendation: What are the recommended min_consensus and min_signal_score?
3. Risk Warning: What are the potential risks of this configuration?

Please respond in JSON format (English):
{
    "recommended_params": {
        "min_indicator_consensus": <number>,
        "min_signal_score": <number>,
        "min_risk_reward": <number>
    },
    "strategy": "<brief description>",
    "reason": "<detailed reasoning>",
    "risks": "<potential risks>"
}
"""
    
    return prompt


def parse_ai_recommendation(ai_response: str) -> Dict:
    """è§£æAIæ¨èå“åº”"""
    try:
        # å°è¯•æå–JSON
        import re
        json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
        if json_match:
            recommendation = json.loads(json_match.group())
            return recommendation
        else:
            # æ— æ³•æå–JSONï¼Œè¿”å›ç©º
            return {}
    except Exception as e:
        print(f"âš ï¸  è§£æAIå“åº”å¤±è´¥: {e}")
        return {}


def optimize_for_signal_type(
    opportunities: List[Dict],
    signal_type: str,
    learned_features: Dict,
    starting_points: List[Dict],
    kline_snapshots=None
) -> Dict:
    """
    ã€V8.5.2.4.42ã€‘ä¸ºç‰¹å®šä¿¡å·ç±»å‹ä¼˜åŒ–å‚æ•°
    
    åˆ†åˆ«ä¸ºè¶…çŸ­çº¿å’Œæ³¢æ®µå¯»æ‰¾æœ€ä¼˜å‚æ•°é…ç½®ï¼ˆåŒ…æ‹¬ç§»åŠ¨æ­¢æŸï¼‰
    
    Args:
        opportunities: è¯¥ä¿¡å·ç±»å‹çš„æœºä¼šåˆ—è¡¨
        signal_type: 'scalping' æˆ– 'swing'
        learned_features: Phase 2å­¦ä¹ çš„ç‰¹å¾
        starting_points: å€™é€‰èµ·ç‚¹åˆ—è¡¨
        kline_snapshots: å¸‚åœºå¿«ç…§æ•°æ®
    
    Returns:
        result: {
            'best_params': {...},
            'capture_rate': float,
            'avg_profit': float,
            'total_profit': float,
            'captured_count': int
        }
    """
    # ã€V8.5.2.4.69ã€‘ä½¿ç”¨calculate_actual_profit_batchè€Œä¸æ˜¯batch_calculate_profits
    # åŸå› : batch_calculate_profitsä¼šèµ°åˆ°æ¨¡æ‹Ÿé€»è¾‘_calculate_with_max_profit
    #       è€Œæ²¡æœ‰ä½¿ç”¨V8.5.2.4.65çš„æ³¢åŠ¨å¹…åº¦ä¿®å¤
    from calculate_actual_profit import calculate_actual_profit_batch
    import gc
    
    print(f"\n  ğŸ¯ ã€{signal_type.upper()}å‚æ•°ä¼˜åŒ–ã€‘")
    print(f"     æœºä¼šæ•°é‡: {len(opportunities)}ä¸ª")
    
    # ã€V8.5.2.4.47ã€‘å†…å­˜ä¼˜åŒ–ï¼šå¯¹å¤§é‡æœºä¼šè¿›è¡Œé‡‡æ ·
    if len(opportunities) > 1000:
        import random
        sample_size = 1000
        sampled_opportunities = random.sample(opportunities, sample_size)
        print(f"     ğŸ’¾ å†…å­˜ä¼˜åŒ–ï¼šé‡‡æ ·{sample_size}ä¸ªæœºä¼šï¼ˆä¿ç•™{sample_size/len(opportunities)*100:.1f}%ï¼‰")
        opportunities = sampled_opportunities
        gc.collect()
    
    # ã€V8.5.2.4.49ã€‘åŸºäºåˆ©æ¶¦å¯†åº¦åŠ¨æ€è°ƒæ•´å‚æ•°æœç´¢ç©ºé—´
    # æ ¸å¿ƒç†å¿µï¼šé«˜å¯†åº¦â†’å¿«è¿›å¿«å‡ºï¼Œä½å¯†åº¦â†’é•¿æœŸæŒæœ‰
    
    import numpy as np
    
    # æå–è¯¥ç±»å‹çš„å¹³å‡å¯†åº¦å’ŒæŒä»“æ—¶é—´
    densities = [o.get('profit_density', 0) for o in opportunities if o.get('profit_density', 0) > 0]
    holding_hours_list = [o.get('holding_hours', 0) for o in opportunities if o.get('holding_hours', 0) > 0]
    avg_profit = np.mean([o.get('objective_profit', 0) for o in opportunities]) if opportunities else 15.0
    
    avg_density = np.mean(densities) if densities else (10.0 if signal_type == 'scalping' else 1.0)
    avg_holding = np.mean(holding_hours_list) if holding_hours_list else (4.0 if signal_type == 'scalping' else 20.0)
    
    print(f"     ğŸ’¡ {signal_type}ç‰¹å¾: å¯†åº¦{avg_density:.1f}, æŒä»“{avg_holding:.1f}h, å¹³å‡åˆ©æ¶¦{avg_profit:.1f}%")
    
    # ã€V8.5.2.4.68ã€‘ä»learned_featuresæå–Phase 2æµ‹è¯•çš„æœ€ä¼˜TP/SL
    # Phase 3ç›®æ ‡ï¼šå›ºå®šTP/SLï¼Œä¼˜åŒ–ç­›é€‰æ¡ä»¶ï¼ˆå»æ‰æ‚éŸ³ï¼Œæé«˜å¹³å‡åˆ©æ¶¦ï¼‰
    optimal_tp_sl = learned_features.get('optimal_tp_sl', {})
    
    if signal_type == 'scalping':
        # ã€V8.5.2.4.68ã€‘å›ºå®šPhase 2æœ€ä¼˜TP/SLï¼Œé‡ç‚¹æµ‹è¯•ç­›é€‰æ¡ä»¶
        scalping_optimal = optimal_tp_sl.get('scalping', {})
        optimal_tp = scalping_optimal.get('atr_tp_multiplier', 12.0)  # Phase 2æ‰¾åˆ°çš„æœ€ä¼˜å€¼
        optimal_sl = scalping_optimal.get('atr_stop_multiplier', 2.0)
        
        # ã€V8.5.2.4.74ã€‘8ç»´åº¦ç­›é€‰å¯é€‰åŒ–
        # ä»learned_featuresæˆ–å…¨å±€é…ç½®ä¸­è·å–ï¼ˆé»˜è®¤å…³é—­ï¼‰
        enable_advanced_filters = learned_features.get('enable_advanced_filters', False)
        
        # ã€V8.5.2.4.75ã€‘Phase 3è¿›ä¸€æ­¥æ”¾å®½ç­›é€‰ + æé«˜TP + å¼ºåˆ¶ç§»åŠ¨æ­¢æŸ
        # ç›®æ ‡ï¼šåœ¨Phase 2åŸºç¡€ä¸Šæé«˜åˆ©æ¶¦ï¼ˆå½“å‰6.46% â†’ ç›®æ ‡10-15%ï¼‰
        # ã€V8.5.2.4.89ã€‘å†…å­˜ä¼˜åŒ–ï¼šå‡å°‘æµ‹è¯•ç»„åˆæ•°ï¼ˆ108â†’18ï¼‰
        # ç­–ç•¥ï¼šä¿ç•™æ ¸å¿ƒç»´åº¦ + å‡å°‘æ¡£ä½
        param_grid = {
            # æ ¸å¿ƒç­›é€‰æ¡ä»¶ï¼ˆå‡å°‘æ¡£ä½ï¼‰
            'min_indicator_consensus': [1],                  # å…±æŒ¯åº¦ï¼ˆåªä¿ç•™æœ€å®½æ¾ï¼‰
            'min_signal_score': [60, 75],                    # ä¿¡å·åˆ†ï¼ˆ2æ¡£ï¼šå®½æ¾+æ ‡å‡†ï¼‰
            
            # è´¨é‡æ§åˆ¶æ¡ä»¶ï¼ˆå‡å°‘æ¡£ä½ï¼‰
            'min_risk_reward': [1.0],                        # R:Rï¼ˆåªä¿ç•™æœ€å®½æ¾ï¼‰
            'min_profit_density': [4.0, 6.0],                # åˆ©æ¶¦å¯†åº¦ï¼ˆ2æ¡£ï¼‰
            
            # TP/SLä¼˜åŒ–ï¼ˆå‡å°‘æ¡£ä½ï¼‰
            'atr_tp_multiplier': [optimal_tp, optimal_tp * 1.5],  # TPï¼ˆ2æ¡£ï¼šæ ‡å‡†+æ‰©å¤§ï¼‰
            'atr_stop_multiplier': [optimal_sl],
            'max_holding_hours': [int(avg_holding)],
        }
        # è®¡ç®—ï¼š1Ã—2Ã—1Ã—2Ã—2 = 8ç»„/èµ·ç‚¹ï¼Œ4èµ·ç‚¹ = 32ç»„æ€»è®¡
        
        
        # ã€V8.5.2.4.76ã€‘è°ƒæ•´trailing stopå‚æ•°ï¼ˆè®©åˆ©æ¶¦æœ‰æ›´å¤šç©ºé—´ï¼‰
        if enable_advanced_filters:
            param_grid.update({
                'require_strong_pattern': [False, True],
                'min_trend_strength': ['any', 'normal', 'strong'],
                'require_near_sr': [False, True],
                'trailing_stop_enabled': [False, True],
                'trailing_stop_activation': [1.0, 2.0],  # æé«˜æ¿€æ´»é˜ˆå€¼ï¼ˆ0.5â†’2.0ï¼‰
                'trailing_stop_distance': [1.5, 2.0],    # æé«˜è·Ÿè¸ªè·ç¦»ï¼ˆ1.0â†’1.5ï¼‰
            })
            print("     ğŸ¨ ã€V8.5.2.4.76ã€‘é«˜çº§ç­›é€‰å·²å¯ç”¨ï¼ˆ8ç»´åº¦æ¢ç´¢+ç§»åŠ¨æ­¢æŸï¼‰")
        else:
            param_grid.update({
                'require_strong_pattern': [False],
                'min_trend_strength': ['any'],
                'require_near_sr': [False],
                'trailing_stop_enabled': [True],
                'trailing_stop_activation': [2.0],  # æé«˜æ¿€æ´»é˜ˆå€¼ï¼ˆç›ˆåˆ©2å€ATRæ—¶å¯åŠ¨ï¼‰
                'trailing_stop_distance': [1.5],    # æé«˜è·Ÿè¸ªè·ç¦»ï¼ˆå›æ’¤1.5å€ATRè§¦å‘ï¼‰
            })
            print("     ğŸ¯ ã€V8.5.2.4.76ã€‘ä½¿ç”¨æ ‡å‡†ç­›é€‰+ç§»åŠ¨æ­¢æŸï¼ˆ5ç»´åº¦ï¼šåŸºç¡€+è´¨é‡+TPï¼‰")
        
        print(f"     ğŸ“ åŸºç¡€æ¡ä»¶: scoreâ‰¥{param_grid['min_signal_score']}, consensusâ‰¥{param_grid['min_indicator_consensus']}")
        print(f"     ğŸ’¡ è´¨é‡æ§åˆ¶: R:Râ‰¥{param_grid['min_risk_reward']}, å¯†åº¦â‰¥{param_grid['min_profit_density']}")
        print(f"     ğŸ¯ TPæ‰©å¤§ï¼ˆ+25%/+50%ï¼‰: èŒƒå›´[{optimal_tp:.1f}, {optimal_tp*1.25:.1f}, {optimal_tp*1.5:.1f}], SL={optimal_sl:.1f}")
        print(f"     ğŸš€ ç›®æ ‡ï¼š{'å…¨ç»´åº¦ç­›é€‰' if enable_advanced_filters else 'å¤§å¹…æ”¾å®½ç­›é€‰+æé«˜TP+å¼ºåˆ¶ç§»åŠ¨æ­¢æŸ'}ï¼Œæé«˜å¹³å‡åˆ©æ¶¦ï¼ˆå½“å‰6.46% â†’ ç›®æ ‡10-15%ï¼‰")
    else:  # swing
        # ã€V8.5.2.4.68ã€‘å›ºå®šPhase 2æœ€ä¼˜TP/SLï¼Œé‡ç‚¹æµ‹è¯•ç­›é€‰æ¡ä»¶
        swing_optimal = optimal_tp_sl.get('swing', {})
        optimal_tp = swing_optimal.get('atr_tp_multiplier', 18.0)  # Phase 2æ‰¾åˆ°çš„æœ€ä¼˜å€¼
        optimal_sl = swing_optimal.get('atr_stop_multiplier', 2.5)
        
        # ã€V8.5.2.4.74ã€‘8ç»´åº¦ç­›é€‰å¯é€‰åŒ–
        # ä»learned_featuresæˆ–å…¨å±€é…ç½®ä¸­è·å–ï¼ˆé»˜è®¤å…³é—­ï¼‰
        enable_advanced_filters = learned_features.get('enable_advanced_filters', False)
        
        # ã€V8.5.2.4.75ã€‘Phase 3è¿›ä¸€æ­¥æ”¾å®½ç­›é€‰ + æé«˜TP + å¼ºåˆ¶ç§»åŠ¨æ­¢æŸ
        # ç›®æ ‡ï¼šåœ¨Phase 2åŸºç¡€ä¸Šæé«˜åˆ©æ¶¦ï¼ˆå½“å‰6.49% â†’ ç›®æ ‡10-15%ï¼‰
        # ã€V8.5.2.4.89ã€‘å†…å­˜ä¼˜åŒ–ï¼šå‡å°‘æµ‹è¯•ç»„åˆæ•°ï¼ˆ108â†’18ï¼‰
        # ç­–ç•¥ï¼šä¿ç•™æ ¸å¿ƒç»´åº¦ + å‡å°‘æ¡£ä½
        param_grid = {
            # æ ¸å¿ƒç­›é€‰æ¡ä»¶ï¼ˆå‡å°‘æ¡£ä½ï¼‰
            'min_indicator_consensus': [1],                  # å…±æŒ¯åº¦ï¼ˆåªä¿ç•™æœ€å®½æ¾ï¼‰
            'min_signal_score': [65, 80],                    # ä¿¡å·åˆ†ï¼ˆ2æ¡£ï¼šå®½æ¾+æ ‡å‡†ï¼‰
            
            # è´¨é‡æ§åˆ¶æ¡ä»¶ï¼ˆå‡å°‘æ¡£ä½ï¼‰
            'min_risk_reward': [1.0],                        # R:Rï¼ˆåªä¿ç•™æœ€å®½æ¾ï¼‰
            'min_profit_density': [0.2, 0.5],                # åˆ©æ¶¦å¯†åº¦ï¼ˆ2æ¡£ï¼‰
            
            # TP/SLä¼˜åŒ–ï¼ˆå‡å°‘æ¡£ä½ï¼‰
            'atr_tp_multiplier': [optimal_tp, optimal_tp * 1.5],  # TPï¼ˆ2æ¡£ï¼šæ ‡å‡†+æ‰©å¤§ï¼‰
            'atr_stop_multiplier': [optimal_sl],
            'max_holding_hours': [int(avg_holding)],
        }
        # è®¡ç®—ï¼š1Ã—2Ã—1Ã—2Ã—2 = 8ç»„/èµ·ç‚¹ï¼Œ4èµ·ç‚¹ = 32ç»„æ€»è®¡
        
        
        # ã€V8.5.2.4.76ã€‘è°ƒæ•´trailing stopå‚æ•°ï¼ˆè®©åˆ©æ¶¦æœ‰æ›´å¤šç©ºé—´ï¼‰
        if enable_advanced_filters:
            param_grid.update({
                'require_strong_pattern': [False, True],
                'min_trend_strength': ['any', 'normal', 'strong'],
                'require_near_sr': [False, True],
                'trailing_stop_enabled': [False, True],
                'trailing_stop_activation': [1.0, 2.0],  # æé«˜æ¿€æ´»é˜ˆå€¼ï¼ˆ0.5â†’2.0ï¼‰
                'trailing_stop_distance': [1.5, 2.0],    # æé«˜è·Ÿè¸ªè·ç¦»ï¼ˆ1.0â†’1.5ï¼‰
            })
            print("     ğŸ¨ ã€V8.5.2.4.76ã€‘é«˜çº§ç­›é€‰å·²å¯ç”¨ï¼ˆ8ç»´åº¦æ¢ç´¢+ç§»åŠ¨æ­¢æŸï¼‰")
        else:
            param_grid.update({
                'require_strong_pattern': [False],
                'min_trend_strength': ['any'],
                'require_near_sr': [False],
                'trailing_stop_enabled': [True],
                'trailing_stop_activation': [2.0],  # æé«˜æ¿€æ´»é˜ˆå€¼ï¼ˆç›ˆåˆ©2å€ATRæ—¶å¯åŠ¨ï¼‰
                'trailing_stop_distance': [1.5],    # æé«˜è·Ÿè¸ªè·ç¦»ï¼ˆå›æ’¤1.5å€ATRè§¦å‘ï¼‰
            })
            print("     ğŸ¯ ã€V8.5.2.4.76ã€‘ä½¿ç”¨æ ‡å‡†ç­›é€‰+ç§»åŠ¨æ­¢æŸï¼ˆ5ç»´åº¦ï¼šåŸºç¡€+è´¨é‡+TPï¼‰")
        
        print(f"     ğŸ“ åŸºç¡€æ¡ä»¶: scoreâ‰¥{param_grid['min_signal_score']}, consensusâ‰¥{param_grid['min_indicator_consensus']}")
        print(f"     ğŸ’¡ è´¨é‡æ§åˆ¶: R:Râ‰¥{param_grid['min_risk_reward']}, å¯†åº¦â‰¥{param_grid['min_profit_density']}")
        print(f"     ğŸ¯ TPæ‰©å¤§ï¼ˆ+27%/+59%ï¼‰: èŒƒå›´[{optimal_tp:.1f}, {optimal_tp*1.27:.1f}, {optimal_tp*1.59:.1f}], SL={optimal_sl:.1f}")
        print(f"     ğŸš€ ç›®æ ‡ï¼š{'å…¨ç»´åº¦ç­›é€‰' if enable_advanced_filters else 'å¤§å¹…æ”¾å®½ç­›é€‰+æé«˜TP+å¼ºåˆ¶ç§»åŠ¨æ­¢æŸ'}ï¼Œæé«˜å¹³å‡åˆ©æ¶¦ï¼ˆå½“å‰6.49% â†’ ç›®æ ‡10-15%ï¼‰")
    
    # å¤šèµ·ç‚¹æœç´¢
    all_results = []
    
    for sp_idx, starting_point in enumerate(starting_points, 1):
        print(f"     [{sp_idx}/{len(starting_points)}] ä»'{starting_point['name']}'å‡ºå‘...")
        
        # ã€V8.5.2.4.68ã€‘ç”Ÿæˆæµ‹è¯•ç»„åˆï¼šsignal_score Ã— consensus Ã— min_risk_reward
        # ç”±äºTP/SLå·²å›ºå®šï¼Œé‡ç‚¹æµ‹è¯•ç­›é€‰æ¡ä»¶ç»„åˆ
        test_combinations = []
        
        # ã€V8.5.2.4.75ã€‘æµ‹è¯•æ‰€æœ‰ç­›é€‰æ¡ä»¶ç»„åˆï¼ˆ8ç»´åº¦+ç§»åŠ¨æ­¢æŸï¼‰
        for consensus in param_grid['min_indicator_consensus']:  # type: ignore[attr-defined]
            for signal_score in param_grid['min_signal_score']:  # type: ignore[attr-defined]
                for risk_reward in param_grid['min_risk_reward']:  # type: ignore[attr-defined]
                    for profit_density in param_grid['min_profit_density']:  # type: ignore[attr-defined]
                        for require_pattern in param_grid['require_strong_pattern']:  # type: ignore[attr-defined]
                            for trend_strength in param_grid['min_trend_strength']:  # type: ignore[attr-defined]
                                for require_sr in param_grid['require_near_sr']:  # type: ignore[attr-defined]
                                    for tp_multiplier in param_grid['atr_tp_multiplier']:  # type: ignore[attr-defined]
                                        for trailing_stop in param_grid['trailing_stop_enabled']:  # type: ignore[attr-defined]
                                            for ts_activation in param_grid['trailing_stop_activation']:  # type: ignore[attr-defined]
                                                for ts_distance in param_grid['trailing_stop_distance']:  # type: ignore[attr-defined]
                                                    test_params = {
                                                        'min_indicator_consensus': consensus,
                                                        'min_signal_score': signal_score,
                                                        'min_risk_reward': risk_reward,
                                                        'min_profit_density': profit_density,
                                                        'require_strong_pattern': require_pattern,
                                                        'min_trend_strength': trend_strength,
                                                        'require_near_sr': require_sr,
                                                        'atr_tp_multiplier': tp_multiplier,
                                                        'atr_stop_multiplier': param_grid['atr_stop_multiplier'][0],  # type: ignore[index]
                                                        'max_holding_hours': param_grid['max_holding_hours'][0],  # type: ignore[index]
                                                        'trailing_stop_enabled': trailing_stop,
                                                        'trailing_stop_activation': ts_activation,  # ã€V8.5.2.4.75ã€‘æ–°å¢
                                                        'trailing_stop_distance': ts_distance       # ã€V8.5.2.4.75ã€‘æ–°å¢
                                                    }
                                                    test_combinations.append(test_params)
        
        # ã€V8.5.2.4.75ã€‘æµ‹è¯•ç»„åˆæ•°é‡ï¼š3Ã—3Ã—2Ã—3Ã—2Ã—3Ã—2Ã—3Ã—1=1944ç»„ï¼ˆ8ç»´åº¦+ç§»åŠ¨æ­¢æŸï¼‰
        # ç»´åº¦ï¼šscoreÃ—consensusÃ—R:RÃ—å¯†åº¦Ã—Kçº¿å½¢æ€Ã—è¶‹åŠ¿å¼ºåº¦Ã—S/RÃ—TPÃ—trailing_stop
        # æ³¨æ„ï¼štrailing_stop_enabledé»˜è®¤åªæœ‰[True]ï¼Œæ‰€ä»¥ç»„åˆæ•°ä¸å˜
        print(f"     ğŸ“Š æµ‹è¯•ç»„åˆæ•°: {len(test_combinations)}ç»„ (8ç»´åº¦ï¼šåŸºç¡€+å½¢æ€+è¶‹åŠ¿+S/R+TP+ç§»åŠ¨æ­¢æŸ)")
        
        # æµ‹è¯•æ¯ä¸ªç»„åˆ
        best_for_this_start = None
        for params in test_combinations:
            # ã€V8.5.2.4.73ã€‘å…¨ç»´åº¦æ™ºèƒ½ç­›é€‰ï¼šåŸºç¡€æ¡ä»¶ + Kçº¿å½¢æ€ + è¶‹åŠ¿å¼ºåº¦ + æ”¯æ’‘é˜»åŠ›
            filtered_opps = []
            for opp in opportunities:
                # åŸºç¡€æ¡ä»¶
                if opp.get('consensus', 0) < params['min_indicator_consensus']:
                    continue
                if opp.get('signal_score', 0) < params['min_signal_score']:
                    continue
                if opp.get('risk_reward', 0) < params.get('min_risk_reward', 0):
                    continue
                if opp.get('profit_density', 0) < params.get('min_profit_density', 0):
                    continue
                
                # ã€V8.5.2.4.73ã€‘Kçº¿å½¢æ€ç­›é€‰
                if params.get('require_strong_pattern', False):
                    snapshot = opp.get('snapshot', {})
                    has_pin_bar = snapshot.get('has_pin_bar', False)
                    has_engulfing = snapshot.get('has_engulfing', False)
                    has_breakout = snapshot.get('has_breakout', False)
                    if not (has_pin_bar or has_engulfing or has_breakout):
                        continue  # å¿…é¡»æœ‰å¼ºKçº¿å½¢æ€
                
                # ã€V8.5.2.4.73ã€‘è¶‹åŠ¿å¼ºåº¦ç­›é€‰
                min_strength = params.get('min_trend_strength', 'any')
                if min_strength != 'any':
                    snapshot = opp.get('snapshot', {})
                    trend_4h_strength = snapshot.get('trend_4h_strength', 'weak')
                    if min_strength == 'strong' and trend_4h_strength != 'strong':
                        continue  # å¿…é¡»æ˜¯å¼ºåŠ¿è¶‹åŠ¿
                    elif min_strength == 'normal' and trend_4h_strength == 'weak':
                        continue  # è‡³å°‘æœ‰æ­£å¸¸è¶‹åŠ¿
                
                # ã€V8.5.2.4.73ã€‘æ”¯æ’‘/é˜»åŠ›ä½ç­›é€‰
                if params.get('require_near_sr', False):
                    snapshot = opp.get('snapshot', {})
                    # æ£€æŸ¥ä»·æ ¼æ˜¯å¦åœ¨S/Rçš„Â±3%èŒƒå›´å†…
                    current_price = snapshot.get('current_price', 0)
                    if current_price > 0:
                        sr = snapshot.get('support_resistance', {})
                        nearest_support = sr.get('nearest_support') or {}
                        nearest_resistance = sr.get('nearest_resistance') or {}
                        support_price = nearest_support.get('price', 0)
                        resistance_price = nearest_resistance.get('price', 0)
                        
                        near_support = support_price > 0 and abs(current_price - support_price) / current_price < 0.03
                        near_resistance = resistance_price > 0 and abs(current_price - resistance_price) / current_price < 0.03
                        
                        if not (near_support or near_resistance):
                            continue  # å¿…é¡»é è¿‘S/R
                
                # é€šè¿‡æ‰€æœ‰ç­›é€‰æ¡ä»¶
                filtered_opps.append(opp)
            
            if not filtered_opps:
                continue
            
            # ã€V8.5.2.4.69ã€‘ä½¿ç”¨calculate_actual_profit_batchè®¡ç®—åˆ©æ¶¦
            # å®ƒä¼šä½¿ç”¨future_dataå’ŒV8.5.2.4.65çš„æ³¢åŠ¨å¹…åº¦ä¿®å¤
            profit_results = calculate_actual_profit_batch(
                filtered_opps, 
                params, 
                batch_size=1000, 
                use_dynamic_atr=True, 
                include_trading_costs=True
            )
            
            # ç»Ÿè®¡
            captured_count = len(profit_results)
            capture_rate = captured_count / len(opportunities) if opportunities else 0
            # ã€V8.5.2.4.69ã€‘ä¿®å¤ï¼šå­—æ®µååº”ä¸ºactual_profit_pctï¼ˆcalculate_actual_profit_batchè¿”å›çš„å­—æ®µåï¼‰
            total_profit = sum(r.get('actual_profit_pct', 0) for r in profit_results)
            avg_profit = total_profit / captured_count if captured_count > 0 else 0
            
            # ã€V8.5.2.4.47ã€‘åªä¿å­˜å½“å‰èµ·ç‚¹çš„æœ€ä½³ç»“æœ
            if best_for_this_start is None or total_profit > best_for_this_start['total_profit']:
                best_for_this_start = {
                    'params': params,
                    'starting_point': starting_point['name'],
                    'captured_count': captured_count,
                    'capture_rate': capture_rate,
                    'avg_profit': avg_profit,
                    'total_profit': total_profit
                }
        
        # ã€V8.5.2.4.47ã€‘æ¯ä¸ªèµ·ç‚¹æµ‹è¯•å®Œåç«‹å³ä¿å­˜æœ€ä½³ç»“æœå¹¶é‡Šæ”¾å†…å­˜
        if best_for_this_start:
            all_results.append(best_for_this_start)
        gc.collect()  # ç«‹å³é‡Šæ”¾å†…å­˜
    
    if not all_results:
        print("     âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆç»“æœï¼ˆæ‰€æœ‰å‚æ•°ç»„åˆç­›é€‰åæœºä¼šæ•°=0ï¼‰")
        print(f"     ğŸ’¡ å¯èƒ½åŸå› ï¼šç­›é€‰æ¡ä»¶è¿‡ä¸¥æˆ–æœºä¼šæ•°å¤ªå°‘ï¼ˆå½“å‰{len(opportunities)}ä¸ªï¼‰")
        print("     ğŸ’¡ å»ºè®®ï¼šå¢åŠ æœºä¼šé‡‡æ ·æ•°é‡æˆ–æ”¾å®½ç­›é€‰æ¡ä»¶")
        return {
            'best_params': {},
            'capture_rate': 0,
            'avg_profit': 0,
            'total_profit': 0,
            'captured_count': 0
        }
    
    # é€‰æ‹©æ€»åˆ©æ¶¦æœ€é«˜çš„ç»„åˆ
    best_result = max(all_results, key=lambda x: x['total_profit'])
    
    print("     âœ“ æœ€ä¼˜å‚æ•°æ‰¾åˆ°ï¼")
    print(f"        èµ·ç‚¹: {best_result['starting_point']}")
    print(f"        æ•è·ç‡: {best_result['capture_rate']*100:.1f}% ({best_result['captured_count']}/{len(opportunities)})")
    print(f"        å¹³å‡åˆ©æ¶¦: {best_result['avg_profit']:.2f}%")
    print(f"        æ€»åˆ©æ¶¦: {best_result['total_profit']:.1f}%")
    print(f"        ç§»åŠ¨æ­¢æŸ: {'âœ… å¯ç”¨' if best_result['params']['trailing_stop_enabled'] else 'âŒ ç¦ç”¨'}")
    
    return {
        'best_params': best_result['params'],
        'capture_rate': best_result['capture_rate'],
        'avg_profit': best_result['avg_profit'],
        'total_profit': best_result['total_profit'],
        'captured_count': best_result['captured_count'],
        'starting_point': best_result['starting_point']
    }

