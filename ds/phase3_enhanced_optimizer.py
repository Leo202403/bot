#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã€V8.5.2.4.42ã€‘Phase 3å¢å¼ºä¼˜åŒ–å™¨

æ ¸å¿ƒåŠŸèƒ½:
1. å åŠ Phase 2çš„learned_featuresï¼ˆsignal_scoreæƒé‡ã€top5å‚æ•°ç»„åˆï¼‰
2. ä½¿ç”¨ä¼˜åŒ–åçš„signal_scoreæƒé‡é‡æ–°è®¡ç®—æ‰€æœ‰æœºä¼š
3. å¤šèµ·ç‚¹æœç´¢ï¼ˆAIå»ºè®® + Phase2æœ€ä¼˜ + Top5ç»„åˆï¼‰
4. ç»„åˆç­›é€‰æµ‹è¯•ï¼ˆconsensus Ã— signal_scoreçŸ©é˜µï¼‰
5. AIååŠ©åˆ†æå’Œæ¨èæœ€ä¼˜å‚æ•°
6. ã€V8.5.2.4.42æ–°å¢ã€‘åˆ†ç¦»ä¼˜åŒ–è¶…çŸ­çº¿å’Œæ³¢æ®µå‚æ•°
7. ã€V8.5.2.4.42æ–°å¢ã€‘æµ‹è¯•ç§»åŠ¨æ­¢ç›ˆæ­¢æŸæ•ˆæœ
"""

import json
from pathlib import Path
from typing import Dict, List, Any, Tuple
import sys


def phase3_enhanced_optimization(
    all_opportunities: List[Dict],
    phase1_baseline: Dict,
    phase2_baseline: Dict,
    kline_snapshots,
    model_name: str = "deepseek"
) -> Dict:
    """
    ã€V8.5.2.4.41ã€‘Phase 3å¢å¼ºä¼˜åŒ–
    
    Args:
        all_opportunities: æ‰€æœ‰è¯†åˆ«çš„æœºä¼š
        phase1_baseline: Phase 1çš„ç»Ÿè®¡åŸºçº¿
        phase2_baseline: Phase 2çš„ä¼˜åŒ–ç»“æœï¼ˆåŒ…å«learned_featuresï¼‰
        kline_snapshots: å¸‚åœºå¿«ç…§æ•°æ®
        model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºAIè°ƒç”¨ï¼‰
    
    Returns:
        phase3_result: Phase 3ä¼˜åŒ–ç»“æœ
    """
    print(f"\n{'='*70}")
    print(f"âš–ï¸  ã€Phase 3ã€‘é£é™©æ§åˆ¶ä¸åˆ©æ¶¦æœ€å¤§åŒ–")
    print(f"{'='*70}")
    print(f"  ç­–ç•¥ï¼šå åŠ Phase 2æˆæœ + å¤šèµ·ç‚¹æœç´¢ + AIè¾…åŠ©å†³ç­–")
    print(f"  ç‰¹è‰²ï¼šä½¿ç”¨ä¼˜åŒ–æƒé‡ + consensusç­›é€‰ + ä¿¡å·åˆ†çŸ©é˜µ")
    print(f"{'='*70}")
    
    # ã€æ­¥éª¤1ã€‘æå–Phase 2å­¦åˆ°çš„ç‰¹å¾
    learned_features = phase2_baseline.get('learned_features', {})
    best_scalping_weights = learned_features.get('best_scalping_weights', {})
    best_swing_weights = learned_features.get('best_swing_weights', {})
    top5_param_combos = learned_features.get('top5_param_combos', [])
    
    print(f"\n  ğŸ“š ã€Phase 2å­¦ä¹ æˆæœåŠ è½½ã€‘")
    print(f"     âš¡ è¶…çŸ­çº¿æœ€ä¼˜æƒé‡: {best_scalping_weights.get('name', 'N/A')}")
    print(f"     ğŸŒŠ æ³¢æ®µæœ€ä¼˜æƒé‡: {best_swing_weights.get('name', 'N/A')}")
    print(f"     ğŸ¯ Top5å‚æ•°ç»„åˆ: {len(top5_param_combos)}ä¸ª")
    
    # ã€æ­¥éª¤2ã€‘ä½¿ç”¨ä¼˜åŒ–æƒé‡é‡æ–°è®¡ç®—signal_score
    print(f"\n  ğŸ”„ ã€é‡æ–°è®¡ç®—signal_scoreã€‘")
    print(f"     ä½¿ç”¨Phase 2ä¼˜åŒ–çš„æƒé‡é…ç½®...")
    
    # å¯¼å…¥é‡æ–°è®¡ç®—å‡½æ•°
    sys.path.insert(0, str(Path(__file__).parent))
    from deepseek_å¤šå¸ç§æ™ºèƒ½ç‰ˆ import recalculate_signal_score_from_snapshot
    
    recalc_count = 0
    for opp in all_opportunities:
        signal_type = opp.get('signal_type', 'swing')
        
        # é€‰æ‹©å¯¹åº”çš„æƒé‡é…ç½®
        if signal_type == 'scalping' and best_scalping_weights:
            weight_config = best_scalping_weights.get('weights', {})
        elif signal_type == 'swing' and best_swing_weights:
            weight_config = best_swing_weights.get('weights', {})
        else:
            weight_config = None
        
        # é‡æ–°è®¡ç®—signal_score
        if weight_config:
            # æ„å»ºlearning_configæ ¼å¼
            learning_config = {
                'scalping_weights': best_scalping_weights.get('weights', {}) if signal_type == 'scalping' else {},
                'swing_weights': best_swing_weights.get('weights', {}) if signal_type == 'swing' else {}
            }
            
            new_signal_score = recalculate_signal_score_from_snapshot(
                opp, signal_type, learning_config
            )
            
            # ä¿å­˜æ—§å€¼ï¼ˆè°ƒè¯•ç”¨ï¼‰
            opp['_old_signal_score'] = opp.get('signal_score', 0)
            opp['signal_score'] = new_signal_score
            recalc_count += 1
    
    print(f"     âœ“ é‡æ–°è®¡ç®—: {recalc_count}/{len(all_opportunities)}ä¸ªæœºä¼š")
    
    # ã€æ­¥éª¤3ã€‘å¤šèµ·ç‚¹æœç´¢
    print(f"\n  ğŸ¯ ã€å¤šèµ·ç‚¹æœç´¢ã€‘")
    print(f"     ç­–ç•¥ï¼šä»å¤šä¸ªä¼˜è´¨èµ·ç‚¹å‡ºå‘ï¼Œé¿å…å±€éƒ¨æœ€ä¼˜")
    
    candidate_starting_points = []
    
    # èµ·ç‚¹1: Phase 2æœ€ä¼˜å‚æ•°
    if phase2_baseline.get('params'):
        candidate_starting_points.append({
            'name': 'Phase2æœ€ä¼˜',
            'params': phase2_baseline['params'].copy(),
            'source': 'phase2_best'
        })
    
    # èµ·ç‚¹2: Phase 1 AIå»ºè®®ï¼ˆå¦‚æœæœ‰ï¼‰
    if phase1_baseline and phase1_baseline.get('ai_suggested_params'):
        candidate_starting_points.append({
            'name': 'AIå»ºè®®',
            'params': phase1_baseline['ai_suggested_params'].copy(),
            'source': 'ai_suggestion'
        })
    
    # èµ·ç‚¹3-5: Top5ç»„åˆçš„å‰3ä¸ª
    for i, combo in enumerate(top5_param_combos[:3], 1):
        if combo.get('params'):
            candidate_starting_points.append({
                'name': f"Top{i}ç»„åˆ",
                'params': combo['params'].copy(),
                'source': f'top5_{i}'
            })
    
    print(f"     å€™é€‰èµ·ç‚¹: {len(candidate_starting_points)}ä¸ª")
    for sp in candidate_starting_points:
        print(f"       - {sp['name']}")
    
    # ä¸ºæ¯ä¸ªèµ·ç‚¹è¿›è¡Œå±€éƒ¨æœç´¢
    from backtest_optimizer_v8321 import optimize_params_v8321_lightweight
    
    all_search_results = []
    
    for i, starting_point in enumerate(candidate_starting_points, 1):
        print(f"\n     [{i}/{len(candidate_starting_points)}] ä»'{starting_point['name']}'å‡ºå‘...")
        
        try:
            # ä¸ºè¿™ä¸ªèµ·ç‚¹åšå±€éƒ¨æœç´¢
            # ã€V8.5.2.4.47ä¼˜åŒ–ã€‘ä»50ç»„å‡åˆ°30ç»„ï¼Œé¿å…å†…å­˜è€—å°½ï¼ˆ2GæœåŠ¡å™¨ï¼‰
            # ã€V8.5.2.4.47ä¿®å¤ã€‘ä½¿ç”¨current_paramsä»£æ›¿starting_paramsï¼Œæ·»åŠ signal_type
            search_result = optimize_params_v8321_lightweight(
                opportunities=all_opportunities,
                current_params=starting_point['params'],
                signal_type='swing',  # é»˜è®¤ä½¿ç”¨swingï¼ˆæˆ–æ ¹æ®å®é™…æƒ…å†µåˆ¤æ–­ï¼‰
                max_combinations=30  # ã€V8.5.2.4.47ã€‘50â†’30ï¼ŒèŠ‚çœ40%å†…å­˜
            )
            
            if search_result:
                search_result['starting_point'] = starting_point['name']
                all_search_results.append(search_result)
                print(f"        âœ“ æ‰¾åˆ°ä¼˜åŒ–å‚æ•°ï¼Œåˆ©æ¶¦: {search_result.get('total_profit', 0):.1f}%")
        except Exception as e:
            print(f"        âš ï¸  æœç´¢å¤±è´¥: {e}")
    
    # é€‰æ‹©æœ€ä½³ç»“æœ
    if all_search_results:
        best_search_result = max(all_search_results, key=lambda x: x.get('total_profit', 0))
        print(f"\n     ğŸ† æœ€ä½³èµ·ç‚¹: {best_search_result.get('starting_point')}")
        print(f"        æ€»åˆ©æ¶¦: {best_search_result.get('total_profit', 0):.1f}%")
        print(f"        æ•è·ç‡: {best_search_result.get('capture_rate', 0)*100:.1f}%")
    else:
        best_search_result = None
        print(f"\n     âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆç»“æœï¼Œä½¿ç”¨Phase 2å‚æ•°")
    
    # ã€æ­¥éª¤4ã€‘ç»„åˆç­›é€‰çŸ©é˜µæµ‹è¯•
    print(f"\n  ğŸ“Š ã€ç»„åˆç­›é€‰çŸ©é˜µã€‘")
    print(f"     æµ‹è¯•ä¸åŒçš„consensus Ã— signal_scoreç»„åˆ")
    
    filter_combinations = [
        {'min_consensus': 1, 'min_signal_score': 75, 'name': 'æå®½æ¾ï¼ˆæœ€å¤§å¬å›ï¼‰'},
        {'min_consensus': 1, 'min_signal_score': 80, 'name': 'å®½æ¾'},
        {'min_consensus': 2, 'min_signal_score': 80, 'name': 'å¹³è¡¡-åå®½'},
        {'min_consensus': 2, 'min_signal_score': 85, 'name': 'å¹³è¡¡'},
        {'min_consensus': 2, 'min_signal_score': 90, 'name': 'å¹³è¡¡-åä¸¥'},
        {'min_consensus': 3, 'min_signal_score': 85, 'name': 'ä¸¥æ ¼-é«˜å…±æŒ¯'},
        {'min_consensus': 3, 'min_signal_score': 90, 'name': 'ä¸¥æ ¼'},
        {'min_consensus': 1, 'min_signal_score': 90, 'name': 'ä¿¡å·åˆ†ä¼˜å…ˆ'},
        {'min_consensus': 3, 'min_signal_score': 80, 'name': 'å…±æŒ¯ä¼˜å…ˆ'},
    ]
    
    # å¯¼å…¥actual_profitè®¡ç®—
    from calculate_actual_profit import calculate_single_actual_profit
    
    matrix_results = []
    
    for combo in filter_combinations:
        # è¿‡æ»¤æœºä¼š
        # ã€V8.5.2.4.47ä¿®å¤ã€‘å­—æ®µåç»Ÿä¸€ä¸ºconsensusï¼ˆPhase 1è®¾ç½®çš„å­—æ®µåï¼‰
        filtered_opps = [
            opp for opp in all_opportunities
            if (opp.get('consensus', 0) >= combo['min_consensus'] and
                opp.get('signal_score', 0) >= combo['min_signal_score'])
        ]
        
        if not filtered_opps:
            continue
        
        # è®¡ç®—actual_profitï¼ˆä½¿ç”¨best_search_resultçš„å‚æ•°ï¼Œå¦‚æœæœ‰ï¼‰
        params = best_search_result.get('params', phase2_baseline.get('params', {})) if best_search_result else phase2_baseline.get('params', {})
        
        for opp in filtered_opps:
            signal_type = opp.get('signal_type', 'swing')
            
            # æ ¹æ®signal_typeä½¿ç”¨é»˜è®¤å€¼
            if signal_type == 'scalping':
                default_tp = 2.0
                default_sl = 1.5
                default_holding = 12
            else:
                default_tp = 6.0
                default_sl = 2.5
                default_holding = 72
            
            strategy_params = {
                **params,
                'atr_tp_multiplier': params.get('atr_tp_multiplier', default_tp),
                'atr_stop_multiplier': params.get('atr_stop_multiplier', default_sl),
                'max_holding_hours': params.get('max_holding_hours', default_holding)
            }
            
            actual_profit = calculate_single_actual_profit(
                opp,
                strategy_params=strategy_params,
                use_dynamic_atr=False
            )
            opp['_matrix_actual_profit'] = actual_profit
        
        # ç»Ÿè®¡ç»“æœ
        capture_rate = len(filtered_opps) / len(all_opportunities) if all_opportunities else 0
        avg_profit = sum(o.get('_matrix_actual_profit', 0) for o in filtered_opps) / len(filtered_opps) if filtered_opps else 0
        total_profit = sum(o.get('_matrix_actual_profit', 0) for o in filtered_opps)
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        score = total_profit * 0.7 + capture_rate * 100 * 0.3
        
        matrix_results.append({
            'name': combo['name'],
            'min_consensus': combo['min_consensus'],
            'min_signal_score': combo['min_signal_score'],
            'captured_count': len(filtered_opps),
            'capture_rate': capture_rate,
            'avg_profit': avg_profit,
            'total_profit': total_profit,
            'score': score
        })
    
    # æ’åºå¹¶æ˜¾ç¤ºTop 3
    matrix_results_sorted = sorted(matrix_results, key=lambda x: x['score'], reverse=True)
    
    print(f"\n     ç»„åˆç­›é€‰Top 3:")
    for i, result in enumerate(matrix_results_sorted[:3], 1):
        print(f"       #{i} [{result['name']}]")
        print(f"          consensus>={result['min_consensus']}, signal_score>={result['min_signal_score']}")
        print(f"          æ•è·: {result['captured_count']}ä¸ª ({result['capture_rate']*100:.1f}%)")
        print(f"          å¹³å‡åˆ©æ¶¦: {result['avg_profit']:.2f}%, æ€»åˆ©æ¶¦: {result['total_profit']:.1f}%")
        print(f"          ç»¼åˆå¾—åˆ†: {result['score']:.1f}")
    
    best_matrix_combo = matrix_results_sorted[0] if matrix_results_sorted else None
    
    # ã€æ­¥éª¤5ã€‘AIè¾…åŠ©å†³ç­–
    print(f"\n  ğŸ¤– ã€AIè¾…åŠ©å†³ç­–ã€‘")
    print(f"     è¯·æ±‚AIåˆ†ææ•°æ®å¹¶æ¨èæœ€ä¼˜å‚æ•°...")
    
    ai_recommendation = request_ai_analysis(
        all_opportunities=all_opportunities,
        phase1_baseline=phase1_baseline,
        phase2_baseline=phase2_baseline,
        search_results=all_search_results,
        matrix_results=matrix_results_sorted[:5],
        model_name=model_name
    )
    
    # ã€æ­¥éª¤6ã€‘åˆ†ç¦»ä¼˜åŒ–è¶…çŸ­çº¿å’Œæ³¢æ®µ
    print(f"\n  ğŸ“Š ã€åˆ†ç¦»ä¼˜åŒ–ã€‘")
    print(f"     åˆ†åˆ«ä¸ºè¶…çŸ­çº¿å’Œæ³¢æ®µå¯»æ‰¾æœ€å¤§åˆ©æ¶¦å‚æ•°...")
    
    # åˆ†ç¦»æœºä¼š
    scalping_opps = [o for o in all_opportunities if o.get('signal_type') == 'scalping']
    swing_opps = [o for o in all_opportunities if o.get('signal_type') == 'swing']
    
    print(f"     è¶…çŸ­çº¿æœºä¼š: {len(scalping_opps)}ä¸ª")
    print(f"     æ³¢æ®µæœºä¼š: {len(swing_opps)}ä¸ª")
    
    # ä¼˜åŒ–è¶…çŸ­çº¿å‚æ•°
    scalping_result = optimize_for_signal_type(
        opportunities=scalping_opps,
        signal_type='scalping',
        learned_features=learned_features,
        starting_points=candidate_starting_points,
        kline_snapshots=kline_snapshots
    )
    
    # ä¼˜åŒ–æ³¢æ®µå‚æ•°
    swing_result = optimize_for_signal_type(
        opportunities=swing_opps,
        signal_type='swing',
        learned_features=learned_features,
        starting_points=candidate_starting_points,
        kline_snapshots=kline_snapshots
    )
    
    print(f"\n  âœ… Phase 3ä¼˜åŒ–å®Œæˆ")
    print(f"     è¶…çŸ­çº¿: æ•è·ç‡{scalping_result['capture_rate']*100:.1f}%, å¹³å‡åˆ©æ¶¦{scalping_result['avg_profit']:.2f}%")
    print(f"     æ³¢æ®µ: æ•è·ç‡{swing_result['capture_rate']*100:.1f}%, å¹³å‡åˆ©æ¶¦{swing_result['avg_profit']:.2f}%")
    
    # ã€V8.5.2.4.42ã€‘è¿”å›åˆ†ç¦»çš„Phase 3ç»“æœ
    return {
        'scalping': {
            'params': scalping_result['best_params'],
            'capture_rate': scalping_result['capture_rate'],
            'avg_profit': scalping_result['avg_profit'],
            'total_profit': scalping_result['total_profit'],
            'captured_count': scalping_result['captured_count']
        },
        'swing': {
            'params': swing_result['best_params'],
            'capture_rate': swing_result['capture_rate'],
            'avg_profit': swing_result['avg_profit'],
            'total_profit': swing_result['total_profit'],
            'captured_count': swing_result['captured_count']
        },
        'decision_source': 'Multi-start search with trailing stop',
        'learned_features': learned_features,
        'multi_start_search': {
            'starting_points': len(candidate_starting_points),
            'all_results': all_search_results,
            'best_result': best_search_result
        },
        'filter_matrix': {
            'tested_combinations': len(matrix_results),
            'all_results': matrix_results_sorted,
            'best_combo': best_matrix_combo
        },
        'ai_recommendation': ai_recommendation,
        'recalculated_opportunities': len(all_opportunities)
    }


def request_ai_analysis(
    all_opportunities: List[Dict],
    phase1_baseline: Dict,
    phase2_baseline: Dict,
    search_results: List[Dict],
    matrix_results: List[Dict],
    model_name: str
) -> Dict:
    """
    ã€V8.5.2.4.41ã€‘è¯·æ±‚AIåˆ†ææ•°æ®å¹¶æ¨èæœ€ä¼˜å‚æ•°
    
    ç»Ÿä¸€AIè°ƒç”¨æ¥å£ï¼Œæ”¯æŒdeepseekå’Œqwen
    ä½¿ç”¨è‹±æ–‡ä¸AIæ²Ÿé€šä»¥è·å¾—æ›´å¥½çš„æ¨ç†èƒ½åŠ›
    
    Args:
        all_opportunities: æ‰€æœ‰æœºä¼š
        phase1_baseline: Phase 1åŸºçº¿
        phase2_baseline: Phase 2åŸºçº¿
        search_results: å¤šèµ·ç‚¹æœç´¢ç»“æœ
        matrix_results: çŸ©é˜µç­›é€‰ç»“æœ
        model_name: æ¨¡å‹åç§° ("deepseek" æˆ– "qwen")
    
    Returns:
        ai_recommendation: AIæ¨èç»“æœ
    """
    try:
        # æ„å»ºAIæç¤ºè¯ï¼ˆè‹±æ–‡ï¼‰
        prompt = build_ai_analysis_prompt(
            all_opportunities, phase1_baseline, phase2_baseline,
            search_results, matrix_results
        )
        
        # ç»Ÿä¸€AIè°ƒç”¨é€»è¾‘
        ai_response = call_ai_unified(prompt, model_name)
        
        # è§£æAIå“åº”
        recommendation = parse_ai_recommendation(ai_response)
        
        print(f"     âœ“ AI Analysis Completed")
        print(f"     Recommended Strategy: {recommendation.get('strategy', 'N/A')}")
        print(f"     Reason: {recommendation.get('reason', 'N/A')[:80]}...")
        
        return recommendation
        
    except Exception as e:
        print(f"     âš ï¸  AI Call Failed: {e}")
        return {}


def call_ai_unified(prompt: str, model_name: str) -> str:
    """
    ã€V8.5.2.4.41ã€‘ç»Ÿä¸€AIè°ƒç”¨æ¥å£
    
    æ”¯æŒdeepseekå’Œqwenï¼Œä½¿ç”¨ç›¸åŒçš„APIè°ƒç”¨é€»è¾‘
    
    Args:
        prompt: è‹±æ–‡æç¤ºè¯
        model_name: æ¨¡å‹åç§°
    
    Returns:
        ai_response: AIå“åº”æ–‡æœ¬
    """
    import os
    import requests
    import json
    
    # æ ¹æ®æ¨¡å‹é€‰æ‹©APIé…ç½®
    if model_name == "deepseek":
        api_key = os.getenv("DEEPSEEK_API_KEY")
        api_url = "https://api.deepseek.com/v1/chat/completions"
        model_id = "deepseek-chat"
    else:  # qwen
        api_key = os.getenv("DASHSCOPE_API_KEY")
        api_url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
        model_id = "qwen-plus"
    
    if not api_key:
        raise ValueError(f"API key not found for {model_name}")
    
    # æ„å»ºè¯·æ±‚
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": model_id,
        "messages": [
            {
                "role": "system",
                "content": "You are an expert trading system optimizer. Analyze data and provide recommendations in JSON format. Always respond in English."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 2000
    }
    
    # å‘é€è¯·æ±‚
    response = requests.post(api_url, headers=headers, json=payload, timeout=30)
    response.raise_for_status()
    
    # è§£æå“åº”
    result = response.json()
    ai_response = result["choices"][0]["message"]["content"]
    
    return ai_response


def build_ai_analysis_prompt(
    all_opportunities: List[Dict],
    phase1_baseline: Dict,
    phase2_baseline: Dict,
    search_results: List[Dict],
    matrix_results: List[Dict]
) -> str:
    """
    Build AI analysis prompt in English
    
    English prompts provide better reasoning capabilities for AI models
    """
    
    # Statistics
    total_opps = len(all_opportunities)
    scalping_count = sum(1 for o in all_opportunities if o.get('signal_type') == 'scalping')
    swing_count = total_opps - scalping_count
    
    # Consensus distribution
    consensus_dist = {}
    for opp in all_opportunities:
        c = opp.get('consensus', 0)  # ã€V8.5.2.4.47ä¿®å¤ã€‘å­—æ®µåç»Ÿä¸€
        consensus_dist[c] = consensus_dist.get(c, 0) + 1
    
    # Signal score distribution
    signal_score_ranges = {'0-70': 0, '70-80': 0, '80-90': 0, '90-100': 0}
    for opp in all_opportunities:
        score = opp.get('signal_score', 0)
        if score < 70:
            signal_score_ranges['0-70'] += 1
        elif score < 80:
            signal_score_ranges['70-80'] += 1
        elif score < 90:
            signal_score_ranges['80-90'] += 1
        else:
            signal_score_ranges['90-100'] += 1
    
    prompt = f"""As a trading system optimization expert, please analyze the following data and recommend optimal parameter configuration.

ã€Phase 1 Objective Statisticsã€‘
- Total Opportunities: {total_opps}
- Scalping: {scalping_count}, Swing: {swing_count}
- Average Max Profit: {phase1_baseline.get('avg_max_profit', 0):.2f}%

ã€Phase 2 Learning Resultsã€‘
- Best Scalping Weights: {phase2_baseline.get('learned_features', {}).get('best_scalping_weights', {}).get('name', 'N/A')}
- Best Swing Weights: {phase2_baseline.get('learned_features', {}).get('best_swing_weights', {}).get('name', 'N/A')}
- Phase 2 Capture Rate: {phase2_baseline.get('capture_rate', 0)*100:.1f}%
- Phase 2 Avg Profit: {phase2_baseline.get('avg_profit', 0):.2f}%

ã€Data Distributionã€‘
Consensus Distribution: {consensus_dist}
Signal Score Distribution: {signal_score_ranges}

ã€Multi-Start Search Resultsã€‘(Top 3)
"""
    
    for i, result in enumerate(search_results[:3], 1):
        prompt += f"""
{i}. Starting Point: {result.get('starting_point', 'N/A')}
   Total Profit: {result.get('total_profit', 0):.1f}%
   Capture Rate: {result.get('capture_rate', 0)*100:.1f}%
   Params: consensus>={result.get('params', {}).get('min_indicator_consensus', 'N/A')}, 
           signal_score>={result.get('params', {}).get('min_signal_score', 'N/A')}
"""
    
    prompt += f"""
ã€Filter Matrix Resultsã€‘(Top 3)
"""
    
    for i, result in enumerate(matrix_results[:3], 1):
        prompt += f"""
{i}. {result.get('name', 'N/A')}
   consensus>={result['min_consensus']}, signal_score>={result['min_signal_score']}
   Capture Rate: {result['capture_rate']*100:.1f}%
   Avg Profit: {result['avg_profit']:.2f}%
   Total Profit: {result['total_profit']:.1f}%
   Composite Score: {result['score']:.1f}
"""
    
    prompt += """
ã€Questionsã€‘
1. Comprehensive Evaluation: Which configuration is optimal and why?
2. Parameter Recommendation: What are the recommended min_consensus and min_signal_score?
3. Risk Warning: What are the potential risks of this configuration?

Please respond in JSON format (English):
{
    "recommended_params": {
        "min_indicator_consensus": <number>,
        "min_signal_score": <number>,
        "min_risk_reward": <number>
    },
    "strategy": "<brief description>",
    "reason": "<detailed reasoning>",
    "risks": "<potential risks>"
}
"""
    
    return prompt


def parse_ai_recommendation(ai_response: str) -> Dict:
    """è§£æAIæ¨èå“åº”"""
    try:
        # å°è¯•æå–JSON
        import re
        json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
        if json_match:
            recommendation = json.loads(json_match.group())
            return recommendation
        else:
            # æ— æ³•æå–JSONï¼Œè¿”å›ç©º
            return {}
    except Exception as e:
        print(f"âš ï¸  è§£æAIå“åº”å¤±è´¥: {e}")
        return {}


def optimize_for_signal_type(
    opportunities: List[Dict],
    signal_type: str,
    learned_features: Dict,
    starting_points: List[Dict],
    kline_snapshots=None
) -> Dict:
    """
    ã€V8.5.2.4.42ã€‘ä¸ºç‰¹å®šä¿¡å·ç±»å‹ä¼˜åŒ–å‚æ•°
    
    åˆ†åˆ«ä¸ºè¶…çŸ­çº¿å’Œæ³¢æ®µå¯»æ‰¾æœ€ä¼˜å‚æ•°é…ç½®ï¼ˆåŒ…æ‹¬ç§»åŠ¨æ­¢æŸï¼‰
    
    Args:
        opportunities: è¯¥ä¿¡å·ç±»å‹çš„æœºä¼šåˆ—è¡¨
        signal_type: 'scalping' æˆ– 'swing'
        learned_features: Phase 2å­¦ä¹ çš„ç‰¹å¾
        starting_points: å€™é€‰èµ·ç‚¹åˆ—è¡¨
        kline_snapshots: å¸‚åœºå¿«ç…§æ•°æ®
    
    Returns:
        result: {
            'best_params': {...},
            'capture_rate': float,
            'avg_profit': float,
            'total_profit': float,
            'captured_count': int
        }
    """
    from trailing_stop_calculator import batch_calculate_profits
    
    print(f"\n  ğŸ¯ ã€{signal_type.upper()}å‚æ•°ä¼˜åŒ–ã€‘")
    print(f"     æœºä¼šæ•°é‡: {len(opportunities)}ä¸ª")
    
    # å‚æ•°æœç´¢ç©ºé—´ï¼ˆåŒ…æ‹¬ç§»åŠ¨æ­¢æŸï¼‰
    # ã€V8.5.2.4.47ä¿®å¤ã€‘æ”¾å®½é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦ç­›é€‰å¯¼è‡´æ•è·ç‡æä½å’Œè´Ÿåˆ©æ¶¦
    if signal_type == 'scalping':
        param_grid = {
            'min_indicator_consensus': [1, 2],          # é™ä½ï¼šå‡å°‘3ï¼ˆè¿‡ä¸¥ï¼‰
            'min_signal_score': [60, 70, 75, 80],       # é™ä½ï¼šä»80èµ·é™åˆ°60èµ·
            'atr_tp_multiplier': [1.5, 2.0, 2.5, 3.0],
            'atr_stop_multiplier': [1.0, 1.5, 2.0],
            'max_holding_hours': [4, 8, 12, 16],
            'trailing_stop_enabled': [False, True]      # ä¼˜å…ˆæµ‹è¯•ä¸ç”¨ç§»åŠ¨æ­¢æŸ
        }
    else:  # swing
        param_grid = {
            'min_indicator_consensus': [1, 2],          # é™ä½ï¼šä»2èµ·é™åˆ°1èµ·ï¼Œå‡å°‘3ã€4
            'min_signal_score': [70, 75, 80, 85],       # é™ä½ï¼šä»85èµ·é™åˆ°70èµ·
            'atr_tp_multiplier': [4.0, 5.0, 6.0, 7.0],
            'atr_stop_multiplier': [2.0, 2.5, 3.0],
            'max_holding_hours': [48, 72, 96],
            'trailing_stop_enabled': [False, True]      # ä¼˜å…ˆæµ‹è¯•ä¸ç”¨ç§»åŠ¨æ­¢æŸ
        }
    
    # å¤šèµ·ç‚¹æœç´¢
    all_results = []
    
    for sp_idx, starting_point in enumerate(starting_points, 1):
        print(f"     [{sp_idx}/{len(starting_points)}] ä»'{starting_point['name']}'å‡ºå‘...")
        
        # å›´ç»•èµ·ç‚¹ç”Ÿæˆæµ‹è¯•ç»„åˆï¼ˆç®€åŒ–ç‰ˆï¼šä½¿ç”¨gridçš„ä¸­å¿ƒå€¼ï¼‰
        test_combinations = []
        
        # ç”Ÿæˆæµ‹è¯•ç»„åˆï¼ˆæ¯ä¸ªç»´åº¦å–2-3ä¸ªå€¼ï¼‰
        for consensus in param_grid['min_indicator_consensus']:
            for signal_score in param_grid['min_signal_score'][:2]:  # æ¯ä¸ªèµ·ç‚¹åªæµ‹è¯•2ä¸ªå€¼
                for tp_mult in param_grid['atr_tp_multiplier'][::2]:  # æ¯éš”ä¸€ä¸ªå–
                    for sl_mult in param_grid['atr_stop_multiplier'][:2]:
                        for trailing in param_grid['trailing_stop_enabled']:
                            test_params = {
                                'min_indicator_consensus': consensus,
                                'min_signal_score': signal_score,
                                'atr_tp_multiplier': tp_mult,
                                'atr_stop_multiplier': sl_mult,
                                'max_holding_hours': param_grid['max_holding_hours'][1],  # ä½¿ç”¨ä¸­é—´å€¼
                                'trailing_stop_enabled': trailing
                            }
                            test_combinations.append(test_params)
        
        # ã€V8.5.2.4.47ä¼˜åŒ–ã€‘é™åˆ¶æµ‹è¯•æ•°é‡ï¼Œé¿å…å†…å­˜è€—å°½ï¼ˆ2GæœåŠ¡å™¨ï¼‰
        # æ¯ä¸ªèµ·ç‚¹ä»50ç»„å‡åˆ°30ç»„ï¼ŒèŠ‚çœ40%å†…å­˜
        test_combinations = test_combinations[:30]
        
        # æµ‹è¯•æ¯ä¸ªç»„åˆ
        for params in test_combinations:
            # ç­›é€‰æœºä¼š
            filtered_opps = [
                opp for opp in opportunities
                # ã€V8.5.2.4.47ä¿®å¤ã€‘å­—æ®µåç»Ÿä¸€ä¸ºconsensus
                if (opp.get('consensus', 0) >= params['min_indicator_consensus'] and
                    opp.get('signal_score', 0) >= params['min_signal_score'])
            ]
            
            if not filtered_opps:
                continue
            
            # è®¡ç®—åˆ©æ¶¦ï¼ˆä½¿ç”¨ç§»åŠ¨æ­¢æŸï¼‰
            profit_results = batch_calculate_profits(filtered_opps, params)
            
            # ç»Ÿè®¡
            captured_count = len(filtered_opps)
            capture_rate = captured_count / len(opportunities) if opportunities else 0
            total_profit = sum(r['profit'] for r in profit_results)
            avg_profit = total_profit / captured_count if captured_count > 0 else 0
            
            all_results.append({
                'params': params,
                'starting_point': starting_point['name'],
                'captured_count': captured_count,
                'capture_rate': capture_rate,
                'avg_profit': avg_profit,
                'total_profit': total_profit
            })
    
    if not all_results:
        print(f"     âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆç»“æœ")
        return {
            'best_params': {},
            'capture_rate': 0,
            'avg_profit': 0,
            'total_profit': 0,
            'captured_count': 0
        }
    
    # é€‰æ‹©æ€»åˆ©æ¶¦æœ€é«˜çš„ç»„åˆ
    best_result = max(all_results, key=lambda x: x['total_profit'])
    
    print(f"     âœ“ æœ€ä¼˜å‚æ•°æ‰¾åˆ°ï¼")
    print(f"        èµ·ç‚¹: {best_result['starting_point']}")
    print(f"        æ•è·ç‡: {best_result['capture_rate']*100:.1f}% ({best_result['captured_count']}/{len(opportunities)})")
    print(f"        å¹³å‡åˆ©æ¶¦: {best_result['avg_profit']:.2f}%")
    print(f"        æ€»åˆ©æ¶¦: {best_result['total_profit']:.1f}%")
    print(f"        ç§»åŠ¨æ­¢æŸ: {'âœ… å¯ç”¨' if best_result['params']['trailing_stop_enabled'] else 'âŒ ç¦ç”¨'}")
    
    return {
        'best_params': best_result['params'],
        'capture_rate': best_result['capture_rate'],
        'avg_profit': best_result['avg_profit'],
        'total_profit': best_result['total_profit'],
        'captured_count': best_result['captured_count'],
        'starting_point': best_result['starting_point']
    }

